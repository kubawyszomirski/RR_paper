{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c7702da",
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy_financial'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29632\\1939402857.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy_financial\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnpf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy_financial'"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy_financial as npf\n",
    "import random  \n",
    "import time\n",
    "\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import PPO, DQN, A2C\n",
    "from stable_baselines3.common.callbacks import CallbackList, CheckpointCallback, EvalCallback\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from sb3_contrib import RecurrentPPO\n",
    "\n",
    "from environment_fx_no_env import calculate_import_export, test1, test2, test3, evaluate1, evaluate2, basepolicy\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from typing import Callable\n",
    "\n",
    "import torch\n",
    "import torch as th\n",
    "from torch import nn\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f3f975",
   "metadata": {
    "code_folding": [
     25
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# import and modify data\n",
    "\n",
    "# Assuming the file is a CSV and specifying the correct path and filename\n",
    "file_path = r\"file_path\"\n",
    "\n",
    "# Use pandas to read the CSV file\n",
    "JA_60 = pd.read_csv(file_path + \"/JA_60\")\n",
    "JA_240 = pd.read_csv(file_path + \"/JA_240\")\n",
    "\n",
    "elec_df = pd.read_csv(file_path + \"/hourly_consumption_gemany2.csv\")\n",
    "import_price = pd.read_csv(file_path + \"/electricity_tariff.csv\")\n",
    "\n",
    "#elec_df = elec_df * 1000\n",
    "elec_df = elec_df.drop('HourOfYear', axis=1)\n",
    "\n",
    "elec_df['hour_of_day'] = np.arange(8760) % 24\n",
    "elec_df['day_of_week'] = np.arange(8760) // 24 % 7  # 0 is Monday, 6 is Sunday\n",
    "\n",
    "# Define rates\n",
    "peak_rate = 1.45\n",
    "normal_rate = 1\n",
    "off_peak_rate = 0.85\n",
    "\n",
    "# Function to determine rate based on hour and day\n",
    "def determine_rate(hour, day):\n",
    "    if day < 5:  # Monday to Friday\n",
    "        if 16 <= hour < 21:  # 4pm to 9pm\n",
    "            return peak_rate\n",
    "        elif 6 <= hour < 10:  # 7am to 9am and 10am to 3pm\n",
    "            return normal_rate\n",
    "        else:  # Off-peak times\n",
    "            return off_peak_rate\n",
    "    else:  # Weekend\n",
    "        if 16 <= hour < 21:  # 4pm to 9pm\n",
    "            return normal_rate\n",
    "        else:  # Off-peak times\n",
    "            return off_peak_rate\n",
    "    \n",
    "# Apply the function to each row to determine the rate\n",
    "elec_df['rate'] = elec_df.apply(lambda row: determine_rate(row['hour_of_day'], row['day_of_week']), axis=1)\n",
    "\n",
    "import_price_df = import_price.drop(columns=['x'])\n",
    "import_price_df = import_price_df[:-26]\n",
    "\n",
    "train_cols = random.sample(list(import_price_df.columns), 7000)\n",
    "import_price_train = import_price_df[train_cols]\n",
    "test_cols = [col for col in import_price_df.columns if col not in train_cols]\n",
    "import_price_test = import_price_df[test_cols]\n",
    "\n",
    "Eff = pd.read_csv(file_path + \"/Efficency_impr\")\n",
    "Eff = (Eff)/100 + 1\n",
    "\n",
    "CAPEX = pd.read_csv(file_path + \"/CAPEX_JA.csv\")\n",
    "CAPEX_JA = (CAPEX[:26])\n",
    "\n",
    "train_cols_CAPEX = random.sample(list(CAPEX_JA.columns), 7000)\n",
    "test_cols_CAPEX = [col for col in CAPEX_JA.columns if col not in train_cols_CAPEX]\n",
    "\n",
    "CAPEX_JA_train = CAPEX_JA[train_cols_CAPEX]\n",
    "CAPEX_JA_test = CAPEX_JA[test_cols_CAPEX]\n",
    "\n",
    "train_cols_Eff = random.sample(list(Eff.columns), 7000)\n",
    "test_cols_Eff = [col for col in Eff.columns if col not in train_cols_Eff]\n",
    "\n",
    "Eff_train = Eff[train_cols_Eff]\n",
    "Eff_test = Eff[test_cols_Eff]\n",
    "\n",
    "JA_60_arr = (np.array(JA_60.T)).flatten()\n",
    "JA_240_arr = (np.array(JA_240.T)).flatten()\n",
    "\n",
    "Eff_train_arr = np.array(Eff_train.T)\n",
    "Eff_test_arr = np.array(Eff_test.T)\n",
    "\n",
    "CAPEX_JA_train_arr = np.array(CAPEX_JA_train.T)\n",
    "CAPEX_JA_test_arr = np.array(CAPEX_JA_test.T)\n",
    "\n",
    "elec_consum_arr = np.array(elec_df[\"Consumption\"])\n",
    "import_price_rate = np.array(elec_df[\"rate\"])\n",
    "\n",
    "import_price_train_arr = np.array(import_price_train.T)\n",
    "import_price_test_arr = np.array(import_price_test.T)\n",
    "\n",
    "grid_factor = pd.read_csv(file_path + \"/grid_factor.csv\")\n",
    "grid_factor =  grid_factor.T\n",
    "\n",
    "train_cols_grid = random.sample(list(grid_factor.columns), 7000)\n",
    "grid_factor_train = grid_factor[train_cols_grid]\n",
    "test_cols_grid = [col for col in grid_factor.columns if col not in train_cols]\n",
    "grid_factor_test = grid_factor[test_cols_grid]\n",
    "\n",
    "grid_factor_train_arr = np.array(grid_factor_train.T)\n",
    "grid_factor_test_arr = np.array(grid_factor_test.T)\n",
    "\n",
    "pv_co2 = pd.read_csv(file_path + \"/pv_emissions.csv\")\n",
    "pv_co2_arr = np.array(pv_co2)\n",
    "pv_co2_arr = np.insert(pv_co2_arr, 0, 1.620)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01482e1",
   "metadata": {
    "code_folding": [
     54,
     239,
     291
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "class TrainEnvironment(gym.Env):\n",
    "    def __init__(self, PV_90_arr, PV_270_arr, elec_consum_arr, import_price_rate, import_tariff, efficency, CAPEX, \n",
    "                 GRID_FACTOR, pv_co2_arr):\n",
    "        \n",
    "        # Price per watthour\n",
    "        self.import_price_df = import_tariff\n",
    "        self.import_price_at_zero = np.float32(0.00035)\n",
    "        self.import_price_rate = import_price_rate\n",
    "        \n",
    "        # Energy Balance\n",
    "        self.PV_90_arr = PV_90_arr\n",
    "        self.PV_270_arr = PV_270_arr\n",
    "        self.elec_df = elec_consum_arr\n",
    "        self.max_export = 4000\n",
    "        self.number_of_panels = 32\n",
    "        \n",
    "        # Degradation\n",
    "        self.deg_mu = 0.82 # Trina: 1.19, JA: 0.82, Maxeon: 0.67\n",
    "        self.deg_std = 0.555 \n",
    "        self.phi = 30 # Trina: 15, JA: 30, Maxeon: 50\n",
    "        \n",
    "        # Efficency Development\n",
    "        self.efficency_develop_df = efficency\n",
    "        self.efficency_at_zero = 1.0\n",
    "        \n",
    "        # Costs\n",
    "        self.power_at_zero = 415  # Trina: 265, JA: 415, Maxeon: 435\n",
    "        self.cost_per_Wp_df_at_zero = 0.69 # Trina: 0.36, JA: 0.69, Maxeon: 1.58\n",
    "        self.cost_per_Wp_df = CAPEX\n",
    "        self.initial_other_costs = 150\n",
    "        \n",
    "        self.operational_cost = 16.8\n",
    "        \n",
    "        self.loan_interest_rate = 1.10\n",
    "        self.normal_interest_rate = 1.02\n",
    "        \n",
    "        self.low_budget = 0 # Low budget: 0, High Budget: 750\n",
    "        self.high_budget = 750 # Low budget: 750, High Budget: 2000\n",
    "                        \n",
    "        # Spaces and length\n",
    "        self.action_space = spaces.MultiDiscrete([self.number_of_panels // 2, self.number_of_panels // 2])\n",
    "        self.observation_space = spaces.Box(0, 1.25, shape=(self.number_of_panels + 8,))\n",
    "        self.episode_len = 25\n",
    "        self.months_per_timestep = 12\n",
    "        \n",
    "        # Emission\n",
    "        self.grid_factor_df = GRID_FACTOR\n",
    "        self.grid_factor_at_zero = 0.553 \n",
    "        self.pv_emission = pv_co2_arr * self.power_at_zero\n",
    "        \n",
    "    def _get_obs(self):\n",
    "        \n",
    "        return self.observation\n",
    "    \n",
    "    def calculate_import_export(self, elec_df, export_price, import_price):\n",
    "        \n",
    "        \"\"\"\n",
    "        Calculate the annual Wh of energy exported to the grid (exported) and saved (minimised)\n",
    "        \"\"\"\n",
    "        \n",
    "        PV_90_tot = self._get_obs()[0:self.number_of_panels // 2].sum() * self.PV_90_arr \n",
    "        PV_270_tot = self._get_obs()[(self.number_of_panels // 2) : self.number_of_panels].sum() * self.PV_270_arr \n",
    "        \n",
    "        AC_OUTPUT_tot = PV_90_tot + PV_270_tot\n",
    "        \n",
    "        exported = (AC_OUTPUT_tot - self.elec_df).clip(min=0, max = self.max_export)        \n",
    "        export_revenue = (export_price * exported).sum()\n",
    "        excess_energy = (AC_OUTPUT_tot - self.elec_df - self.max_export).clip(min=0)\n",
    "\n",
    "        \n",
    "        minimised = AC_OUTPUT_tot - exported \n",
    "        minimised_revenue = (minimised * (self.import_price_rate * import_price)).sum()\n",
    "        \n",
    "        AC_for_env = AC_OUTPUT_tot - excess_energy\n",
    "\n",
    "\n",
    "        return export_revenue, AC_OUTPUT_tot, AC_for_env, minimised_revenue\n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Reset the environment to the original state at t=1\n",
    "        \"\"\"\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        # Panels\n",
    "        self.init_obs = np.random.uniform(0, 1, size=self.number_of_panels).astype(np.float32)\n",
    "        self.init_obs = np.where(self.init_obs < 0.5, 0.0, np.random.uniform(0.85, 1.0, size=self.number_of_panels))\n",
    "\n",
    "        # Combine all initialization into a single step for efficiency\n",
    "        self.import_price_at_zero_norm = (self.import_price_at_zero - self.import_price_df.min().min()) / (self.import_price_df.max().max() - self.import_price_df.min().min())\n",
    "        self.FiT_at_zero_norm = (self.import_price_at_zero - self.import_price_df.min().min() * 0.33) / (self.import_price_df.max().max() - self.import_price_df.min().min() * 0.33)\n",
    "        self.efficency_at_zero_norm = (self.efficency_at_zero - 0.999) / (1.156 - 0.999)\n",
    "        self.panel_cost_and_inverter_at_zero_norm = (self.cost_per_Wp_df_at_zero - self.cost_per_Wp_df.min().min()) / (self.cost_per_Wp_df.max().max() - self.cost_per_Wp_df.min().min())\n",
    "        \n",
    "        self.grid_factor_at_zero_norm = (self.grid_factor_at_zero + 0.05319002) / (0.55762151 + 0.05319002)\n",
    "        \n",
    "        self.current_budget_constraint = np.random.randint(self.low_budget, self.high_budget)\n",
    "        self.next_step_budget_constraint = 0\n",
    "        \n",
    "        \n",
    "        # Complete observation initialization in one go\n",
    "        self.observation = np.concatenate([\n",
    "            self.init_obs,\n",
    "            [self.import_price_at_zero_norm, self.FiT_at_zero_norm, self.efficency_at_zero_norm, \n",
    "             self.panel_cost_and_inverter_at_zero_norm, 0., 0., 0., self.grid_factor_at_zero_norm]\n",
    "        ]).astype(np.float32)\n",
    "\n",
    "        self.previous_observation = self.observation.copy()\n",
    "\n",
    "        # RANDOM IMPORT PRICE\n",
    "        self.random_import_price = self.import_price_df[np.random.choice(self.import_price_df.shape[0])] \n",
    "\n",
    "        # RANDOM EFFICENCY\n",
    "        self.random_efficency_develop = self.efficency_develop_df[np.random.choice(self.efficency_develop_df.shape[0])]   \n",
    "        \n",
    "        # RANDOM COST PER WP\n",
    "        self.random_cost_per_Wp = self.cost_per_Wp_df[np.random.choice(self.cost_per_Wp_df.shape[0])]   \n",
    "\n",
    "        # RANDOM Grid Factor\n",
    "        self.random_grid_factor = self.grid_factor_df[np.random.choice(self.grid_factor_df.shape[0])]   \n",
    "\n",
    "        \n",
    "        self.episode_len = 25  \n",
    "    \n",
    "        info = {}\n",
    "        \n",
    "        # RESET BALANCES\n",
    "        self.fin_balance_tot = 0\n",
    "        self.reward_tot = 0\n",
    "        self.env_balance_tot = 0\n",
    "        self.produced = 0\n",
    "        self.other_costs = 0\n",
    "        self.FiT = 0.0004\n",
    "        self.next_FiT = 0.0004\n",
    "\n",
    "        self.total_cash_flow = []\n",
    "        self.annual_cash_flow = 0\n",
    "                \n",
    "        self.due_loans = [0, 0, 0, 0] \n",
    "        self.current_interest = 0\n",
    "        self.step_total_interest = 1\n",
    "        self.survival = np.zeros(self.number_of_panels, dtype=np.float32)\n",
    "        self.resale_values = array_of_zeros = np.zeros(self.number_of_panels, dtype=np.float32)\n",
    "        \n",
    "        self.broke = np.zeros(self.number_of_panels, dtype=np.float32)\n",
    "        \n",
    "        self.two_year_ago_interest = 0\n",
    "        self.first_year_interest = []\n",
    "        self.second_year_interest = [0]\n",
    "        self.third_year_interest = [0, 0]\n",
    "        self.fourth_year_interest = [0, 0, 0]\n",
    "        self.next_year_total = 0\n",
    "        \n",
    "        self.survival = np.zeros(self.number_of_panels, dtype=np.float32)\n",
    "    \n",
    "        return self.observation, info\n",
    "    \n",
    "    def emission_balance(self, pv_production, grid_factor, panel_emission, action_step):\n",
    "        \n",
    "        curtailed = (pv_production.sum() * grid_factor)/1000\n",
    "        \n",
    "        number_installed = int(np.sum(action_step))\n",
    "        \n",
    "        panel_emission_tot = number_installed * panel_emission\n",
    "        \n",
    "        emission_balance = curtailed - panel_emission_tot\n",
    "        \n",
    "        return emission_balance \n",
    "    \n",
    "    def calculate_resale(self, initial_panel_cost, indices):\n",
    "        \n",
    "        self.resale_values[indices] = initial_panel_cost\n",
    "        \n",
    "        self.resale_values = self.resale_values * 0.85\n",
    "        \n",
    "        for count, i in enumerate(self.broke):\n",
    "            if i == 1:\n",
    "                self.resale_values[count] = 0\n",
    "        \n",
    "        resale_step = self.resale_values[indices].sum()\n",
    "        \n",
    "        return resale_step\n",
    "    \n",
    "    def calculate_panel_inv_cost(self, cost_per_Wp):\n",
    "        \n",
    "        PW_ep = self.efficency_develop * self.power_at_zero\n",
    "        \n",
    "        panel_cost_and_inverter = PW_ep * cost_per_Wp\n",
    "        \n",
    "        return panel_cost_and_inverter\n",
    "        \n",
    "    def calculate_penalty(self, current_step, annual_expense):\n",
    "              \n",
    "        year = 25 - current_step\n",
    "        \n",
    "        if year > 0:\n",
    "            self.current_budget_constraint = self.next_step_budget_constraint    \n",
    "            \n",
    "        \n",
    "        self.current_interest = self.next_year_total\n",
    "        annual_expense = (-annual_expense)\n",
    "        value = 0 \n",
    "        loan = 0\n",
    "        annual_interest = 0\n",
    "\n",
    "        if annual_expense > self.current_budget_constraint:\n",
    "            loan = (self.current_budget_constraint - annual_expense)\n",
    "            value = annual_expense / self.current_budget_constraint\n",
    "            periods = 2 if value < 2 else 3 if value < 3 else 4\n",
    "\n",
    "            annual_interest = loan / periods\n",
    "            interest_multiplier = 1\n",
    "\n",
    "            for i in range(4):\n",
    "                if i < periods:\n",
    "                    self.due_loans[i] = annual_interest * interest_multiplier\n",
    "                    interest_multiplier *= self.loan_interest_rate\n",
    "                else:\n",
    "                    self.due_loans[i] = 0\n",
    "        else:\n",
    "             self.due_loans = [0, 0, 0, 0]\n",
    "    \n",
    "        self.first_year_interest.append(self.due_loans[0])\n",
    "        self.second_year_interest.append(self.due_loans[1])\n",
    "        self.third_year_interest.append(self.due_loans[2])\n",
    "        self.fourth_year_interest.append(self.due_loans[3])\n",
    "    \n",
    "    \n",
    "        self.next_year_total = self.first_year_interest[year] + self.second_year_interest[year] + self.third_year_interest[year] + self.fourth_year_interest[year]\n",
    "        \n",
    "        self.next_step_budget_constraint = np.random.randint(self.low_budget, self.high_budget) * self.step_total_interest\n",
    "        current_budget_observation = (self.next_step_budget_constraint - self.low_budget * self.step_total_interest) / (self.high_budget * self.step_total_interest - self.low_budget * self.step_total_interest) \n",
    "        self.observation[self.number_of_panels + 6] = current_budget_observation\n",
    "                \n",
    "        return self.current_interest, self.due_loans, self.next_year_total\n",
    "        \n",
    "    def calculate_total_CAPEX(self, action_step, panel_cost_and_inverter):\n",
    "        \"\"\"\n",
    "        Calculate CAPEX each step in a vectorized manner.\n",
    "        \"\"\"\n",
    "        BOS = panel_cost_and_inverter * 0.55\n",
    "        number_installed = int(np.sum(action_step))\n",
    "\n",
    "        # Calculate costs from module and inverter\n",
    "        panel_cost_and_inverter_step = panel_cost_and_inverter * number_installed\n",
    "\n",
    "        # Calculate other installation costs\n",
    "        if number_installed == 0:\n",
    "            other_costs = 0\n",
    "        elif number_installed == 1:\n",
    "            other_costs = self.initial_other_costs * self.step_total_interest\n",
    "        else:\n",
    "            discounts = 0.9 ** np.arange(number_installed)\n",
    "            other_costs = (self.initial_other_costs * self.step_total_interest * discounts).sum()\n",
    "\n",
    "        # Calculate BOS costs using vector operations\n",
    "        is_new_installation = (self.previous_observation[:number_installed] == 0) & (action_step[:number_installed] == 1)\n",
    "        is_replacement = (self.previous_observation[:number_installed] > 0) & (action_step[:number_installed] == 1)\n",
    "        BOS_cost = np.sum(BOS * is_new_installation) + np.sum((BOS / 2) * is_replacement)\n",
    "\n",
    "        # Sum total CAPEX\n",
    "        total_CAPEX = panel_cost_and_inverter_step + BOS_cost + other_costs\n",
    "\n",
    "        return total_CAPEX, panel_cost_and_inverter\n",
    "        \n",
    "    def failure(self, actions):\n",
    "        \n",
    "        beta = 3  # Shape parameter\n",
    "\n",
    "        # Determine which panels are active based on the actions and previous observations.\n",
    "        if self.episode_len == 24:\n",
    "            active_panels = (self.observation[:self.number_of_panels] > 0.85)\n",
    "        else:\n",
    "            active_panels = (self.observation[:self.number_of_panels] == self.efficency_develop)\n",
    "\n",
    "        # Calculate lifespan for all active panels at once\n",
    "        lifespans = np.random.weibull(beta, self.number_of_panels) * self.phi\n",
    "        lifespans = np.where(active_panels, lifespans, 0)  # Apply lifespan only to active panels\n",
    "\n",
    "        # Adjust survival times based on episode length\n",
    "        self.survival[:self.number_of_panels] = np.where(\n",
    "            active_panels,\n",
    "            np.abs(lifespans.astype(int)) + np.abs(self.episode_len - 25),\n",
    "            self.survival[:self.number_of_panels]\n",
    "        )\n",
    "\n",
    "        return self.survival\n",
    "\n",
    "    def calculate_FiT(self, episodes, import_price):\n",
    "            \n",
    "        self.FiT = import_price\n",
    "            \n",
    "        if episodes == 25:\n",
    "            self.FiT = self.FiT\n",
    "            \n",
    "        elif episodes == 24 or episodes == 23:\n",
    "            self.FiT = self.FiT * 0.64\n",
    "            \n",
    "        elif episodes == 22:\n",
    "            self.FiT = self.FiT * 0.46\n",
    "            \n",
    "        elif episodes == 21:\n",
    "            self.FiT = self.FiT * 0.55\n",
    "            \n",
    "        elif episodes < 20:\n",
    "            self.FiT = self.FiT * 0.33\n",
    "            \n",
    "        elif episodes == 20:\n",
    "            self.FiT = self.FiT * 0.37\n",
    "            \n",
    "        return self.FiT\n",
    "                        \n",
    "    def step(self, action):\n",
    "        \n",
    "        \"\"\"\n",
    "        defines actions, reward etc.\n",
    "        \"\"\"\n",
    "        \n",
    "        # RESET THE ANNUAL BALANCES\n",
    "        self.total_CAPEX = 0\n",
    "        self.pv_costs = 0\n",
    "        self.fin_balance = 0\n",
    "        self.env_balance = 0\n",
    "        self.number_installed = 0\n",
    "        current_penalty = 0\n",
    "        self.other_costs = 0\n",
    "        next_step_penalty = 0\n",
    "        self.step_total_interest = self.step_total_interest * self.normal_interest_rate\n",
    "        current_operational_costs = self.operational_cost * self.step_total_interest\n",
    "        \n",
    "        \n",
    "        self.cost_per_Wp = self.random_cost_per_Wp[abs(self.episode_len - 25)]\n",
    "        self.import_price = self.random_import_price[abs(self.episode_len - 25)]\n",
    "        self.efficency_develop = self.random_efficency_develop[abs(self.episode_len - 25)]\n",
    "        self.grid_factor = self.random_grid_factor[abs(self.episode_len - 25)]\n",
    "        self.step_pv_emission = (self.pv_emission[abs(self.episode_len - 25)] * self.efficency_develop)\n",
    "        self.panel_cost_and_inverter = self.calculate_panel_inv_cost(self.cost_per_Wp)\n",
    "        FiT = self.calculate_FiT(self.episode_len, self.import_price)\n",
    "        \n",
    "        reward = 0   \n",
    "        \n",
    "        # Find indices of the lowest 'action' values in previous_observation\n",
    "        indices_0 = np.argsort(self.previous_observation[:(self.number_of_panels // 2)])[:action[0]]\n",
    "        indices_1 = np.argsort(self.previous_observation[(self.number_of_panels // 2):self.number_of_panels])[:action[1]]\n",
    "\n",
    "        indices = np.concatenate([indices_0, indices_1 + (self.number_of_panels // 2)])\n",
    "        \n",
    "        # Replace these indices in the observation with efficiency_develop\n",
    "        self.observation[:self.number_of_panels][indices] = self.efficency_develop\n",
    "        \n",
    "        # Copy over the other values from previous_observation to observation\n",
    "        mask = np.ones(len(self.previous_observation[:self.number_of_panels]), dtype=bool)\n",
    "        mask[indices] = False\n",
    "        self.observation[:self.number_of_panels][mask] = self.previous_observation[:self.number_of_panels][mask]\n",
    "\n",
    "        replaced_panels = np.zeros(len(self.previous_observation[:self.number_of_panels]), dtype=int)\n",
    "        replaced_panels[indices] = 1\n",
    "\n",
    "        instaltion = (self.observation[:self.number_of_panels] > 0).astype(int)\n",
    "        self.pv_costs -= instaltion.sum() * current_operational_costs\n",
    "\n",
    "        actions_step = np.array(replaced_panels)\n",
    "        \n",
    "        action = action[0] + action[1]\n",
    "\n",
    "            \n",
    "        if action > 0:\n",
    "            step_CAPEX, panel_cost_and_inverter = self.calculate_total_CAPEX(actions_step, self.panel_cost_and_inverter)\n",
    "            self.pv_costs -= step_CAPEX\n",
    "            \n",
    "        else:\n",
    "            panel_cost_and_inverter = 0\n",
    "                \n",
    "        next_observation = self._get_obs()\n",
    "\n",
    "        # Calculate the Reslae value\n",
    "        resale = self.calculate_resale(panel_cost_and_inverter, indices) #  ***\n",
    "        \n",
    "        self.pv_costs += resale\n",
    "        \n",
    "        # CALCULATE THE BUDGET INTEREST\n",
    "        current_penalty, due_loans, next_step_penalty = self.calculate_penalty(self.episode_len, self.pv_costs)\n",
    "\n",
    "        # CALCULATE THE ENERGY YIELD\n",
    "        exported_revenue, AC_OUTPUT_tot, AC_for_env, minimised_revenue = self.calculate_import_export(self.elec_df, FiT, self.import_price)        \n",
    "        \n",
    "        # CALCULATE STEP EMISSIONS\n",
    "        self.env_balance = self.emission_balance(AC_for_env, self.grid_factor, self.step_pv_emission, actions_step)\n",
    "\n",
    "        self.env_balance_tot += self.env_balance \n",
    "        \n",
    "        pv_costs_observation = - self.pv_costs / 10000\n",
    "        self.observation[self.number_of_panels + 4] = pv_costs_observation\n",
    "        \n",
    "        next_step_penalty_observation = - next_step_penalty / 8000\n",
    "        self.observation[self.number_of_panels + 5] = next_step_penalty_observation\n",
    "        \n",
    "        \n",
    "        # CALCULATE STEP BALANCES\n",
    "        self.fin_balance += self.pv_costs\n",
    "        self.fin_balance += current_penalty\n",
    "        self.fin_balance += float(exported_revenue + minimised_revenue)\n",
    "        \n",
    "        # CALCULATE TOTAL BALANCES\n",
    "        self.fin_balance_tot += self.fin_balance                \n",
    "        \n",
    "        # SUBSTRACT 1 FOR TIMESTEP\n",
    "        self.episode_len -= 1\n",
    "        done = self.episode_len <= 0\n",
    "        \n",
    "        fin_mean = -2331\n",
    "        fin_stdev = 1634\n",
    "        \n",
    "        env_mean = -5169\n",
    "        st_dev = 3429\n",
    "        \n",
    "        reward = ((self.fin_balance - fin_mean) / fin_stdev) + ((self.env_balance - env_mean) / st_dev)\n",
    "        \n",
    "        # FAILURE\n",
    "        self.broke = np.zeros(self.number_of_panels, dtype=np.float32)\n",
    "        survival = self.failure(actions_step)\n",
    "        \n",
    "        for c, p in enumerate(survival):\n",
    "            \n",
    "            if c < self.number_of_panels:\n",
    "\n",
    "                if p - 1 <= abs(self.episode_len - 24):\n",
    "                    self.broke[c] = 1\n",
    "                    self.observation[c] = 0\n",
    "        \n",
    "        # DEGRADATION RATE\n",
    "        # Applying degradation only to panels that are operational (above 0.1 efficiency)\n",
    "        active_panels = self.observation[:self.number_of_panels] > 0.1\n",
    "        degradations = np.random.normal(self.deg_mu, self.deg_std, size=self.number_of_panels) / 100\n",
    "        self.observation[:self.number_of_panels][active_panels] -= degradations[active_panels]\n",
    "        \n",
    "        if not done: \n",
    "        \n",
    "            self.next_cost_per_Wp = self.random_cost_per_Wp[abs(self.episode_len - 25)]\n",
    "            self.next_import_price = self.random_import_price[abs(self.episode_len - 25)]\n",
    "            self.next_efficency_develop = self.random_efficency_develop[abs(self.episode_len - 25)]\n",
    "            self.next_grid_factor = self.random_grid_factor[abs(self.episode_len - 25)]\n",
    "            next_FIT = self.calculate_FiT(self.episode_len, self.next_import_price)\n",
    "        \n",
    "            price_observation = (self.next_import_price - 0.00022499) / (0.0020798 - 0.00022499)\n",
    "            self.observation[self.number_of_panels] = price_observation\n",
    "\n",
    "            FiT_observation = (next_FIT - 0.00022499 * 0.33) / (0.0020798 - 0.00022499 * 0.33)\n",
    "            self.observation[self.number_of_panels + 1] = FiT_observation\n",
    "\n",
    "            eff_observation = (self.next_efficency_develop - 0.999) / (1.156 - 0.999)\n",
    "            self.observation[self.number_of_panels + 2] = eff_observation\n",
    "            \n",
    "            cost_per_Wp_observation = (self.cost_per_Wp_df_at_zero - self.cost_per_Wp_df.min().min()) / (self.cost_per_Wp_df.max().max() - self.cost_per_Wp_df.min().min())\n",
    "            self.observation[self.number_of_panels + 3] = cost_per_Wp_observation\n",
    "            \n",
    "            grid_factor_observation = (self.next_grid_factor - 0.553) / (0.553 - 0.00022499)\n",
    "\n",
    "            self.observation[self.number_of_panels + 7] = grid_factor_observation\n",
    "        \n",
    "        info = {\"step financial balance (eur):\": self.fin_balance,\n",
    "               \"total financial balance: (eur)\": self.fin_balance_tot,\n",
    "               \"internal rate of return\": 0,\n",
    "               \"current_interest\": reward,\n",
    "                \"net present value\": (self.env_balance - env_mean) / st_dev}\n",
    "         \n",
    "        \n",
    "        self.previous_observation = self.observation.copy()\n",
    "        \n",
    "        return self.observation, reward, done, False, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff95454",
   "metadata": {
    "code_folding": [
     0,
     50,
     54,
     157,
     169,
     183,
     191,
     212,
     257,
     309,
     463
    ]
   },
   "outputs": [],
   "source": [
    "class TestEnvironment(gym.Env):\n",
    "    def __init__(self, PV_90_arr, PV_270_arr, elec_consum_arr, import_price_rate, import_tariff, efficency, CAPEX, \n",
    "                 GRID_FACTOR, pv_co2_arr):\n",
    "        \n",
    "        # Price per watthour\n",
    "        self.import_price_df = import_tariff\n",
    "        self.import_price_at_zero = np.float32(0.00035)\n",
    "        self.import_price_rate = import_price_rate\n",
    "        \n",
    "        # Energy Balance\n",
    "        self.PV_90_arr = PV_90_arr\n",
    "        self.PV_270_arr = PV_270_arr\n",
    "        self.elec_df = elec_consum_arr\n",
    "        self.max_export = 4000\n",
    "        self.number_of_panels = 32\n",
    "        \n",
    "        # Degradation\n",
    "        self.deg_mu = 0.82 # Trina: 1.19, JA: 0.82, Maxeon: 0.67\n",
    "        self.deg_std = 0.555 \n",
    "        self.phi = 30 # Trina: 15, JA: 30, Maxeon: 50\n",
    "        \n",
    "        # Efficency Development\n",
    "        self.efficency_develop_df = efficency\n",
    "        self.efficency_at_zero = 1.0\n",
    "        \n",
    "        # Costs\n",
    "        self.power_at_zero = 415  # Trina: 265, JA: 415, Maxeon: 435\n",
    "        self.cost_per_Wp_df_at_zero = 0.69 # Trina: 0.36, JA: 0.69, Maxeon: 1.58\n",
    "        self.cost_per_Wp_df = CAPEX\n",
    "        self.initial_other_costs = 150\n",
    "        \n",
    "        self.operational_cost = 16.8\n",
    "        \n",
    "        self.loan_interest_rate = 1.10\n",
    "        self.normal_interest_rate = 1.02\n",
    "        \n",
    "        self.low_budget = 0 # Low budget: 0, High Budget: 750\n",
    "        self.high_budget = 750 # Low budget: 750, High Budget: 2000\n",
    "                        \n",
    "        # Spaces and length\n",
    "        self.action_space = spaces.MultiDiscrete([self.number_of_panels // 2, self.number_of_panels // 2])\n",
    "        self.observation_space = spaces.Box(0, 1.25, shape=(self.number_of_panels + 8,))\n",
    "        self.episode_len = 25\n",
    "        self.months_per_timestep = 12\n",
    "        \n",
    "        # Emission\n",
    "        self.grid_factor_df = GRID_FACTOR #****\n",
    "        self.grid_factor_at_zero = 0.553 \n",
    "        self.pv_emission = pv_co2_arr * self.power_at_zero\n",
    "        \n",
    "    def _get_obs(self):\n",
    "        \n",
    "        return self.observation\n",
    "    \n",
    "    def calculate_import_export(self, elec_df, export_price, import_price):\n",
    "        \n",
    "        \"\"\"\n",
    "        Calculate the annual Wh of energy exported to the grid (exported) and saved (minimised)\n",
    "        \"\"\"\n",
    "        \n",
    "        PV_90_tot = self._get_obs()[0:self.number_of_panels // 2].sum() * self.PV_90_arr \n",
    "        PV_270_tot = self._get_obs()[(self.number_of_panels // 2) : self.number_of_panels].sum() * self.PV_270_arr \n",
    "        \n",
    "        AC_OUTPUT_tot = PV_90_tot + PV_270_tot\n",
    "\n",
    "        exported = (AC_OUTPUT_tot - self.elec_df).clip(min=0, max = self.max_export)  \n",
    "        excess_energy = (AC_OUTPUT_tot - self.elec_df - self.max_export).clip(min=0)\n",
    "        \n",
    "        export_revenue = (export_price * exported).sum()\n",
    "\n",
    "        \n",
    "        minimised = AC_OUTPUT_tot - exported \n",
    "        minimised_revenue = (minimised * (self.import_price_rate * import_price)).sum()\n",
    "        \n",
    "        AC_for_env = AC_OUTPUT_tot - excess_energy\n",
    "\n",
    "        return export_revenue, AC_OUTPUT_tot, AC_for_env, minimised_revenue\n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Reset the environment to the original state at t=1\n",
    "        \"\"\"\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            \n",
    "        # Panels\n",
    "        self.init_obs = np.random.uniform(0, 1, size=self.number_of_panels).astype(np.float32)\n",
    "        self.init_obs = np.where(self.init_obs < 0.5, 0.0, np.random.uniform(0.85, 1.0, size=self.number_of_panels))\n",
    "\n",
    "        # Combine all initialization into a single step for efficiency\n",
    "        self.import_price_at_zero_norm = (self.import_price_at_zero - self.import_price_df.min().min()) / (self.import_price_df.max().max() - self.import_price_df.min().min())\n",
    "        self.FiT_at_zero_norm = (self.import_price_at_zero - self.import_price_df.min().min() * 0.33) / (self.import_price_df.max().max() - self.import_price_df.min().min() * 0.33)\n",
    "        self.efficency_at_zero_norm = (self.efficency_at_zero - 0.999) / (1.156 - 0.999)\n",
    "        self.panel_cost_and_inverter_at_zero_norm = (self.cost_per_Wp_df_at_zero - self.cost_per_Wp_df.min().min()) / (self.cost_per_Wp_df.max().max() - self.cost_per_Wp_df.min().min())\n",
    "        \n",
    "        self.grid_factor_at_zero_norm = (self.grid_factor_at_zero + 0.05319002) / (0.55762151 + 0.05319002)\n",
    "        \n",
    "        self.current_budget_constraint = np.random.randint(self.low_budget, self.high_budget)\n",
    "        self.next_step_budget_constraint = 0\n",
    "        \n",
    "        \n",
    "        # Complete observation initialization in one go\n",
    "        self.observation = np.concatenate([\n",
    "            self.init_obs,\n",
    "            [self.import_price_at_zero_norm, self.FiT_at_zero_norm, self.efficency_at_zero_norm, \n",
    "             self.panel_cost_and_inverter_at_zero_norm, 0., 0., 0., self.grid_factor_at_zero_norm]\n",
    "        ]).astype(np.float32) #***\n",
    "\n",
    "        self.previous_observation = self.observation.copy()\n",
    "\n",
    "        # RANDOM IMPORT PRICE\n",
    "        self.random_import_price = self.import_price_df[np.random.choice(self.import_price_df.shape[0])] \n",
    "\n",
    "        # RANDOM EFFICENCY\n",
    "        self.random_efficency_develop = self.efficency_develop_df[np.random.choice(self.efficency_develop_df.shape[0])]   \n",
    "        \n",
    "        # RANDOM COST PER WP\n",
    "        self.random_cost_per_Wp = self.cost_per_Wp_df[np.random.choice(self.cost_per_Wp_df.shape[0])]   \n",
    "        \n",
    "        # RANDOM Grid Factor\n",
    "        self.random_grid_factor = self.grid_factor_df[np.random.choice(self.grid_factor_df.shape[0])]   #***\n",
    "        \n",
    "        self.episode_len = 25  \n",
    "    \n",
    "        info = {}\n",
    "        \n",
    "        # RESET BALANCES\n",
    "        self.fin_balance_tot = 0\n",
    "        self.reward_tot = 0\n",
    "        self.env_balance_tot = 0\n",
    "        self.produced = 0\n",
    "        self.other_costs = 0\n",
    "        self.FiT = 0.0004\n",
    "        self.next_FiT = 0.0004\n",
    "        self.resale_values = array_of_zeros = np.zeros(self.number_of_panels, dtype=np.float32)\n",
    "        \n",
    "        self.broke = np.zeros(self.number_of_panels, dtype=np.float32)\n",
    "        self.total_cash_flow = []\n",
    "        self.annual_cash_flow = 0\n",
    "                \n",
    "        self.due_loans = [0, 0, 0, 0] \n",
    "        self.current_interest = 0\n",
    "        self.step_total_interest = 1\n",
    "        \n",
    "        self.two_year_ago_interest = 0\n",
    "        self.first_year_interest = []\n",
    "        self.second_year_interest = [0]\n",
    "        self.third_year_interest = [0, 0]\n",
    "        self.fourth_year_interest = [0, 0, 0]\n",
    "        self.next_year_total = 0\n",
    "        \n",
    "        self.survival = np.zeros(self.number_of_panels, dtype=np.float32)\n",
    "    \n",
    "        return self.observation, info\n",
    "    \n",
    "    def emission_balance(self, pv_production, grid_factor, panel_emission, action_step):\n",
    "        \n",
    "        curtailed = (pv_production.sum() * grid_factor)/1000\n",
    "        \n",
    "        number_installed = int(np.sum(action_step))\n",
    "        \n",
    "        panel_emission_tot = number_installed * panel_emission\n",
    "        \n",
    "        emission_balance = curtailed - panel_emission_tot\n",
    "        \n",
    "        return emission_balance \n",
    "    \n",
    "    def calculate_resale(self, initial_panel_cost, indices):\n",
    "        \n",
    "        self.resale_values[indices] = initial_panel_cost\n",
    "        \n",
    "        self.resale_values = self.resale_values * 0.85\n",
    "        \n",
    "        for count, i in enumerate(self.broke):\n",
    "            if i == 1:\n",
    "                self.resale_values[count] = 0\n",
    "        \n",
    "        resale_step = self.resale_values[indices].sum()\n",
    "        \n",
    "        return resale_step\n",
    "    \n",
    "    def calculate_panel_inv_cost(self, cost_per_Wp):\n",
    "        \n",
    "        PW_ep = self.efficency_develop * self.power_at_zero\n",
    "        \n",
    "        panel_cost_and_inverter = PW_ep * cost_per_Wp\n",
    "        \n",
    "        return panel_cost_and_inverter\n",
    "    \n",
    "    def calculate_irr_and_npv(self, pv_cost, minimised_revenue, export_revenue, penalty):\n",
    "                \n",
    "        \"\"\"\n",
    "        Calculates total cash flow of the project needed for the internal rate of return\n",
    "        \"\"\" \n",
    "        self.expences = 0\n",
    "        self.annual_cash_flow = 0\n",
    "        initial_cost = 0\n",
    "        \n",
    "        self.expences = pv_cost\n",
    "        self.annual_cash_flow = self.expences + export_revenue + minimised_revenue + penalty\n",
    "        initial_cost_q, x = self.calculate_total_CAPEX(self.init_obs, self.panel_cost_and_inverter)\n",
    "        #initial_cost = - initial_cost_q\n",
    "        \n",
    "        if self.episode_len == 24:\n",
    "            self.total_cash_flow.append(initial_cost + self.annual_cash_flow) \n",
    "        else:\n",
    "            self.total_cash_flow.append(self.annual_cash_flow) \n",
    "        \n",
    "        return self.total_cash_flow\n",
    "        \n",
    "    def calculate_penalty(self, current_step, annual_expense):\n",
    "              \n",
    "        year = 25 - current_step\n",
    "        \n",
    "        if year > 0:\n",
    "            self.current_budget_constraint = self.next_step_budget_constraint    \n",
    "            \n",
    "        \n",
    "        self.current_interest = self.next_year_total\n",
    "        annual_expense = (-annual_expense)\n",
    "        value = 0 \n",
    "        loan = 0\n",
    "        annual_interest = 0\n",
    "\n",
    "        if annual_expense > self.current_budget_constraint:\n",
    "            loan = (self.current_budget_constraint - annual_expense)\n",
    "            value = annual_expense / self.current_budget_constraint\n",
    "            periods = 2 if value < 2 else 3 if value < 3 else 4\n",
    "\n",
    "            annual_interest = loan / periods\n",
    "            interest_multiplier = 1\n",
    "\n",
    "            for i in range(4):\n",
    "                if i < periods:\n",
    "                    self.due_loans[i] = annual_interest * interest_multiplier\n",
    "                    interest_multiplier *= self.loan_interest_rate\n",
    "                else:\n",
    "                    self.due_loans[i] = 0\n",
    "        else:\n",
    "             self.due_loans = [0, 0, 0, 0]\n",
    "    \n",
    "        self.first_year_interest.append(self.due_loans[0])\n",
    "        self.second_year_interest.append(self.due_loans[1])\n",
    "        self.third_year_interest.append(self.due_loans[2])\n",
    "        self.fourth_year_interest.append(self.due_loans[3])\n",
    "    \n",
    "    \n",
    "        self.next_year_total = self.first_year_interest[year] + self.second_year_interest[year] + self.third_year_interest[year] + self.fourth_year_interest[year]\n",
    "        \n",
    "        self.next_step_budget_constraint = np.random.randint(750, 2000) * self.step_total_interest\n",
    "        current_budget_observation = (self.next_step_budget_constraint - 750 * self.step_total_interest) / (2000 * self.step_total_interest - 750 * self.step_total_interest) \n",
    "        self.observation[self.number_of_panels + 6] = current_budget_observation\n",
    "                \n",
    "        return self.current_interest, self.due_loans, self.next_year_total\n",
    "        \n",
    "    def calculate_total_CAPEX(self, action_step, panel_cost_and_inverter):\n",
    "        \"\"\"\n",
    "        Calculate CAPEX each step in a vectorized manner.\n",
    "        \"\"\"\n",
    "        BOS = panel_cost_and_inverter * 0.55\n",
    "        number_installed = int(np.sum(action_step))\n",
    "\n",
    "        # Calculate costs from module and inverter\n",
    "        panel_cost_and_inverter_step = panel_cost_and_inverter * number_installed\n",
    "\n",
    "        # Calculate other installation costs\n",
    "        if number_installed == 0:\n",
    "            other_costs = 0\n",
    "        elif number_installed == 1:\n",
    "            other_costs = self.initial_other_costs * self.step_total_interest\n",
    "        else:\n",
    "            discounts = 0.9 ** np.arange(number_installed)\n",
    "            other_costs = (self.initial_other_costs * self.step_total_interest * discounts).sum()\n",
    "\n",
    "        # Calculate BOS costs using vector operations\n",
    "        is_new_installation = (self.previous_observation[:number_installed] == 0) & (action_step[:number_installed] == 1)\n",
    "        is_replacement = (self.previous_observation[:number_installed] > 0) & (action_step[:number_installed] == 1)\n",
    "        BOS_cost = np.sum(BOS * is_new_installation) + np.sum((BOS / 2) * is_replacement)\n",
    "\n",
    "        # Sum total CAPEX\n",
    "        total_CAPEX = panel_cost_and_inverter_step + BOS_cost + other_costs\n",
    "\n",
    "        return total_CAPEX, panel_cost_and_inverter\n",
    "        \n",
    "    def failure(self, actions):\n",
    "        \n",
    "        beta = 3  # Shape parameter\n",
    "\n",
    "        # Determine which panels are active based on the actions and previous observations.\n",
    "        if self.episode_len == 24:\n",
    "            active_panels = (self.observation[:self.number_of_panels] > 0.85)\n",
    "        else:\n",
    "            active_panels = (self.observation[:self.number_of_panels] == self.efficency_develop)\n",
    "\n",
    "        # Calculate lifespan for all active panels at once\n",
    "        lifespans = np.random.weibull(beta, self.number_of_panels) * self.phi\n",
    "        lifespans = np.where(active_panels, lifespans, 0)  # Apply lifespan only to active panels\n",
    "\n",
    "        # Adjust survival times based on episode length\n",
    "        self.survival[:self.number_of_panels] = np.where(\n",
    "            active_panels,\n",
    "            np.abs(lifespans.astype(int)) + np.abs(self.episode_len - 25),\n",
    "            self.survival[:self.number_of_panels]\n",
    "        )\n",
    "\n",
    "        return self.survival\n",
    "\n",
    "    def calculate_FiT(self, episodes, import_price):\n",
    "            \n",
    "        self.FiT = import_price\n",
    "            \n",
    "        if episodes == 25:\n",
    "            self.FiT = self.FiT\n",
    "            \n",
    "        elif episodes == 24 or episodes == 23:\n",
    "            self.FiT = self.FiT * 0.64\n",
    "            \n",
    "        elif episodes == 22:\n",
    "            self.FiT = self.FiT * 0.46\n",
    "            \n",
    "        elif episodes == 21:\n",
    "            self.FiT = self.FiT * 0.55\n",
    "            \n",
    "        elif episodes < 20:\n",
    "            self.FiT = self.FiT * 0.33\n",
    "            \n",
    "        elif episodes == 20:\n",
    "            self.FiT = self.FiT * 0.37\n",
    "            \n",
    "        return self.FiT\n",
    "                        \n",
    "    def step(self, action):\n",
    "        \n",
    "        \"\"\"\n",
    "        defines actions, reward etc.\n",
    "        \"\"\"\n",
    "        \n",
    "        # RESET THE ANNUAL BALANCES\n",
    "        self.total_CAPEX = 0\n",
    "        self.pv_costs = 0\n",
    "        self.fin_balance = 0\n",
    "        self.env_balance = 0\n",
    "        self.number_installed = 0\n",
    "        irr_fin = 0\n",
    "        npv_fin = 0\n",
    "        current_penalty = 0\n",
    "        self.other_costs = 0\n",
    "        next_step_penalty = 0\n",
    "        self.step_total_interest = self.step_total_interest * self.normal_interest_rate\n",
    "        current_operational_costs = self.operational_cost * self.step_total_interest\n",
    "        \n",
    "        \n",
    "        self.cost_per_Wp = self.random_cost_per_Wp[abs(self.episode_len - 25)]\n",
    "        self.import_price = self.random_import_price[abs(self.episode_len - 25)]\n",
    "        self.efficency_develop = self.random_efficency_develop[abs(self.episode_len - 25)]\n",
    "        self.grid_factor = self.random_grid_factor[abs(self.episode_len - 25)]\n",
    "        self.step_pv_emission = (self.pv_emission[abs(self.episode_len - 25)] * self.efficency_develop)\n",
    "           \n",
    "        self.panel_cost_and_inverter = self.calculate_panel_inv_cost(self.cost_per_Wp)\n",
    "        FiT = self.calculate_FiT(self.episode_len, self.import_price)\n",
    "        \n",
    "        reward = 0   \n",
    "        \n",
    "        # Find indices of the lowest 'action' values in previous_observation\n",
    "        indices_0 = np.argsort(self.previous_observation[:(self.number_of_panels // 2)])[:action[0]]\n",
    "        indices_1 = np.argsort(self.previous_observation[(self.number_of_panels // 2):self.number_of_panels])[:action[1]]\n",
    "\n",
    "        indices = np.concatenate([indices_0, indices_1 + (self.number_of_panels // 2)])\n",
    "        \n",
    "        # Replace these indices in the observation with efficiency_develop\n",
    "        self.observation[:self.number_of_panels][indices] = self.efficency_develop\n",
    "\n",
    "        # Copy over the other values from previous_observation to observation\n",
    "        mask = np.ones(len(self.previous_observation[:self.number_of_panels]), dtype=bool)\n",
    "        mask[indices] = False\n",
    "        self.observation[:self.number_of_panels][mask] = self.previous_observation[:self.number_of_panels][mask]\n",
    "\n",
    "        replaced_panels = np.zeros(len(self.previous_observation[:self.number_of_panels]), dtype=int)\n",
    "        replaced_panels[indices] = 1\n",
    "\n",
    "        instaltion = (self.observation[:self.number_of_panels] > 0).astype(int)\n",
    "        self.pv_costs -= instaltion.sum() * current_operational_costs\n",
    "\n",
    "        actions_step = np.array(replaced_panels)\n",
    "\n",
    "        action = action[0] + action[1]\n",
    "        \n",
    "        if action > 0:\n",
    "            step_CAPEX, panel_cost_and_inverter = self.calculate_total_CAPEX(actions_step, self.panel_cost_and_inverter)\n",
    "            self.pv_costs -= step_CAPEX\n",
    "            \n",
    "        else:\n",
    "            panel_cost_and_inverter = 0\n",
    "                \n",
    "        next_observation = self._get_obs()\n",
    "\n",
    "        # Calculate the Reslae value\n",
    "        resale = self.calculate_resale(panel_cost_and_inverter, indices) #  ***\n",
    "        \n",
    "        self.pv_costs += resale\n",
    "\n",
    "        \n",
    "        # CALCULATE THE BUDGET INTEREST\n",
    "        current_penalty, due_loans, next_step_penalty = self.calculate_penalty(self.episode_len, self.pv_costs)\n",
    "        \n",
    "        \n",
    "        # CALCULATE THE ENERGY YIELD\n",
    "        exported_revenue, AC_OUTPUT_tot, AC_for_env, minimised_revenue = self.calculate_import_export(self.elec_df, FiT, self.import_price)        \n",
    "        \n",
    "        \n",
    "        # CALCULATE STEP EMISSIONS\n",
    "        self.env_balance = self.emission_balance(AC_for_env, self.grid_factor, self.step_pv_emission, actions_step)\n",
    "        \n",
    "        self.env_balance_tot += self.env_balance\n",
    "        \n",
    "        pv_costs_observation = - self.pv_costs / 10000\n",
    "        self.observation[self.number_of_panels + 4] = pv_costs_observation\n",
    "        \n",
    "        next_step_penalty_observation = - next_step_penalty / 8000\n",
    "        self.observation[self.number_of_panels + 5] = next_step_penalty_observation\n",
    "        \n",
    "        # CALCULATE STEP BALANCES\n",
    "        self.fin_balance += self.pv_costs\n",
    "        self.fin_balance += current_penalty\n",
    "        self.fin_balance += float(exported_revenue + minimised_revenue)\n",
    "        \n",
    "        # CALCULATE TOTAL BALANCES\n",
    "        self.fin_balance_tot += self.fin_balance                \n",
    "        \n",
    "        # SUBSTRACT 1 FOR TIMESTEP\n",
    "        self.episode_len -= 1\n",
    "        done = self.episode_len <= 0\n",
    "        \n",
    "        # CALCULATE IRR, NPV AND CARBON INTENSITY\n",
    "        total_cash_flow = self.calculate_irr_and_npv(self.pv_costs, exported_revenue, minimised_revenue, current_penalty)\n",
    "        irr = npf.irr(total_cash_flow) * 100\n",
    "        npv = npf.npv(0.04 ,total_cash_flow)\n",
    "            \n",
    "        # RETURNS AND CALCULATE REWARD\n",
    "        if self.episode_len == 0:\n",
    "            irr_fin = irr\n",
    "            npv_fin = npv\n",
    "        \n",
    "        fin_mean = -2331\n",
    "        fin_stdev = 1634\n",
    "        \n",
    "        env_mean = -5169\n",
    "        st_dev = 3429\n",
    "        \n",
    "        reward = ((self.fin_balance - fin_mean) / fin_stdev) + ((self.env_balance - env_mean) / st_dev)\n",
    "        #reward = self.fin_balance_tot / 1000 if done else 0\n",
    "        \n",
    "        # FAILURE\n",
    "         \n",
    "        survival = self.failure(actions_step)\n",
    "        self.broke = np.zeros(self.number_of_panels, dtype=np.float32)\n",
    "\n",
    "        for c, p in enumerate(survival):\n",
    "            \n",
    "            if c < self.number_of_panels:\n",
    "\n",
    "                if p - 1 <= abs(self.episode_len - 24):\n",
    "                    self.broke[c] = 1\n",
    "\n",
    "                    self.observation[c] = 0\n",
    "        \n",
    "        # DEGRADATION RATE\n",
    "        # Applying degradation only to panels that are operational (above 0.1 efficiency)\n",
    "        active_panels = self.observation[:self.number_of_panels] > 0.1\n",
    "        degradations = np.random.normal(self.deg_mu, self.deg_std, size=self.number_of_panels) / 100\n",
    "        self.observation[:self.number_of_panels][active_panels] -= degradations[active_panels]\n",
    "        \n",
    "        if not done: \n",
    "        \n",
    "            self.next_cost_per_Wp = self.random_cost_per_Wp[abs(self.episode_len - 25)]\n",
    "            self.next_import_price = self.random_import_price[abs(self.episode_len - 25)]\n",
    "            self.next_efficency_develop = self.random_efficency_develop[abs(self.episode_len - 25)]\n",
    "            self.next_grid_factor = self.random_grid_factor[abs(self.episode_len - 25)]\n",
    "            next_FIT = self.calculate_FiT(self.episode_len, self.next_import_price)\n",
    "        \n",
    "            price_observation = (self.next_import_price - 0.00022499) / (0.0020798 - 0.00022499)\n",
    "            self.observation[self.number_of_panels] = price_observation\n",
    "\n",
    "            FiT_observation = (next_FIT - 0.00022499 * 0.33) / (0.0020798 - 0.00022499 * 0.33)\n",
    "            self.observation[self.number_of_panels + 1] = FiT_observation\n",
    "\n",
    "            eff_observation = (self.next_efficency_develop - 0.999) / (1.156 - 0.999)\n",
    "            self.observation[self.number_of_panels + 2] = eff_observation\n",
    "\n",
    "            cost_per_Wp_observation = (self.cost_per_Wp_df_at_zero - self.cost_per_Wp_df.min().min()) / (self.cost_per_Wp_df.max().max() - self.cost_per_Wp_df.min().min())\n",
    "            self.observation[self.number_of_panels + 3] = cost_per_Wp_observation\n",
    "            \n",
    "            grid_factor_observation = (self.next_grid_factor - 0.553) / (0.553 - 0.00022499)\n",
    "\n",
    "            self.observation[self.number_of_panels + 7] = grid_factor_observation\n",
    "\n",
    "        \n",
    "        \n",
    "        info = {\"step financial balance (eur):\": self.env_balance,\n",
    "               \"total financial balance: (eur)\": self.fin_balance_tot,\n",
    "               \"total environmental balance: (kgco2)\": self.env_balance_tot,\n",
    "               \"current_interest\": current_penalty,\n",
    "                \"finbalance\": self.env_balance,\n",
    "               \"reward\": npv_fin}\n",
    "         \n",
    "        \n",
    "        self.previous_observation = self.observation.copy()\n",
    "        \n",
    "        return self.observation, reward, done, False, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18c69028",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "env = TrainEnvironment(JA_60_arr, JA_240_arr, elec_consum_arr, import_price_rate, import_price_train_arr, Eff_train_arr, \n",
    "                       CAPEX_JA_train_arr, grid_factor_test_arr, pv_co2_arr)\n",
    "env_test = TestEnvironment(JA_60_arr, JA_240_arr, elec_consum_arr, import_price_rate, import_price_test_arr, Eff_test_arr, \n",
    "                           CAPEX_JA_test_arr, grid_factor_train_arr, pv_co2_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60c5c35c",
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "#check_env(env)\n",
    "def test4(episodes, environment):    \n",
    "    for episode in range(episodes):\n",
    "        done = False\n",
    "        obs = environment.reset()\n",
    "        step = 0\n",
    "        print(obs, \"\\n\")\n",
    "        while not done:\n",
    "            step += 1\n",
    "            random_action = environment.action_space.sample()\n",
    "            obs, reward, done, trun, info = environment.step(random_action)\n",
    "            \n",
    "            \n",
    "            # Extracting the 2nd and 3rd key-value pairs\n",
    "            keys = list(info.keys())\n",
    "            values = list(info.values())\n",
    "\n",
    "            # Getting the 2nd key-value pair\n",
    "            zeroth_key = keys[4]\n",
    "            zeroth_value = values[4]\n",
    "\n",
    "            # Getting the 3rd key-value pair\n",
    "\n",
    "            sixth_key = keys[3]\n",
    "            sixth_value = values[3]\n",
    "            \n",
    "            print(\"STEP:\", step)\n",
    "            print(\"ACT\",\"\\n\",  random_action)\n",
    "            print(\"OBS\",\"\\n\",  obs)\n",
    "            print(zeroth_key, zeroth_value, sixth_key, sixth_value)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4903b5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.        , 0.9643404 , 0.9753191 , 0.8551375 , 0.        ,\n",
      "       0.9549957 , 0.        , 0.        , 0.9190497 , 0.9455148 ,\n",
      "       0.920098  , 0.91300225, 0.        , 0.        , 0.94720644,\n",
      "       0.        , 0.9189833 , 0.        , 0.9150068 , 0.8622742 ,\n",
      "       0.94984674, 0.8981805 , 0.93276334, 0.        , 0.9551914 ,\n",
      "       0.9876699 , 0.        , 0.9773744 , 0.        , 0.        ,\n",
      "       0.9175955 , 0.99942166, 0.06935652, 0.11512984, 0.00636943,\n",
      "       0.7395664 , 0.        , 0.        , 0.        , 0.99243385],\n",
      "      dtype=float32), {}) \n",
      "\n",
      "STEP: 1\n",
      "ACT \n",
      " [13 14]\n",
      "OBS \n",
      " [ 0.9976064   0.96572536  0.963991    0.9934892   0.9910786   0.94208837\n",
      "  0.9899317   1.0096053   0.99065423  0.9949906   0.99297875  0.99364895\n",
      "  0.9907915   0.9889373   1.0031904   0.99982375  0.98327965  0.99042135\n",
      "  1.0026557   0.98551285  0.9971334   0.99377966  0.98982555  1.0008972\n",
      "  0.9969536   0.99066037  0.9859411   0.99634206  0.98629063  0.9921009\n",
      "  0.99130607  0.98348767  0.07068363  0.07661422  0.00636944  0.7395664\n",
      "  0.57477266  0.16836646  0.748      -0.06151076]\n",
      "net present value -2.1042674955249563 current_interest -1.6768110634310627\n",
      "\n",
      "\n",
      "STEP: 2\n",
      "ACT \n",
      " [2 1]\n",
      "OBS \n",
      " [ 0.9910546   0.9561474   1.0033572   0.9923225   0.9862826   0.9951949\n",
      "  0.9841298   0.9989648   0.9835018   0.985563    0.96817714  0.9901664\n",
      "  0.988897    0.9825199   0.9888918   0.98557866  0.9948676   0.9728821\n",
      "  0.990776    0.97438854  0.97992814  0.9904043   0.98111874  0.99067616\n",
      "  0.992665    0.9802882   0.97152835  0.98383343  0.9645364   0.98128295\n",
      "  0.9868281   0.98481     0.08242331  0.0835629   0.00636967  0.7395664\n",
      "  0.11914334  0.21100366  0.96       -0.14144094]\n",
      "net present value 2.5071508821177715 current_interest 4.305047324143184\n",
      "\n",
      "\n",
      "STEP: 3\n",
      "ACT \n",
      " [10  2]\n",
      "OBS \n",
      " [ 0.9804961   0.98642474  0.98934895  0.9824821   0.98394936  0.9978232\n",
      "  0.9982103   0.9839571   0.9919954   1.0021018   1.0032194   0.98373187\n",
      "  0.9880957   0.9854572   0.99043864  0.98825675  0.9832096   0.96937865\n",
      "  0.9785214   0.96043116  0.9809034   0.98056316  0.          0.9787071\n",
      "  0.9907845   0.9696241   1.0021265   0.9785919   0.98571354  0.96656114\n",
      "  0.98774403  0.9885393   0.09657122  0.05566767  0.0063697   0.7395664\n",
      "  0.2651693   0.29156044  0.456      -0.18649644]\n",
      "net present value 0.6912421496060731 current_interest 1.502792576126889\n",
      "\n",
      "\n",
      "STEP: 4\n",
      "ACT \n",
      " [ 0 13]\n",
      "OBS \n",
      " [ 0.97240084  0.97189826  0.9873433   0.97456616  0.9742693   0.9883832\n",
      "  0.9856252   0.9797984   0.98151016  0.9856217   0.9903309   0.9737225\n",
      "  0.98579735  0.97812295  0.9813664   0.9785039   0.9968633   0.98756325\n",
      "  0.98571193  0.98785955  0.986045    0.99320346  0.99261147  0.99273497\n",
      "  0.98017687  0.9944946   0.99487054  0.9860745   0.9908344   1.0030038\n",
      "  0.98392606  0.97326976  0.10067302  0.07588875  0.00641805  0.7395664\n",
      "  0.25125313  0.3878914   0.14266667 -0.27635393]\n",
      "net present value 0.4801268223302271 current_interest 0.7699299873174994\n",
      "\n",
      "\n",
      "STEP: 5\n",
      "ACT \n",
      " [4 4]\n",
      "OBS \n",
      " [ 0.99821603  0.9941445   0.98038095  0.96649444  0.98409426  0.98923373\n",
      "  0.9736475   0.97053283  0.9791074   0.97330856  0.9837934   0.9926767\n",
      "  0.97947586  0.9749953   0.9638729   0.9711947   0.985096    0.9760353\n",
      "  0.98817813  0.9956298   0.97745705  0.97744113  0.9793595   0.98612463\n",
      "  0.99180496  0.98509276  0.9870725   0.9749067   0.9905494   0.99666107\n",
      "  0.98068136  0.9922241   0.09558236  0.03719464  0.01986916  0.7395664\n",
      "  0.20759147  0.20708764  0.18266666 -0.31411928]\n",
      "net present value 1.2792433915769819 current_interest 1.5734228045190977\n",
      "\n",
      "\n",
      "STEP: 6\n",
      "ACT \n",
      " [12  7]\n",
      "OBS \n",
      " [ 0.99691     0.9912101   0.996527    0.99608934  0.99577725  0.9774219\n",
      "  0.9893009   0.99910575  0.99479485  0.98908174  0.9916363   0.9942043\n",
      "  0.99199     0.9990565   0.99567574  0.9926768   0.9781925   0.9917914\n",
      "  0.97688526  0.9831612   1.0013189   0.9894549   0.997936    0.97954625\n",
      "  0.98084337  0.9946144   0.9787642   0.99222374  0.9755364   0.9969751\n",
      "  0.9938476   0.97280973  0.08661866  0.02643569  0.01988502  0.7395664\n",
      "  0.37864438  0.3413959   0.48666668 -0.3572605 ]\n",
      "net present value -0.6927743634884833 current_interest -0.9483586570187655\n",
      "\n",
      "\n",
      "STEP: 7\n",
      "ACT \n",
      " [12 14]\n",
      "OBS \n",
      " [ 0.9926638   0.98140574  0.9865161   0.9970561   0.9937435   0.99100304\n",
      "  0.98730916  0.99341565  0.98884195  0.9893877   0.9925437   0.99836844\n",
      "  0.99414754  0.9863389   1.0016418   0.98715514  1.0033063   0.99724716\n",
      "  0.994389    1.0005329   0.9931217   0.9940237   0.9958396   0.9894117\n",
      "  0.9954746   0.98610824  0.99924487  0.9980189   0.99645     0.9862175\n",
      "  0.9837458   0.9869119   0.09705204  0.02961992  0.02045224  0.7395664\n",
      "  0.45937186  0.4191938   0.76933336 -0.39961928]\n",
      "net present value -1.8959169695395686 current_interest -3.440834631735412\n",
      "\n",
      "\n",
      "STEP: 8\n",
      "ACT \n",
      " [11  0]\n",
      "OBS \n",
      " [ 0.9933752   0.98646986  0.9937823   0.99637306  0.9775115   1.0028682\n",
      "  0.9902007   0.9892018   0.998948    0.9960817   1.0046921   0.9821618\n",
      "  0.9749088   0.99118024  0.99297434  0.9919232   1.0044222   0.9867572\n",
      "  0.9889812   0.9904401   0.9770464   0.98790187  0.9888465   0.98368543\n",
      "  0.9817502   0.97740287  0.9918296   0.99868256  0.9806859   0.97885597\n",
      "  0.9742453   0.9763984   0.08915418  0.02720952  0.02045224  0.7395664\n",
      "  0.28045756  0.4296931   0.6706667  -0.4679365 ]\n",
      "net present value 0.6630962043974631 current_interest -0.0998352094721845\n",
      "\n",
      "\n",
      "STEP: 9\n",
      "ACT \n",
      " [2 3]\n",
      "OBS \n",
      " [ 0.98615766  0.9772868   0.9796762   0.9976056   0.9864686   0.9912044\n",
      "  0.98831344  0.9813976   0.98529094  0.99719906  0.99093264  0.97259027\n",
      "  0.9891738   0.982811    0.98467815  0.97740227  0.9938498   0.9859109\n",
      "  0.98632497  0.9849958   0.98474073  0.987728    0.9714952   0.97804964\n",
      "  0.97764635  0.9669194   0.98833215  0.9929085   0.97392845  0.9688822\n",
      "  0.99178815  1.0113541   0.0847647   0.02586986  0.02045224  0.7395664\n",
      "  0.16102736  0.4255207   0.692      -0.5064947 ]\n",
      "net present value 1.5774885634261517 current_interest 1.4284413914088194\n",
      "\n",
      "\n",
      "STEP: 10\n",
      "ACT \n",
      " [5 2]\n",
      "OBS \n",
      " [ 0.97384536  0.99566704  0.9986767   0.9822106   0.9827781   0.9862321\n",
      "  0.9828495   0.9956983   0.972327    0.98488426  0.9773537   0.9914006\n",
      "  0.9866249   0.97164553  0.9722578   0.9972436   0.9787626   0.9786867\n",
      "  0.9677882   0.9769691   0.9774193   0.9818198   0.9707896   0.966922\n",
      "  0.9629795   0.99054796  0.99064875  0.9827711   0.96696925  0.99750346\n",
      "  0.98797816  1.0036447   0.10532784  0.03214566  0.02045224  0.7395664\n",
      "  0.19552326  0.3434698   0.9573333  -0.5394163 ]\n",
      "net present value 1.2104122160375994 current_interest 0.8359405861391815\n",
      "\n",
      "\n",
      "STEP: 11\n",
      "ACT \n",
      " [6 3]\n",
      "OBS \n",
      " [ 0.9936074   0.9831571   0.98069745  1.0003024   0.98107004  0.9862707\n",
      "  0.9730312   0.98437786  0.98593783  0.98115766  0.9966482   0.9817444\n",
      "  0.9754762   0.9923802   0.99407274  0.9857902   0.97122836  0.96647227\n",
      "  0.9596319   0.9756333   0.96614903  0.97875345  0.9630748   0.997007\n",
      "  1.0020847   0.98031616  0.9749832   0.9707604   0.9957764   0.98821336\n",
      "  0.9796195   0.98651713  0.15645841  0.04775051  0.03339864  0.7395664\n",
      "  0.22605012  0.24416588  0.948      -0.5566712 ]\n",
      "net present value 0.8697120810236441 current_interest 0.8579719224076144\n",
      "\n",
      "\n",
      "STEP: 12\n",
      "ACT \n",
      " [3 4]\n",
      "OBS \n",
      " [ 0.99147856  0.9894626   0.99161804  0.9913557   0.97153604  0.97614926\n",
      "  0.995493    0.9788847   0.97673786  0.986261    0.98918897  0.9728112\n",
      "  0.9873191   0.9854452   0.98446476  0.97615063  0.95910734  0.98920137\n",
      "  0.99768955  0.96505827  0.9956141   0.97332174  1.0066563   0.9830091\n",
      "  1.0009179   0.9691088   0.97231543  0.9625718   0.9923212   0.98950994\n",
      "  0.96451277  0.9716053   0.16587412  0.05062416  0.06927399  0.7395664\n",
      "  0.20110944  0.16093078  0.47733334 -0.56943125]\n",
      "net present value 1.1794166651628977 current_interest 2.1710742378687753\n",
      "\n",
      "\n",
      "STEP: 13\n",
      "ACT \n",
      " [0 7]\n",
      "OBS \n",
      " [ 0.9897369   0.9726365   0.9863962   0.98793507  0.96498823  0.97226226\n",
      "  0.981782    0.970644    0.96282136  0.97552     0.9819586   0.96080667\n",
      "  0.9705512   0.9781502   0.9733862   0.9724207   1.0049208   0.9807743\n",
      "  0.98990977  0.99912095  0.98710775  0.9618746   1.003462    0.9653607\n",
      "  0.98937684  1.0021247   1.0064398   0.9944244   0.97561693  0.9780922\n",
      "  0.9998927   1.000088    0.18644367  0.05690191  0.06989849  0.7395664\n",
      "  0.19227894  0.22292258  0.7733333  -0.58730257]\n",
      "net present value 1.1806937363463408 current_interest 2.7057974002313507\n",
      "\n",
      "\n",
      "STEP: 14\n",
      "ACT \n",
      " [ 6 14]\n",
      "OBS \n",
      " [ 0.99387187  0.9576195   0.9714618   0.9842173   1.0019237   1.0037516\n",
      "  0.97849506  0.9921187   1.0027744   0.97587365  0.96865183  1.0053521\n",
      "  1.0030069   0.9585786   0.9714348   0.95361054  1.0033033   0.99738955\n",
      "  1.0004244   1.0026926   1.0077819   1.0028526   0.99928004  0.99561703\n",
      "  0.9988137   0.9996417   1.0040753   1.001042    1.0183318   0.98993737\n",
      "  0.99739325  1.0030887   0.22292015  0.06803439  0.06989849  0.7395664\n",
      "  0.34948242  0.1930776   0.34933335 -0.6530495 ]\n",
      "net present value -0.7147592790993574 current_interest -0.285116395432338\n",
      "\n",
      "\n",
      "STEP: 15\n",
      "ACT \n",
      " [ 8 13]\n",
      "OBS \n",
      " [ 0.98423547  0.9939646   1.0010357   0.9729481   1.0021296   0.9884455\n",
      "  1.0079744   0.98308694  1.0040016   0.9965303   1.0123892   0.9966552\n",
      "  0.9886955   1.0063688   0.9967055   1.0080767   0.99900806  0.9970162\n",
      "  1.0088357   1.0026627   0.99268794  0.99188435  1.0036521   1.0002997\n",
      "  0.99815106  1.0025077   0.9972863   1.0078161   1.0122724   0.9959346\n",
      "  0.9973246   1.0016251   0.25447237  0.07766401  0.07228336  0.7395664\n",
      "  0.37069273  0.254919    0.5426667  -0.66657996]\n",
      "net present value -0.8848535006988545 current_interest -0.15339077703246717\n",
      "\n",
      "\n",
      "STEP: 16\n",
      "ACT \n",
      " [14 11]\n",
      "OBS \n",
      " [ 1.0110123   1.0124562   1.0028203   0.9987513   1.0044513   0.998097\n",
      "  0.99971426  1.0146666   1.0004526   1.0065488   1.0142905   0.9996888\n",
      "  1.0010334   0.99683744  1.0057011   1.0009187   0.9979551   1.0134673\n",
      "  1.0060623   0.99354994  0.999306    1.0041939   0.996965    0.99962664\n",
      "  1.0042931   1.0033233   0.994299    1.009076    1.0130152   0.9963317\n",
      "  0.9986346   1.0059519   0.25751397  0.07859229  0.07228367  0.7395664\n",
      "  0.4247371   0.39602345  0.84       -0.6397125 ]\n",
      "net present value -1.3754781384746335 current_interest -1.037286809679101\n",
      "\n",
      "\n",
      "STEP: 17\n",
      "ACT \n",
      " [ 1 15]\n",
      "OBS \n",
      " [ 0.9904611   1.0008552   0.9975425   0.993948    1.000909    0.9884437\n",
      "  0.99533427  1.0105618   0.99369484  0.9935013   1.0092502   0.99712247\n",
      "  0.98866963  1.0075684   1.0016057   0.98718375  1.000337    1.013503\n",
      "  1.0086063   1.0098706   1.0073978   0.99501556  0.994331    0.9974391\n",
      "  1.0039414   0.9944364   0.9911484   1.0037593   0.9969396   1.000524\n",
      "  1.0035511   0.9975015   0.25530195  0.0779172   0.07228369  0.7395664\n",
      "  0.2897841   0.43195632  0.7186667  -0.66278565]\n",
      "net present value -0.025050418595063857 current_interest 0.463494498451506\n",
      "\n",
      "\n",
      "STEP: 18\n",
      "ACT \n",
      " [15 13]\n",
      "OBS \n",
      " [ 1.0065652   1.0057026   0.9975583   0.99882925  1.008815    1.0064852\n",
      "  1.0051522   1.0033747   1.0040783   1.0100197   1.0187205   1.0038259\n",
      "  1.0048461   1.0092653   0.99757     1.018721    1.0073361   1.0070843\n",
      "  0.99318236  1.0127594   0.9993355   1.0002083   1.0013409   1.0007108\n",
      "  1.0037973   0.9982233   1.0076425   0.99408275  0.9965308   1.0000298\n",
      "  1.004172    0.998157    0.25305694  0.07723203  0.0722837   0.7395664\n",
      "  0.45124644  0.4670102   0.352      -0.69475377]\n",
      "net present value -1.5581703929017028 current_interest -2.2410932396849392\n",
      "\n",
      "\n",
      "STEP: 19\n",
      "ACT \n",
      " [13 14]\n",
      "OBS \n",
      " [ 0.9979677   1.000981    0.9995879   0.9986456   1.0027686   1.0114105\n",
      "  1.0027161   0.9921445   0.99686027  1.0077525   1.0080833   1.0094538\n",
      "  1.0014918   0.99593806  1.0053763   1.0114914   1.0017729   1.0098854\n",
      "  0.9940322   1.0072801   1.00043     1.0084575   1.0061892   1.0085865\n",
      "  1.0029544   1.0030774   0.9992598   1.0033886   1.0053244   1.0112237\n",
      "  1.0110974   0.99885577  0.2820117   0.0860689   0.0722839   0.7395664\n",
      "  0.44026083  0.4857232   0.928      -0.71007603]\n",
      "net present value -1.3740263066184706 current_interest -2.17624221366155\n",
      "\n",
      "\n",
      "STEP: 20\n",
      "ACT \n",
      " [11  3]\n",
      "OBS \n",
      " [ 0.99725586  1.0014899   0.9969407   0.99948734  1.0065898   1.0073091\n",
      "  1.0144125   1.005814    1.0103835   0.9984612   1.0008874   0.99599576\n",
      "  1.0115416   0.9947287   0.99813575  1.0043215   0.99494684  1.0100863\n",
      "  1.0127136   1.003091    0.9936437   1.000086    0.9997146   1.0065874\n",
      "  0.9912143   0.9956315   0.99800265  1.0015159   0.99146444  0.99524206\n",
      "  0.9994167   1.0034916   0.31581935  0.09638688  0.07228411  0.7395664\n",
      "  0.326507    0.43537495  0.352      -0.7159592 ]\n",
      "net present value 0.2924146071392566 current_interest 0.2994688091672493\n",
      "\n",
      "\n",
      "STEP: 21\n",
      "ACT \n",
      " [6 4]\n",
      "OBS \n",
      " [ 1.0072553   0.9971697   1.0007569   0.98303074  0.9948855   0.9943894\n",
      "  1.0046295   0.99386674  0.9978068   1.0063955   0.9986394   1.0136976\n",
      "  1.007078    1.0086101   1.0113975   0.9950608   1.0029864   0.995335\n",
      "  1.0098423   0.99443495  0.9971605   0.9901833   0.98340446  0.998292\n",
      "  1.0078626   0.9824161   0.9911151   0.99691933  1.0026041   0.98925734\n",
      "  0.99034643  0.98835635  0.2944762   0.08987303  0.07240505  0.7395664\n",
      "  0.2657015   0.45666966  0.34933335 -0.7610377 ]\n",
      "net present value 0.8094811603381303 current_interest 1.6732885168273002\n",
      "\n",
      "\n",
      "STEP: 22\n",
      "ACT \n",
      " [10  9]\n",
      "OBS \n",
      " [ 0.9960355   1.0118037   0.99828374  1.0117755   1.0051183   1.0012584\n",
      "  1.0081117   0.99991834  0.9903787   0.99995464  0.9978558   0.998226\n",
      "  0.99498785  0.99457353  0.9997071   1.0071231   0.98966444  0.9954249\n",
      "  1.0021654   0.9970826   0.99186903  0.99758255  1.0049746   1.000252\n",
      "  1.0022508   0.9974075   1.0045615   0.9920451   0.99592894  1.0038903\n",
      "  1.0041274   1.0113944   0.26766875  0.0816915   0.07241315  0.7395664\n",
      "  0.3747046   0.4350942   0.708      -0.7800105 ]\n",
      "net present value -0.25113716110563933 current_interest -0.3060757291585118\n",
      "\n",
      "\n",
      "STEP: 23\n",
      "ACT \n",
      " [11 12]\n",
      "OBS \n",
      " [ 0.99647564  0.99835926  1.0006484   1.0063994   1.0023496   0.99728286\n",
      "  0.9987596   1.0002321   1.000894    1.0126296   1.0057579   1.0020199\n",
      "  1.0072687   0.9924299   1.0015587   0.99577755  1.0026002   1.003385\n",
      "  1.0010036   1.0016632   1.0087005   1.0034046   0.9972609   0.9970514\n",
      "  1.0018151   1.004942    0.9885338   0.99798965  0.9962425   1.0108446\n",
      "  0.98829556  0.99795216  0.2524037   0.07703266  0.0724163   0.7395664\n",
      "  0.41989174  0.39998466  0.52133334 -0.7835283 ]\n",
      "net present value -0.646349565695947 current_interest -1.0645083588433535\n",
      "\n",
      "\n",
      "STEP: 24\n",
      "ACT \n",
      " [9 7]\n",
      "OBS \n",
      " [ 0.99531555  1.0074873   0.98813003  0.9981505   0.99776024  1.0006331\n",
      "  1.005768    1.007911    0.99863994  1.0038016   0.9980607   0.98658824\n",
      "  0.9978426   1.0042604   0.9954055   0.9958646   0.99733186  0.99329287\n",
      "  0.9985526   1.0025795   0.99447244  0.9954894   1.0004805   1.0049495\n",
      "  0.9906545   1.0014293   1.0088025   0.9950905   0.99487996  1.0052323\n",
      "  1.0128903   0.997884    0.265186    0.08093377  0.07243068  0.7395664\n",
      "  0.356873    0.42924199  0.9946667  -0.8267362 ]\n",
      "net present value 0.18058493284055793 current_interest 0.20129380324924892\n",
      "\n",
      "\n",
      "STEP: 25\n",
      "ACT \n",
      " [ 9 10]\n",
      "OBS \n",
      " [ 0.9931966   0.99881375  1.0085745   1.0086167   1.0087591   0.99778056\n",
      "  1.0016091   0.9955335   0.99769795  0.9860094   1.0065151   1.0011015\n",
      "  0.99841356  0.9893133   1.0004767   1.0092372   1.0062516   1.0099783\n",
      "  0.9940624   0.9947007   1.000026    1.0099505   1.0100529   0.99949336\n",
      "  0.99874896  0.99444085  0.99522656  0.98788536  0.98782444  0.99634415\n",
      "  1.0051769   1.0032169   0.265186    0.08093377  0.07243068  0.7395664\n",
      "  0.39177486  0.45348087  0.38666666 -0.8267362 ]\n",
      "net present value -0.13388623881140133 current_interest -0.37450319634184037\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test4(1, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1279284b",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test1(1000, env_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e45550",
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def make_env(rank: int, seed: int = 0) -> Callable:\n",
    "    def _init() -> gym.Env:\n",
    "        random.seed(seed + rank)\n",
    "        np.random.seed(seed + rank) \n",
    "        env = TrainEnvironment(JA_60_arr, JA_240_arr, elec_consum_arr, import_price_rate, import_price_train_arr, Eff_train_arr, \n",
    "                       CAPEX_JA_train_arr, grid_factor_test_arr, pv_co2_arr)\n",
    "        env.reset(seed=seed + rank)\n",
    "        return env\n",
    "\n",
    "    return _init\n",
    "# Number of environments to run in parallel\n",
    "num_cpu = 16\n",
    "env = SubprocVecEnv([make_env(i) for i in range(num_cpu)])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36af5784",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "log_path = \"./logs/\"\n",
    "eval_callback = EvalCallback(env_test, best_model_save_path = \"C:/Users/kubaw/Desktop/DELFT/THESIS/CODE/TEST_MODELS/32_ENV_JA_LOW_2/\",\n",
    "                             log_path = log_path, n_eval_episodes = 750, eval_freq=15000,\n",
    "                             deterministic=True, render=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41010d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_kwargs = dict(net_arch=dict(pi=[2048, 2048], vf=[2048, 2048]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3408195a",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def linear_schedule(initial_value, final_value=0.00001):\n",
    "    \"\"\"\n",
    "    Returns a function that computes a linearly decreasing value from initial_value to final_value.\n",
    "    \"\"\"\n",
    "    def func(progress_remaining):\n",
    "        # Calculate the decrease based on the remaining progress\n",
    "        return final_value + (initial_value - final_value) * progress_remaining\n",
    "    return func\n",
    "\n",
    "# Define the learning rate using the linear schedule\n",
    "learning_rate = linear_schedule(0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "678979b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to C:/Users/kubaw/Desktop/DELFT/THESIS\\CODE/TEST_MODELS/LOGS/logs\\PPO_467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kubaw\\miniforge3\\envs\\pytorch-env\\lib\\site-packages\\stable_baselines3\\common\\callbacks.py:414: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x000001509E205150> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001509F45FBB0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 1344  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 24    |\n",
      "|    total_timesteps | 32768 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016636478 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.53       |\n",
      "|    explained_variance   | -0.00174    |\n",
      "|    learning_rate        | 0.000199    |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 24          |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 42.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 335        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 292        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02125514 |\n",
      "|    clip_fraction        | 0.294      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.48      |\n",
      "|    explained_variance   | 0.224      |\n",
      "|    learning_rate        | 0.000199   |\n",
      "|    loss                 | 23.7       |\n",
      "|    n_updates            | 48         |\n",
      "|    policy_gradient_loss | -0.0359    |\n",
      "|    value_loss           | 47.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 426         |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017752007 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.41       |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.000198    |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 72          |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 52.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 293        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 558        |\n",
      "|    total_timesteps      | 163840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01919432 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.3       |\n",
      "|    explained_variance   | 0.286      |\n",
      "|    learning_rate        | 0.000198   |\n",
      "|    loss                 | 27.9       |\n",
      "|    n_updates            | 96         |\n",
      "|    policy_gradient_loss | -0.0304    |\n",
      "|    value_loss           | 53.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 689         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021235332 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.18       |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.000197    |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 50.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 821         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016913548 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.05       |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.000196    |\n",
      "|    loss                 | 29.7        |\n",
      "|    n_updates            | 144         |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    value_loss           | 54.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kubaw\\miniforge3\\envs\\pytorch-env\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kubaw\\AppData\\Local\\Temp\\ipykernel_15060\\3207890752.py:225: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  value = annual_expense / self.current_budget_constraint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=240000, episode_reward=103.76 +/- 9.59\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 104         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 240000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014866164 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.92       |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.000196    |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 168         |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 49.1        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 266    |\n",
      "|    iterations      | 8      |\n",
      "|    time_elapsed    | 984    |\n",
      "|    total_timesteps | 262144 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 1116        |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014002538 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.79       |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.000195    |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 192         |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1248        |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018875968 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.63       |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.000194    |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 216         |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 261         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 1380        |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016630378 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.46       |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 0.000194    |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    value_loss           | 42.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1513        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016336126 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.29       |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.000193    |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 264         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 1645        |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017254645 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.11       |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.000193    |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 288         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    value_loss           | 44.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1777        |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013654271 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.96       |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.000192    |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 312         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=104.79 +/- 8.36\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 105         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 480000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010631384 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.82       |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.000191    |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 336         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 252    |\n",
      "|    iterations      | 15     |\n",
      "|    time_elapsed    | 1947   |\n",
      "|    total_timesteps | 491520 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 2079        |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043487772 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.67       |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.000191    |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 46          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 2213        |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012109138 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.58       |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.00019     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 384         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 44.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 251        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 2347       |\n",
      "|    total_timesteps      | 589824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01109109 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.42      |\n",
      "|    explained_variance   | 0.918      |\n",
      "|    learning_rate        | 0.000189   |\n",
      "|    loss                 | 22.3       |\n",
      "|    n_updates            | 408        |\n",
      "|    policy_gradient_loss | -0.013     |\n",
      "|    value_loss           | 44.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 2482         |\n",
      "|    total_timesteps      | 622592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097600855 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.29        |\n",
      "|    explained_variance   | 0.919        |\n",
      "|    learning_rate        | 0.000189     |\n",
      "|    loss                 | 23.2         |\n",
      "|    n_updates            | 432          |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    value_loss           | 46           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 2613        |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009331621 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.29       |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.000188    |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 456         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 47          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 2745        |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008636129 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.16       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.000188    |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=103.11 +/- 6.44\n",
      "Episode length: 25.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 25         |\n",
      "|    mean_reward          | 103        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 720000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00849651 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.06      |\n",
      "|    explained_variance   | 0.926      |\n",
      "|    learning_rate        | 0.000187   |\n",
      "|    loss                 | 22.8       |\n",
      "|    n_updates            | 504        |\n",
      "|    policy_gradient_loss | -0.00979   |\n",
      "|    value_loss           | 44.7       |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 247    |\n",
      "|    iterations      | 22     |\n",
      "|    time_elapsed    | 2907   |\n",
      "|    total_timesteps | 720896 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 3040        |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008722247 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.95       |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.000186    |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 528         |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    value_loss           | 48.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 3170        |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010546761 |\n",
      "|    clip_fraction        | 0.0934      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.81       |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.000186    |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 552         |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    value_loss           | 46.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 3300        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009106269 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.7        |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.000185    |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 576         |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 3432        |\n",
      "|    total_timesteps      | 851968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008037391 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.57       |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.000184    |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 3564        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009010218 |\n",
      "|    clip_fraction        | 0.0894      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.46       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.000184    |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 624         |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    value_loss           | 42.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 3695         |\n",
      "|    total_timesteps      | 917504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074102664 |\n",
      "|    clip_fraction        | 0.0659       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.34        |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.000183     |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 648          |\n",
      "|    policy_gradient_loss | -0.00648     |\n",
      "|    value_loss           | 42.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 3827         |\n",
      "|    total_timesteps      | 950272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069922125 |\n",
      "|    clip_fraction        | 0.0511       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.25        |\n",
      "|    explained_variance   | 0.941        |\n",
      "|    learning_rate        | 0.000183     |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 672          |\n",
      "|    policy_gradient_loss | -0.00557     |\n",
      "|    value_loss           | 42.2         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=960000, episode_reward=104.92 +/- 7.13\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 105          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 960000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046620704 |\n",
      "|    clip_fraction        | 0.0399       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.2         |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.000182     |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 696          |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    value_loss           | 43.6         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 246    |\n",
      "|    iterations      | 30     |\n",
      "|    time_elapsed    | 3993   |\n",
      "|    total_timesteps | 983040 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 246        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 4127       |\n",
      "|    total_timesteps      | 1015808    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00860909 |\n",
      "|    clip_fraction        | 0.0457     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.11      |\n",
      "|    explained_variance   | 0.944      |\n",
      "|    learning_rate        | 0.000181   |\n",
      "|    loss                 | 20.3       |\n",
      "|    n_updates            | 720        |\n",
      "|    policy_gradient_loss | -0.00526   |\n",
      "|    value_loss           | 40.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 4260        |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011001723 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.07       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.000181    |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 744         |\n",
      "|    policy_gradient_loss | -0.00445    |\n",
      "|    value_loss           | 40.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 4392         |\n",
      "|    total_timesteps      | 1081344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052720234 |\n",
      "|    clip_fraction        | 0.041        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 768          |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 4524        |\n",
      "|    total_timesteps      | 1114112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004102405 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.000179    |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 792         |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 4655         |\n",
      "|    total_timesteps      | 1146880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032064626 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.8         |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 0.000179     |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 816          |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    value_loss           | 39.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 4788         |\n",
      "|    total_timesteps      | 1179648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051405686 |\n",
      "|    clip_fraction        | 0.0463       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.76        |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.000178     |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    value_loss           | 37.6         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1200000, episode_reward=106.19 +/- 7.33\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 106          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060899556 |\n",
      "|    clip_fraction        | 0.055        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.68        |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.000178     |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 864          |\n",
      "|    policy_gradient_loss | -0.00475     |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 244     |\n",
      "|    iterations      | 37      |\n",
      "|    time_elapsed    | 4950    |\n",
      "|    total_timesteps | 1212416 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 245         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 5081        |\n",
      "|    total_timesteps      | 1245184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004422268 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.000177    |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 888         |\n",
      "|    policy_gradient_loss | -0.00351    |\n",
      "|    value_loss           | 34.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 5214         |\n",
      "|    total_timesteps      | 1277952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044237915 |\n",
      "|    clip_fraction        | 0.0408       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.64        |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.000176     |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 912          |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    value_loss           | 36.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 245         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 5346        |\n",
      "|    total_timesteps      | 1310720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003174872 |\n",
      "|    clip_fraction        | 0.0349      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.000176    |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 936         |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 5481         |\n",
      "|    total_timesteps      | 1343488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029446704 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.57        |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.000175     |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    value_loss           | 36           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 5612         |\n",
      "|    total_timesteps      | 1376256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036847044 |\n",
      "|    clip_fraction        | 0.0293       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.59        |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.000174     |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 984          |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    value_loss           | 35.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 5745         |\n",
      "|    total_timesteps      | 1409024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054274118 |\n",
      "|    clip_fraction        | 0.0539       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.56        |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.000174     |\n",
      "|    loss                 | 18.2         |\n",
      "|    n_updates            | 1008         |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    value_loss           | 35.7         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1440000, episode_reward=107.71 +/- 7.56\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 108          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1440000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037100865 |\n",
      "|    clip_fraction        | 0.0378       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.53        |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.000173     |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 1032         |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    value_loss           | 35.1         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 244     |\n",
      "|    iterations      | 44      |\n",
      "|    time_elapsed    | 5907    |\n",
      "|    total_timesteps | 1441792 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 6040         |\n",
      "|    total_timesteps      | 1474560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034881406 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.48        |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.000173     |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 1056         |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    value_loss           | 35           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 6172         |\n",
      "|    total_timesteps      | 1507328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033469573 |\n",
      "|    clip_fraction        | 0.047        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.53        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.000172     |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 6303         |\n",
      "|    total_timesteps      | 1540096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033222395 |\n",
      "|    clip_fraction        | 0.0457       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.51        |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.000171     |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 1104         |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    value_loss           | 34.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 6435        |\n",
      "|    total_timesteps      | 1572864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004466725 |\n",
      "|    clip_fraction        | 0.0552      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.000171    |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 1128        |\n",
      "|    policy_gradient_loss | -0.00345    |\n",
      "|    value_loss           | 35.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 6567        |\n",
      "|    total_timesteps      | 1605632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003510653 |\n",
      "|    clip_fraction        | 0.0359      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.00017     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 1152        |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    value_loss           | 34.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 6698         |\n",
      "|    total_timesteps      | 1638400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053923726 |\n",
      "|    clip_fraction        | 0.0695       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.46        |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.000169     |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 1176         |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    value_loss           | 34.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 6830        |\n",
      "|    total_timesteps      | 1671168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003216231 |\n",
      "|    clip_fraction        | 0.0497      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.000169    |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1680000, episode_reward=108.57 +/- 7.81\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 109          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1680000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046080267 |\n",
      "|    clip_fraction        | 0.0395       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.000168     |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 1224         |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    value_loss           | 33.4         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 243     |\n",
      "|    iterations      | 52      |\n",
      "|    time_elapsed    | 6996    |\n",
      "|    total_timesteps | 1703936 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 7131         |\n",
      "|    total_timesteps      | 1736704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054847314 |\n",
      "|    clip_fraction        | 0.0564       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.46        |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.000168     |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 1248         |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    value_loss           | 35.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 7266         |\n",
      "|    total_timesteps      | 1769472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038334131 |\n",
      "|    clip_fraction        | 0.0325       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.000167     |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 1272         |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    value_loss           | 35.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 7400         |\n",
      "|    total_timesteps      | 1802240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030285753 |\n",
      "|    clip_fraction        | 0.0306       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.000166     |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 1296         |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    value_loss           | 35.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 7534        |\n",
      "|    total_timesteps      | 1835008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013588701 |\n",
      "|    clip_fraction        | 0.0599      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.000166    |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.00289    |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 7668         |\n",
      "|    total_timesteps      | 1867776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057872706 |\n",
      "|    clip_fraction        | 0.0504       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.53        |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.000165     |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 1344         |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    value_loss           | 34.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 7801        |\n",
      "|    total_timesteps      | 1900544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004171363 |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.000165    |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 1368        |\n",
      "|    policy_gradient_loss | -0.00248    |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1920000, episode_reward=108.57 +/- 8.23\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 109         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1920000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004014304 |\n",
      "|    clip_fraction        | 0.0534      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.000164    |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 1392        |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 242     |\n",
      "|    iterations      | 59      |\n",
      "|    time_elapsed    | 7964    |\n",
      "|    total_timesteps | 1933312 |\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 8094        |\n",
      "|    total_timesteps      | 1966080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004828313 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.000163    |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 1416        |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 8224         |\n",
      "|    total_timesteps      | 1998848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042997003 |\n",
      "|    clip_fraction        | 0.0404       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.000163     |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    value_loss           | 33.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 8355         |\n",
      "|    total_timesteps      | 2031616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040678494 |\n",
      "|    clip_fraction        | 0.0454       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.000162     |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 1464         |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 8485        |\n",
      "|    total_timesteps      | 2064384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004585493 |\n",
      "|    clip_fraction        | 0.059       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.000161    |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 1488        |\n",
      "|    policy_gradient_loss | -0.00249    |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 8617        |\n",
      "|    total_timesteps      | 2097152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004283908 |\n",
      "|    clip_fraction        | 0.0677      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.000161    |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 1512        |\n",
      "|    policy_gradient_loss | -0.00188    |\n",
      "|    value_loss           | 35.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 8748        |\n",
      "|    total_timesteps      | 2129920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007819914 |\n",
      "|    clip_fraction        | 0.0345      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.00016     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 1536        |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2160000, episode_reward=108.68 +/- 8.24\n",
      "Episode length: 25.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 25         |\n",
      "|    mean_reward          | 109        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2160000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00775032 |\n",
      "|    clip_fraction        | 0.073      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.39      |\n",
      "|    explained_variance   | 0.957      |\n",
      "|    learning_rate        | 0.00016    |\n",
      "|    loss                 | 17.7       |\n",
      "|    n_updates            | 1560       |\n",
      "|    policy_gradient_loss | -0.002     |\n",
      "|    value_loss           | 33.9       |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 242     |\n",
      "|    iterations      | 66      |\n",
      "|    time_elapsed    | 8910    |\n",
      "|    total_timesteps | 2162688 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 9043         |\n",
      "|    total_timesteps      | 2195456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048895506 |\n",
      "|    clip_fraction        | 0.0464       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.000159     |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 1584         |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    value_loss           | 32.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 9176        |\n",
      "|    total_timesteps      | 2228224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011338277 |\n",
      "|    clip_fraction        | 0.0345      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.000158    |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 1608        |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    value_loss           | 33.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 242        |\n",
      "|    iterations           | 69         |\n",
      "|    time_elapsed         | 9307       |\n",
      "|    total_timesteps      | 2260992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00615635 |\n",
      "|    clip_fraction        | 0.0533     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.32      |\n",
      "|    explained_variance   | 0.957      |\n",
      "|    learning_rate        | 0.000158   |\n",
      "|    loss                 | 16.9       |\n",
      "|    n_updates            | 1632       |\n",
      "|    policy_gradient_loss | -0.0026    |\n",
      "|    value_loss           | 34.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 9439         |\n",
      "|    total_timesteps      | 2293760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046778703 |\n",
      "|    clip_fraction        | 0.0524       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.000157     |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 1656         |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 9571        |\n",
      "|    total_timesteps      | 2326528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006227662 |\n",
      "|    clip_fraction        | 0.0464      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.000156    |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 9705         |\n",
      "|    total_timesteps      | 2359296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056738644 |\n",
      "|    clip_fraction        | 0.0676       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.000156     |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 1704         |\n",
      "|    policy_gradient_loss | -0.00087     |\n",
      "|    value_loss           | 35.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 9837         |\n",
      "|    total_timesteps      | 2392064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029752129 |\n",
      "|    clip_fraction        | 0.0482       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.000155     |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 1728         |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    value_loss           | 32.5         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2400000, episode_reward=108.75 +/- 8.68\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 109          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2400000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030496223 |\n",
      "|    clip_fraction        | 0.0456       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.000155     |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 1752         |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    value_loss           | 33.9         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 242     |\n",
      "|    iterations      | 74      |\n",
      "|    time_elapsed    | 10001   |\n",
      "|    total_timesteps | 2424832 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 10134        |\n",
      "|    total_timesteps      | 2457600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048661274 |\n",
      "|    clip_fraction        | 0.0767       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.000154     |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 1776         |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    value_loss           | 34.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 10265       |\n",
      "|    total_timesteps      | 2490368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009772144 |\n",
      "|    clip_fraction        | 0.0439      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.000153    |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 10396        |\n",
      "|    total_timesteps      | 2523136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038723457 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.000153     |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 1824         |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    value_loss           | 32.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 10527        |\n",
      "|    total_timesteps      | 2555904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039490666 |\n",
      "|    clip_fraction        | 0.0438       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.000152     |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 1848         |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    value_loss           | 32.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 10659        |\n",
      "|    total_timesteps      | 2588672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034375198 |\n",
      "|    clip_fraction        | 0.0517       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.000151     |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 1872         |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    value_loss           | 33.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 10793        |\n",
      "|    total_timesteps      | 2621440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048904447 |\n",
      "|    clip_fraction        | 0.0865       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.000151     |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 1896         |\n",
      "|    policy_gradient_loss | 1.68e-05     |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2640000, episode_reward=109.31 +/- 8.67\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 109          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2640000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040212525 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.00015      |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 1920         |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    value_loss           | 33.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 242     |\n",
      "|    iterations      | 81      |\n",
      "|    time_elapsed    | 10959   |\n",
      "|    total_timesteps | 2654208 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 11093       |\n",
      "|    total_timesteps      | 2686976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004669955 |\n",
      "|    clip_fraction        | 0.0433      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.00015     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 1944        |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 11225       |\n",
      "|    total_timesteps      | 2719744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004668994 |\n",
      "|    clip_fraction        | 0.0518      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.000149    |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 1968        |\n",
      "|    policy_gradient_loss | -0.00301    |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 11358       |\n",
      "|    total_timesteps      | 2752512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003493195 |\n",
      "|    clip_fraction        | 0.0394      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.000148    |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 1992        |\n",
      "|    policy_gradient_loss | -0.00253    |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 11491       |\n",
      "|    total_timesteps      | 2785280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008060439 |\n",
      "|    clip_fraction        | 0.0798      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.000148    |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 2016        |\n",
      "|    policy_gradient_loss | -0.000581   |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 11623        |\n",
      "|    total_timesteps      | 2818048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043098372 |\n",
      "|    clip_fraction        | 0.0401       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.000147     |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 2040         |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    value_loss           | 33.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 11754       |\n",
      "|    total_timesteps      | 2850816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004047326 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.000146    |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 2064        |\n",
      "|    policy_gradient_loss | 0.00119     |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2880000, episode_reward=108.77 +/- 8.63\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 109          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2880000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033076508 |\n",
      "|    clip_fraction        | 0.0544       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.000146     |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 2088         |\n",
      "|    policy_gradient_loss | -0.00241     |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 241     |\n",
      "|    iterations      | 88      |\n",
      "|    time_elapsed    | 11917   |\n",
      "|    total_timesteps | 2883584 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 12049        |\n",
      "|    total_timesteps      | 2916352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044798357 |\n",
      "|    clip_fraction        | 0.0286       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.11        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.000145     |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 2112         |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    value_loss           | 33.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 12182        |\n",
      "|    total_timesteps      | 2949120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026555904 |\n",
      "|    clip_fraction        | 0.0688       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.000145     |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 2136         |\n",
      "|    policy_gradient_loss | -0.000741    |\n",
      "|    value_loss           | 32.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 12315       |\n",
      "|    total_timesteps      | 2981888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014942091 |\n",
      "|    clip_fraction        | 0.041       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.000144    |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 2160        |\n",
      "|    policy_gradient_loss | -0.00243    |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 12446        |\n",
      "|    total_timesteps      | 3014656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028432817 |\n",
      "|    clip_fraction        | 0.0664       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.000143     |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 2184         |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    value_loss           | 31.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 12576       |\n",
      "|    total_timesteps      | 3047424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004399038 |\n",
      "|    clip_fraction        | 0.0588      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.000143    |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 2208        |\n",
      "|    policy_gradient_loss | -0.0016     |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 12710        |\n",
      "|    total_timesteps      | 3080192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062225647 |\n",
      "|    clip_fraction        | 0.0782       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 0.000142     |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 2232         |\n",
      "|    policy_gradient_loss | -0.000329    |\n",
      "|    value_loss           | 30.5         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 242        |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 12841      |\n",
      "|    total_timesteps      | 3112960    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00511513 |\n",
      "|    clip_fraction        | 0.0401     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.04      |\n",
      "|    explained_variance   | 0.962      |\n",
      "|    learning_rate        | 0.000141   |\n",
      "|    loss                 | 15.7       |\n",
      "|    n_updates            | 2256       |\n",
      "|    policy_gradient_loss | -0.00387   |\n",
      "|    value_loss           | 30.7       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3120000, episode_reward=108.47 +/- 8.35\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 108         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3120000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003289466 |\n",
      "|    clip_fraction        | 0.057       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.000141    |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 2280        |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 241     |\n",
      "|    iterations      | 96      |\n",
      "|    time_elapsed    | 13004   |\n",
      "|    total_timesteps | 3145728 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 13138       |\n",
      "|    total_timesteps      | 3178496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006382751 |\n",
      "|    clip_fraction        | 0.0468      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.00014     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 2304        |\n",
      "|    policy_gradient_loss | -0.00199    |\n",
      "|    value_loss           | 32.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 13270       |\n",
      "|    total_timesteps      | 3211264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003564752 |\n",
      "|    clip_fraction        | 0.0516      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.00014     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 2328        |\n",
      "|    policy_gradient_loss | -0.00203    |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 13401        |\n",
      "|    total_timesteps      | 3244032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042134533 |\n",
      "|    clip_fraction        | 0.0351       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.000139     |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 2352         |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    value_loss           | 31.6         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 242        |\n",
      "|    iterations           | 100        |\n",
      "|    time_elapsed         | 13532      |\n",
      "|    total_timesteps      | 3276800    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00342162 |\n",
      "|    clip_fraction        | 0.0605     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0.959      |\n",
      "|    learning_rate        | 0.000138   |\n",
      "|    loss                 | 16.7       |\n",
      "|    n_updates            | 2376       |\n",
      "|    policy_gradient_loss | -0.0015    |\n",
      "|    value_loss           | 32.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 101          |\n",
      "|    time_elapsed         | 13665        |\n",
      "|    total_timesteps      | 3309568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065220566 |\n",
      "|    clip_fraction        | 0.093        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.000138     |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 2400         |\n",
      "|    policy_gradient_loss | 0.00122      |\n",
      "|    value_loss           | 32.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 102          |\n",
      "|    time_elapsed         | 13795        |\n",
      "|    total_timesteps      | 3342336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044438588 |\n",
      "|    clip_fraction        | 0.0333       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.000137     |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 2424         |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    value_loss           | 31.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3360000, episode_reward=109.11 +/- 8.54\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 109          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3360000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065817125 |\n",
      "|    clip_fraction        | 0.0572       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.000136     |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 2448         |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    value_loss           | 32.4         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 241     |\n",
      "|    iterations      | 103     |\n",
      "|    time_elapsed    | 13957   |\n",
      "|    total_timesteps | 3375104 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 104          |\n",
      "|    time_elapsed         | 14089        |\n",
      "|    total_timesteps      | 3407872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029346203 |\n",
      "|    clip_fraction        | 0.0483       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.000136     |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 2472         |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    value_loss           | 32.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 105          |\n",
      "|    time_elapsed         | 14221        |\n",
      "|    total_timesteps      | 3440640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028310893 |\n",
      "|    clip_fraction        | 0.0947       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.000135     |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 2496         |\n",
      "|    policy_gradient_loss | 0.00265      |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 14352       |\n",
      "|    total_timesteps      | 3473408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002322321 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.000135    |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    value_loss           | 32.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 242        |\n",
      "|    iterations           | 107        |\n",
      "|    time_elapsed         | 14486      |\n",
      "|    total_timesteps      | 3506176    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02211187 |\n",
      "|    clip_fraction        | 0.06       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.000134   |\n",
      "|    loss                 | 16         |\n",
      "|    n_updates            | 2544       |\n",
      "|    policy_gradient_loss | -0.00194   |\n",
      "|    value_loss           | 32.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 108          |\n",
      "|    time_elapsed         | 14618        |\n",
      "|    total_timesteps      | 3538944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036181365 |\n",
      "|    clip_fraction        | 0.0495       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.000133     |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 2568         |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    value_loss           | 33.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 109          |\n",
      "|    time_elapsed         | 14752        |\n",
      "|    total_timesteps      | 3571712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046675587 |\n",
      "|    clip_fraction        | 0.0484       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.000133     |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 2592         |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    value_loss           | 33.3         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3600000, episode_reward=108.90 +/- 9.19\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 109          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3600000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036534993 |\n",
      "|    clip_fraction        | 0.0415       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.000132     |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 2616         |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 33.1         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 241     |\n",
      "|    iterations      | 110     |\n",
      "|    time_elapsed    | 14917   |\n",
      "|    total_timesteps | 3604480 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 15051        |\n",
      "|    total_timesteps      | 3637248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032911506 |\n",
      "|    clip_fraction        | 0.0597       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.992       |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.000132     |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 2640         |\n",
      "|    policy_gradient_loss | -0.00114     |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 112          |\n",
      "|    time_elapsed         | 15185        |\n",
      "|    total_timesteps      | 3670016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030653924 |\n",
      "|    clip_fraction        | 0.0461       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.963       |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.000131     |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 2664         |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    value_loss           | 32           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 113          |\n",
      "|    time_elapsed         | 15317        |\n",
      "|    total_timesteps      | 3702784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053595393 |\n",
      "|    clip_fraction        | 0.0578       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.976       |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.00013      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 2688         |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    value_loss           | 32.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 15450       |\n",
      "|    total_timesteps      | 3735552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033635553 |\n",
      "|    clip_fraction        | 0.0698      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.951      |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.00013     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 2712        |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 115          |\n",
      "|    time_elapsed         | 15582        |\n",
      "|    total_timesteps      | 3768320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042711217 |\n",
      "|    clip_fraction        | 0.0399       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.000129     |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 2736         |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    value_loss           | 35.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 116          |\n",
      "|    time_elapsed         | 15715        |\n",
      "|    total_timesteps      | 3801088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063192495 |\n",
      "|    clip_fraction        | 0.0538       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.973       |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 0.000128     |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 2760         |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    value_loss           | 30.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 117          |\n",
      "|    time_elapsed         | 15847        |\n",
      "|    total_timesteps      | 3833856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039007284 |\n",
      "|    clip_fraction        | 0.0565       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.963       |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.000128     |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 2784         |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    value_loss           | 31.6         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3840000, episode_reward=108.62 +/- 9.16\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 109         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3840000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003214836 |\n",
      "|    clip_fraction        | 0.059       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.979      |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.000127    |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 2808        |\n",
      "|    policy_gradient_loss | -0.00142    |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 241     |\n",
      "|    iterations      | 118     |\n",
      "|    time_elapsed    | 16010   |\n",
      "|    total_timesteps | 3866624 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 119          |\n",
      "|    time_elapsed         | 16143        |\n",
      "|    total_timesteps      | 3899392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037706723 |\n",
      "|    clip_fraction        | 0.0449       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.953       |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.000127     |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 2832         |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 31.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 16275       |\n",
      "|    total_timesteps      | 3932160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005369637 |\n",
      "|    clip_fraction        | 0.0426      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.944      |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.000126    |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 2856        |\n",
      "|    policy_gradient_loss | -0.00199    |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 121          |\n",
      "|    time_elapsed         | 16407        |\n",
      "|    total_timesteps      | 3964928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028270949 |\n",
      "|    clip_fraction        | 0.0424       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.93        |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 0.000125     |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 2880         |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    value_loss           | 31.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 16539       |\n",
      "|    total_timesteps      | 3997696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004920977 |\n",
      "|    clip_fraction        | 0.0513      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.929      |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.000125    |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 2904        |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    value_loss           | 32          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 123          |\n",
      "|    time_elapsed         | 16671        |\n",
      "|    total_timesteps      | 4030464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034942734 |\n",
      "|    clip_fraction        | 0.0532       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.924       |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.000124     |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 2928         |\n",
      "|    policy_gradient_loss | -0.000882    |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 124          |\n",
      "|    time_elapsed         | 16802        |\n",
      "|    total_timesteps      | 4063232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031929878 |\n",
      "|    clip_fraction        | 0.0422       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.917       |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.000123     |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 2952         |\n",
      "|    policy_gradient_loss | -0.00205     |\n",
      "|    value_loss           | 32.1         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4080000, episode_reward=108.92 +/- 9.17\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 109         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4080000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003953023 |\n",
      "|    clip_fraction        | 0.0632      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.889      |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.000123    |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 2976        |\n",
      "|    policy_gradient_loss | -0.00161    |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 241     |\n",
      "|    iterations      | 125     |\n",
      "|    time_elapsed    | 16965   |\n",
      "|    total_timesteps | 4096000 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 126          |\n",
      "|    time_elapsed         | 17095        |\n",
      "|    total_timesteps      | 4128768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033920573 |\n",
      "|    clip_fraction        | 0.041        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.886       |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.000122     |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 3000         |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    value_loss           | 33.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 127          |\n",
      "|    time_elapsed         | 17228        |\n",
      "|    total_timesteps      | 4161536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050112135 |\n",
      "|    clip_fraction        | 0.0599       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.883       |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.000122     |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 3024         |\n",
      "|    policy_gradient_loss | -0.000156    |\n",
      "|    value_loss           | 33.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 128          |\n",
      "|    time_elapsed         | 17359        |\n",
      "|    total_timesteps      | 4194304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061435504 |\n",
      "|    clip_fraction        | 0.0484       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.889       |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.000121     |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 3048         |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    value_loss           | 32.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 129          |\n",
      "|    time_elapsed         | 17491        |\n",
      "|    total_timesteps      | 4227072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027050702 |\n",
      "|    clip_fraction        | 0.0526       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.889       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.00012      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 3072         |\n",
      "|    policy_gradient_loss | -0.0009      |\n",
      "|    value_loss           | 34.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 130          |\n",
      "|    time_elapsed         | 17624        |\n",
      "|    total_timesteps      | 4259840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032254744 |\n",
      "|    clip_fraction        | 0.0365       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.889       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.00012      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 3096         |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    value_loss           | 32.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 17763       |\n",
      "|    total_timesteps      | 4292608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003335049 |\n",
      "|    clip_fraction        | 0.0634      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.884      |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.000119    |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 3120        |\n",
      "|    policy_gradient_loss | 0.000404    |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4320000, episode_reward=107.47 +/- 8.77\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 107         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4320000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009668686 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.878      |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.000118    |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 3144        |\n",
      "|    policy_gradient_loss | -0.00197    |\n",
      "|    value_loss           | 32.9        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 241     |\n",
      "|    iterations      | 132     |\n",
      "|    time_elapsed    | 17928   |\n",
      "|    total_timesteps | 4325376 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 18060       |\n",
      "|    total_timesteps      | 4358144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004338653 |\n",
      "|    clip_fraction        | 0.056       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.863      |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.000118    |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 3168        |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 18193       |\n",
      "|    total_timesteps      | 4390912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051140424 |\n",
      "|    clip_fraction        | 0.0693      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.874      |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.000117    |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 3192        |\n",
      "|    policy_gradient_loss | -0.000528   |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 135          |\n",
      "|    time_elapsed         | 18326        |\n",
      "|    total_timesteps      | 4423680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020732386 |\n",
      "|    clip_fraction        | 0.0428       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.866       |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.000117     |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 3216         |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 136          |\n",
      "|    time_elapsed         | 18457        |\n",
      "|    total_timesteps      | 4456448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058928374 |\n",
      "|    clip_fraction        | 0.0747       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.862       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.000116     |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 3240         |\n",
      "|    policy_gradient_loss | 0.00231      |\n",
      "|    value_loss           | 34.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 137          |\n",
      "|    time_elapsed         | 18589        |\n",
      "|    total_timesteps      | 4489216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031766042 |\n",
      "|    clip_fraction        | 0.0368       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.844       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.000115     |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 3264         |\n",
      "|    policy_gradient_loss | -0.00189     |\n",
      "|    value_loss           | 34.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 18720       |\n",
      "|    total_timesteps      | 4521984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002969006 |\n",
      "|    clip_fraction        | 0.0685      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.844      |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.000115    |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 3288        |\n",
      "|    policy_gradient_loss | -0.000195   |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 139          |\n",
      "|    time_elapsed         | 18853        |\n",
      "|    total_timesteps      | 4554752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026238754 |\n",
      "|    clip_fraction        | 0.0351       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.841       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.000114     |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 3312         |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    value_loss           | 33.2         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4560000, episode_reward=107.34 +/- 9.14\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 107          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026676832 |\n",
      "|    clip_fraction        | 0.0424       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.842       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.000113     |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 3336         |\n",
      "|    policy_gradient_loss | -0.00144     |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 241     |\n",
      "|    iterations      | 140     |\n",
      "|    time_elapsed    | 19017   |\n",
      "|    total_timesteps | 4587520 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 19149       |\n",
      "|    total_timesteps      | 4620288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013535735 |\n",
      "|    clip_fraction        | 0.0608      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.832      |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.000113    |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 3360        |\n",
      "|    policy_gradient_loss | -0.00056    |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 142          |\n",
      "|    time_elapsed         | 19281        |\n",
      "|    total_timesteps      | 4653056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016953065 |\n",
      "|    clip_fraction        | 0.0717       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.843       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.000112     |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 3384         |\n",
      "|    policy_gradient_loss | 0.00336      |\n",
      "|    value_loss           | 33.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 143          |\n",
      "|    time_elapsed         | 19414        |\n",
      "|    total_timesteps      | 4685824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033141873 |\n",
      "|    clip_fraction        | 0.0474       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.835       |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.000112     |\n",
      "|    loss                 | 19           |\n",
      "|    n_updates            | 3408         |\n",
      "|    policy_gradient_loss | -0.0015      |\n",
      "|    value_loss           | 35.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 144          |\n",
      "|    time_elapsed         | 19545        |\n",
      "|    total_timesteps      | 4718592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036585196 |\n",
      "|    clip_fraction        | 0.0515       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.829       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.000111     |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 3432         |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 19678       |\n",
      "|    total_timesteps      | 4751360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002478474 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.826      |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.00011     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 3456        |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 146        |\n",
      "|    time_elapsed         | 19811      |\n",
      "|    total_timesteps      | 4784128    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00361937 |\n",
      "|    clip_fraction        | 0.0671     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.812     |\n",
      "|    explained_variance   | 0.959      |\n",
      "|    learning_rate        | 0.00011    |\n",
      "|    loss                 | 16         |\n",
      "|    n_updates            | 3480       |\n",
      "|    policy_gradient_loss | 0.000347   |\n",
      "|    value_loss           | 32.4       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4800000, episode_reward=106.39 +/- 9.23\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 106         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4800000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003284747 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.804      |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.000109    |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 3504        |\n",
      "|    policy_gradient_loss | -0.000366   |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 241     |\n",
      "|    iterations      | 147     |\n",
      "|    time_elapsed    | 19978   |\n",
      "|    total_timesteps | 4816896 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 148          |\n",
      "|    time_elapsed         | 20112        |\n",
      "|    total_timesteps      | 4849664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024786736 |\n",
      "|    clip_fraction        | 0.0284       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.793       |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.000108     |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 3528         |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 20245       |\n",
      "|    total_timesteps      | 4882432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006571913 |\n",
      "|    clip_fraction        | 0.0482      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.796      |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.000108    |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 3552        |\n",
      "|    policy_gradient_loss | -0.00146    |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 150          |\n",
      "|    time_elapsed         | 20378        |\n",
      "|    total_timesteps      | 4915200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025366335 |\n",
      "|    clip_fraction        | 0.0786       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.808       |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.000107     |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 3576         |\n",
      "|    policy_gradient_loss | 0.00119      |\n",
      "|    value_loss           | 34.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 151          |\n",
      "|    time_elapsed         | 20511        |\n",
      "|    total_timesteps      | 4947968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059290463 |\n",
      "|    clip_fraction        | 0.0365       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.801       |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.000107     |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 3600         |\n",
      "|    policy_gradient_loss | -0.00104     |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 152          |\n",
      "|    time_elapsed         | 20643        |\n",
      "|    total_timesteps      | 4980736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045582643 |\n",
      "|    clip_fraction        | 0.0303       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.802       |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.000106     |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 3624         |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 153          |\n",
      "|    time_elapsed         | 20775        |\n",
      "|    total_timesteps      | 5013504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048250537 |\n",
      "|    clip_fraction        | 0.0549       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.778       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.000105     |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 3648         |\n",
      "|    policy_gradient_loss | -0.000627    |\n",
      "|    value_loss           | 34.4         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5040000, episode_reward=107.03 +/- 9.52\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 107         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5040000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002049366 |\n",
      "|    clip_fraction        | 0.0589      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.769      |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.000105    |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 3672        |\n",
      "|    policy_gradient_loss | -1.23e-05   |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 241     |\n",
      "|    iterations      | 154     |\n",
      "|    time_elapsed    | 20937   |\n",
      "|    total_timesteps | 5046272 |\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 155          |\n",
      "|    time_elapsed         | 21070        |\n",
      "|    total_timesteps      | 5079040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033580284 |\n",
      "|    clip_fraction        | 0.0482       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.77        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.000104     |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 3696         |\n",
      "|    policy_gradient_loss | -0.000601    |\n",
      "|    value_loss           | 32.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 156          |\n",
      "|    time_elapsed         | 21200        |\n",
      "|    total_timesteps      | 5111808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038667675 |\n",
      "|    clip_fraction        | 0.0656       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.774       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.000103     |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 3720         |\n",
      "|    policy_gradient_loss | -0.000163    |\n",
      "|    value_loss           | 32           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 157         |\n",
      "|    time_elapsed         | 21329       |\n",
      "|    total_timesteps      | 5144576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016660992 |\n",
      "|    clip_fraction        | 0.0599      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.777      |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.000103    |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 3744        |\n",
      "|    policy_gradient_loss | 0.000698    |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 158          |\n",
      "|    time_elapsed         | 21459        |\n",
      "|    total_timesteps      | 5177344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020097436 |\n",
      "|    clip_fraction        | 0.0261       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.798       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.000102     |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 3768         |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    value_loss           | 34.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 159          |\n",
      "|    time_elapsed         | 21591        |\n",
      "|    total_timesteps      | 5210112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039155483 |\n",
      "|    clip_fraction        | 0.0577       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.781       |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.000102     |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 3792         |\n",
      "|    policy_gradient_loss | 0.000249     |\n",
      "|    value_loss           | 34.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 21723       |\n",
      "|    total_timesteps      | 5242880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002827386 |\n",
      "|    clip_fraction        | 0.0414      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.769      |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.000101    |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 3816        |\n",
      "|    policy_gradient_loss | -0.00143    |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 21857       |\n",
      "|    total_timesteps      | 5275648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002612341 |\n",
      "|    clip_fraction        | 0.0333      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.765      |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 3840        |\n",
      "|    policy_gradient_loss | -0.00179    |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5280000, episode_reward=106.83 +/- 9.69\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 107          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042156074 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.76        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 9.98e-05     |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 3864         |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    value_loss           | 33.6         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 241     |\n",
      "|    iterations      | 162     |\n",
      "|    time_elapsed    | 22021   |\n",
      "|    total_timesteps | 5308416 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 22152       |\n",
      "|    total_timesteps      | 5341184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004524528 |\n",
      "|    clip_fraction        | 0.083       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.756      |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 9.91e-05    |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 3888        |\n",
      "|    policy_gradient_loss | 0.00213     |\n",
      "|    value_loss           | 34.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 22284       |\n",
      "|    total_timesteps      | 5373952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007142977 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.749      |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 9.85e-05    |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 3912        |\n",
      "|    policy_gradient_loss | 0.00759     |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 22419       |\n",
      "|    total_timesteps      | 5406720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002516434 |\n",
      "|    clip_fraction        | 0.0289      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.75       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 9.79e-05    |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 3936        |\n",
      "|    policy_gradient_loss | -0.00174    |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 166          |\n",
      "|    time_elapsed         | 22552        |\n",
      "|    total_timesteps      | 5439488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030980902 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.744       |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 9.73e-05     |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 3960         |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 167          |\n",
      "|    time_elapsed         | 22684        |\n",
      "|    total_timesteps      | 5472256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048175575 |\n",
      "|    clip_fraction        | 0.0501       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.738       |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 9.66e-05     |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 3984         |\n",
      "|    policy_gradient_loss | -0.00122     |\n",
      "|    value_loss           | 34.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 168          |\n",
      "|    time_elapsed         | 22818        |\n",
      "|    total_timesteps      | 5505024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028141236 |\n",
      "|    clip_fraction        | 0.0335       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.725       |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 9.6e-05      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 4008         |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    value_loss           | 34.4         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5520000, episode_reward=105.89 +/- 9.49\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 106         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5520000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003175131 |\n",
      "|    clip_fraction        | 0.0573      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.712      |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 9.54e-05    |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 4032        |\n",
      "|    policy_gradient_loss | -0.000138   |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 240     |\n",
      "|    iterations      | 169     |\n",
      "|    time_elapsed    | 22983   |\n",
      "|    total_timesteps | 5537792 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 170          |\n",
      "|    time_elapsed         | 23115        |\n",
      "|    total_timesteps      | 5570560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042546443 |\n",
      "|    clip_fraction        | 0.0456       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.703       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 9.48e-05     |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 4056         |\n",
      "|    policy_gradient_loss | -0.00087     |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 171          |\n",
      "|    time_elapsed         | 23245        |\n",
      "|    total_timesteps      | 5603328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033103297 |\n",
      "|    clip_fraction        | 0.0771       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.706       |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 9.42e-05     |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 4080         |\n",
      "|    policy_gradient_loss | 0.00204      |\n",
      "|    value_loss           | 34.9         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 172        |\n",
      "|    time_elapsed         | 23377      |\n",
      "|    total_timesteps      | 5636096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00446371 |\n",
      "|    clip_fraction        | 0.0503     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.704     |\n",
      "|    explained_variance   | 0.956      |\n",
      "|    learning_rate        | 9.35e-05   |\n",
      "|    loss                 | 17.6       |\n",
      "|    n_updates            | 4104       |\n",
      "|    policy_gradient_loss | 0.000397   |\n",
      "|    value_loss           | 34.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 173          |\n",
      "|    time_elapsed         | 23512        |\n",
      "|    total_timesteps      | 5668864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030980967 |\n",
      "|    clip_fraction        | 0.0364       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.711       |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 9.29e-05     |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 4128         |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    value_loss           | 36.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 23646       |\n",
      "|    total_timesteps      | 5701632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010389748 |\n",
      "|    clip_fraction        | 0.0528      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.714      |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 9.23e-05    |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 4152        |\n",
      "|    policy_gradient_loss | -0.000495   |\n",
      "|    value_loss           | 35.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 175          |\n",
      "|    time_elapsed         | 23778        |\n",
      "|    total_timesteps      | 5734400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030807154 |\n",
      "|    clip_fraction        | 0.0324       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.686       |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 9.17e-05     |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 4176         |\n",
      "|    policy_gradient_loss | -0.0016      |\n",
      "|    value_loss           | 34.6         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5760000, episode_reward=105.41 +/- 9.13\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 105          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5760000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021447306 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.68        |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 9.1e-05      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 4200         |\n",
      "|    policy_gradient_loss | -0.0006      |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 240     |\n",
      "|    iterations      | 176     |\n",
      "|    time_elapsed    | 23942   |\n",
      "|    total_timesteps | 5767168 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 177          |\n",
      "|    time_elapsed         | 24073        |\n",
      "|    total_timesteps      | 5799936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073357737 |\n",
      "|    clip_fraction        | 0.0428       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.678       |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 9.04e-05     |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 4224         |\n",
      "|    policy_gradient_loss | -0.000375    |\n",
      "|    value_loss           | 33.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 24206       |\n",
      "|    total_timesteps      | 5832704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006648431 |\n",
      "|    clip_fraction        | 0.054       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.676      |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 8.98e-05    |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 4248        |\n",
      "|    policy_gradient_loss | 0.000316    |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 179         |\n",
      "|    time_elapsed         | 24338       |\n",
      "|    total_timesteps      | 5865472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002701614 |\n",
      "|    clip_fraction        | 0.0339      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.672      |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 8.92e-05    |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 4272        |\n",
      "|    policy_gradient_loss | -0.00144    |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 180          |\n",
      "|    time_elapsed         | 24470        |\n",
      "|    total_timesteps      | 5898240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030456372 |\n",
      "|    clip_fraction        | 0.0702       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.67        |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 8.86e-05     |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 4296         |\n",
      "|    policy_gradient_loss | 0.00116      |\n",
      "|    value_loss           | 35.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 24601       |\n",
      "|    total_timesteps      | 5931008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003857705 |\n",
      "|    clip_fraction        | 0.0677      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.663      |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 8.79e-05    |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 4320        |\n",
      "|    policy_gradient_loss | 0.00119     |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 182          |\n",
      "|    time_elapsed         | 24732        |\n",
      "|    total_timesteps      | 5963776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017868519 |\n",
      "|    clip_fraction        | 0.0333       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.66        |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 8.73e-05     |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 4344         |\n",
      "|    policy_gradient_loss | -0.0013      |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 24863       |\n",
      "|    total_timesteps      | 5996544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009754131 |\n",
      "|    clip_fraction        | 0.0387      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.649      |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 8.67e-05    |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 4368        |\n",
      "|    policy_gradient_loss | -0.000735   |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6000000, episode_reward=106.86 +/- 9.62\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 107          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028498755 |\n",
      "|    clip_fraction        | 0.0243       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.633       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 8.61e-05     |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 4392         |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    value_loss           | 32.8         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 240     |\n",
      "|    iterations      | 184     |\n",
      "|    time_elapsed    | 25027   |\n",
      "|    total_timesteps | 6029312 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 25158       |\n",
      "|    total_timesteps      | 6062080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002268504 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.621      |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 8.54e-05    |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 4416        |\n",
      "|    policy_gradient_loss | -0.000405   |\n",
      "|    value_loss           | 36.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 186          |\n",
      "|    time_elapsed         | 25291        |\n",
      "|    total_timesteps      | 6094848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028722319 |\n",
      "|    clip_fraction        | 0.0676       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.623       |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 8.48e-05     |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 4440         |\n",
      "|    policy_gradient_loss | 0.000664     |\n",
      "|    value_loss           | 34.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 187          |\n",
      "|    time_elapsed         | 25422        |\n",
      "|    total_timesteps      | 6127616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032493654 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.626       |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 8.42e-05     |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 4464         |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 188          |\n",
      "|    time_elapsed         | 25554        |\n",
      "|    total_timesteps      | 6160384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024193784 |\n",
      "|    clip_fraction        | 0.0381       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.616       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 8.36e-05     |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 4488         |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    value_loss           | 33.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 25686       |\n",
      "|    total_timesteps      | 6193152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005250156 |\n",
      "|    clip_fraction        | 0.0444      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.605      |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 8.3e-05     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 4512        |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    value_loss           | 32.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 190          |\n",
      "|    time_elapsed         | 25818        |\n",
      "|    total_timesteps      | 6225920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034732441 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.61        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 8.23e-05     |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 4536         |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    value_loss           | 32           |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6240000, episode_reward=106.86 +/- 9.49\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 107         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 6240000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010556501 |\n",
      "|    clip_fraction        | 0.0276      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.611      |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 8.17e-05    |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 4560        |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    value_loss           | 34.4        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 240     |\n",
      "|    iterations      | 191     |\n",
      "|    time_elapsed    | 25981   |\n",
      "|    total_timesteps | 6258688 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 192          |\n",
      "|    time_elapsed         | 26112        |\n",
      "|    total_timesteps      | 6291456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045498908 |\n",
      "|    clip_fraction        | 0.0343       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.612       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 8.11e-05     |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 4584         |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    value_loss           | 32.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 193          |\n",
      "|    time_elapsed         | 26244        |\n",
      "|    total_timesteps      | 6324224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026931125 |\n",
      "|    clip_fraction        | 0.0295       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.623       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 8.05e-05     |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 4608         |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 194          |\n",
      "|    time_elapsed         | 26374        |\n",
      "|    total_timesteps      | 6356992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045651295 |\n",
      "|    clip_fraction        | 0.0391       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.611       |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 7.98e-05     |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 4632         |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    value_loss           | 31.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 195          |\n",
      "|    time_elapsed         | 26507        |\n",
      "|    total_timesteps      | 6389760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020308462 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.605       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 7.92e-05     |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 4656         |\n",
      "|    policy_gradient_loss | -0.00055     |\n",
      "|    value_loss           | 32.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 196          |\n",
      "|    time_elapsed         | 26638        |\n",
      "|    total_timesteps      | 6422528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014706948 |\n",
      "|    clip_fraction        | 0.0419       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.602       |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 7.86e-05     |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 4680         |\n",
      "|    policy_gradient_loss | -0.000585    |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 197          |\n",
      "|    time_elapsed         | 26770        |\n",
      "|    total_timesteps      | 6455296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017789977 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.608       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 7.8e-05      |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 4704         |\n",
      "|    policy_gradient_loss | -0.00111     |\n",
      "|    value_loss           | 32.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=6480000, episode_reward=106.36 +/- 9.92\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 106          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6480000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018966193 |\n",
      "|    clip_fraction        | 0.0274       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.593       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 7.73e-05     |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 4728         |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    value_loss           | 32.3         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 240     |\n",
      "|    iterations      | 198     |\n",
      "|    time_elapsed    | 26934   |\n",
      "|    total_timesteps | 6488064 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 27068       |\n",
      "|    total_timesteps      | 6520832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009903185 |\n",
      "|    clip_fraction        | 0.0411      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.578      |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 7.67e-05    |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 4752        |\n",
      "|    policy_gradient_loss | -0.000876   |\n",
      "|    value_loss           | 31.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 200          |\n",
      "|    time_elapsed         | 27200        |\n",
      "|    total_timesteps      | 6553600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027029305 |\n",
      "|    clip_fraction        | 0.0264       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.587       |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 7.61e-05     |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 4776         |\n",
      "|    policy_gradient_loss | -0.00113     |\n",
      "|    value_loss           | 34.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 201         |\n",
      "|    time_elapsed         | 27332       |\n",
      "|    total_timesteps      | 6586368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005068078 |\n",
      "|    clip_fraction        | 0.0385      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.593      |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 7.55e-05    |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 4800        |\n",
      "|    policy_gradient_loss | -0.000789   |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 202          |\n",
      "|    time_elapsed         | 27465        |\n",
      "|    total_timesteps      | 6619136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024340777 |\n",
      "|    clip_fraction        | 0.0379       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.589       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 7.49e-05     |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 4824         |\n",
      "|    policy_gradient_loss | -0.00111     |\n",
      "|    value_loss           | 32.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 203          |\n",
      "|    time_elapsed         | 27599        |\n",
      "|    total_timesteps      | 6651904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030166802 |\n",
      "|    clip_fraction        | 0.0333       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.572       |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 7.42e-05     |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 4848         |\n",
      "|    policy_gradient_loss | -0.00128     |\n",
      "|    value_loss           | 33.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 241          |\n",
      "|    iterations           | 204          |\n",
      "|    time_elapsed         | 27732        |\n",
      "|    total_timesteps      | 6684672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041210195 |\n",
      "|    clip_fraction        | 0.0531       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.57        |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 7.36e-05     |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 4872         |\n",
      "|    policy_gradient_loss | 0.0023       |\n",
      "|    value_loss           | 34.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 27864       |\n",
      "|    total_timesteps      | 6717440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009468531 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.553      |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 7.3e-05     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 4896        |\n",
      "|    policy_gradient_loss | -0.00121    |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6720000, episode_reward=106.64 +/- 9.60\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 107          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6720000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025475656 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 7.24e-05     |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 4920         |\n",
      "|    policy_gradient_loss | -0.00141     |\n",
      "|    value_loss           | 31.8         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 240     |\n",
      "|    iterations      | 206     |\n",
      "|    time_elapsed    | 28030   |\n",
      "|    total_timesteps | 6750208 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 207          |\n",
      "|    time_elapsed         | 28163        |\n",
      "|    total_timesteps      | 6782976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027584839 |\n",
      "|    clip_fraction        | 0.0298       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 7.17e-05     |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 4944         |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    value_loss           | 34.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 208          |\n",
      "|    time_elapsed         | 28296        |\n",
      "|    total_timesteps      | 6815744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016474476 |\n",
      "|    clip_fraction        | 0.0289       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.51        |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 7.11e-05     |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 4968         |\n",
      "|    policy_gradient_loss | -0.000827    |\n",
      "|    value_loss           | 33.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 209          |\n",
      "|    time_elapsed         | 28429        |\n",
      "|    total_timesteps      | 6848512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030780025 |\n",
      "|    clip_fraction        | 0.0276       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 7.05e-05     |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 4992         |\n",
      "|    policy_gradient_loss | -0.00121     |\n",
      "|    value_loss           | 33.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 210          |\n",
      "|    time_elapsed         | 28561        |\n",
      "|    total_timesteps      | 6881280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023391577 |\n",
      "|    clip_fraction        | 0.0404       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 6.99e-05     |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 5016         |\n",
      "|    policy_gradient_loss | 3.14e-05     |\n",
      "|    value_loss           | 33.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 211          |\n",
      "|    time_elapsed         | 28692        |\n",
      "|    total_timesteps      | 6914048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027441084 |\n",
      "|    clip_fraction        | 0.0395       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 6.93e-05     |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 5040         |\n",
      "|    policy_gradient_loss | -0.000878    |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 28824       |\n",
      "|    total_timesteps      | 6946816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008720444 |\n",
      "|    clip_fraction        | 0.0389      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.48       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 6.86e-05    |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 5064        |\n",
      "|    policy_gradient_loss | -0.000414   |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6960000, episode_reward=105.59 +/- 9.71\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 106          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6960000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036379262 |\n",
      "|    clip_fraction        | 0.0412       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.471       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 6.8e-05      |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 5088         |\n",
      "|    policy_gradient_loss | 0.00014      |\n",
      "|    value_loss           | 33.3         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 240     |\n",
      "|    iterations      | 213     |\n",
      "|    time_elapsed    | 28988   |\n",
      "|    total_timesteps | 6979584 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 29122       |\n",
      "|    total_timesteps      | 7012352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005955516 |\n",
      "|    clip_fraction        | 0.0372      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.47       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 6.74e-05    |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 5112        |\n",
      "|    policy_gradient_loss | -0.0012     |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 215          |\n",
      "|    time_elapsed         | 29254        |\n",
      "|    total_timesteps      | 7045120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014264111 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 6.68e-05     |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 5136         |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    value_loss           | 33.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 216          |\n",
      "|    time_elapsed         | 29387        |\n",
      "|    total_timesteps      | 7077888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019955367 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.464       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 6.61e-05     |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 5160         |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    value_loss           | 33.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 217          |\n",
      "|    time_elapsed         | 29519        |\n",
      "|    total_timesteps      | 7110656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022189547 |\n",
      "|    clip_fraction        | 0.031        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.459       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 6.55e-05     |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 5184         |\n",
      "|    policy_gradient_loss | -0.000584    |\n",
      "|    value_loss           | 32.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 218          |\n",
      "|    time_elapsed         | 29652        |\n",
      "|    total_timesteps      | 7143424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043336162 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.449       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 6.49e-05     |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 5208         |\n",
      "|    policy_gradient_loss | -0.000384    |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 219          |\n",
      "|    time_elapsed         | 29783        |\n",
      "|    total_timesteps      | 7176192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017311156 |\n",
      "|    clip_fraction        | 0.0318       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.446       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 6.43e-05     |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 5232         |\n",
      "|    policy_gradient_loss | -0.000648    |\n",
      "|    value_loss           | 32.5         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7200000, episode_reward=106.59 +/- 9.97\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 107          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019258936 |\n",
      "|    clip_fraction        | 0.0379       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.434       |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 6.37e-05     |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 5256         |\n",
      "|    policy_gradient_loss | -0.000456    |\n",
      "|    value_loss           | 31.6         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 240     |\n",
      "|    iterations      | 220     |\n",
      "|    time_elapsed    | 29947   |\n",
      "|    total_timesteps | 7208960 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 221          |\n",
      "|    time_elapsed         | 30079        |\n",
      "|    total_timesteps      | 7241728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018485881 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.436       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 6.3e-05      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 5280         |\n",
      "|    policy_gradient_loss | -0.00121     |\n",
      "|    value_loss           | 32.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 222          |\n",
      "|    time_elapsed         | 30210        |\n",
      "|    total_timesteps      | 7274496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024592374 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.433       |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 6.24e-05     |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 5304         |\n",
      "|    policy_gradient_loss | -0.000986    |\n",
      "|    value_loss           | 34.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 223         |\n",
      "|    time_elapsed         | 30341       |\n",
      "|    total_timesteps      | 7307264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001322661 |\n",
      "|    clip_fraction        | 0.037       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.429      |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 6.18e-05    |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 5328        |\n",
      "|    policy_gradient_loss | -0.000295   |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 224          |\n",
      "|    time_elapsed         | 30474        |\n",
      "|    total_timesteps      | 7340032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013827245 |\n",
      "|    clip_fraction        | 0.0506       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.427       |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 6.12e-05     |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 5352         |\n",
      "|    policy_gradient_loss | 0.0018       |\n",
      "|    value_loss           | 30.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 225         |\n",
      "|    time_elapsed         | 30609       |\n",
      "|    total_timesteps      | 7372800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001227725 |\n",
      "|    clip_fraction        | 0.0237      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.423      |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 6.05e-05    |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 5376        |\n",
      "|    policy_gradient_loss | -0.000915   |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 226          |\n",
      "|    time_elapsed         | 30743        |\n",
      "|    total_timesteps      | 7405568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028453295 |\n",
      "|    clip_fraction        | 0.0287       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.425       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 5.99e-05     |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 5400         |\n",
      "|    policy_gradient_loss | -0.000718    |\n",
      "|    value_loss           | 32.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 30878       |\n",
      "|    total_timesteps      | 7438336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004415909 |\n",
      "|    clip_fraction        | 0.0319      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.431      |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 5.93e-05    |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 5424        |\n",
      "|    policy_gradient_loss | -0.00112    |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=7440000, episode_reward=107.07 +/- 9.59\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 107         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 7440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004028997 |\n",
      "|    clip_fraction        | 0.0207      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.424      |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 5.87e-05    |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 5448        |\n",
      "|    policy_gradient_loss | -0.00117    |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 240     |\n",
      "|    iterations      | 228     |\n",
      "|    time_elapsed    | 31043   |\n",
      "|    total_timesteps | 7471104 |\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 229          |\n",
      "|    time_elapsed         | 31174        |\n",
      "|    total_timesteps      | 7503872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017289201 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.412       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 5.8e-05      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 5472         |\n",
      "|    policy_gradient_loss | -0.000707    |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 230          |\n",
      "|    time_elapsed         | 31308        |\n",
      "|    total_timesteps      | 7536640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022292617 |\n",
      "|    clip_fraction        | 0.0264       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 5.74e-05     |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 5496         |\n",
      "|    policy_gradient_loss | -0.000549    |\n",
      "|    value_loss           | 33.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 31440       |\n",
      "|    total_timesteps      | 7569408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002199767 |\n",
      "|    clip_fraction        | 0.0196      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.407      |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 5.68e-05    |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 5520        |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 232          |\n",
      "|    time_elapsed         | 31573        |\n",
      "|    total_timesteps      | 7602176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020230939 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.409       |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 5.62e-05     |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 5544         |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    value_loss           | 34.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 233          |\n",
      "|    time_elapsed         | 31706        |\n",
      "|    total_timesteps      | 7634944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018253772 |\n",
      "|    clip_fraction        | 0.0308       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 5.56e-05     |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 5568         |\n",
      "|    policy_gradient_loss | -0.000937    |\n",
      "|    value_loss           | 32.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 234          |\n",
      "|    time_elapsed         | 31838        |\n",
      "|    total_timesteps      | 7667712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048327395 |\n",
      "|    clip_fraction        | 0.0303       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.412       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 5.49e-05     |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 5592         |\n",
      "|    policy_gradient_loss | -0.00078     |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7680000, episode_reward=105.82 +/- 9.10\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 106          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7680000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016384579 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.404       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 5.43e-05     |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 5616         |\n",
      "|    policy_gradient_loss | -0.000778    |\n",
      "|    value_loss           | 32.4         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 240     |\n",
      "|    iterations      | 235     |\n",
      "|    time_elapsed    | 32002   |\n",
      "|    total_timesteps | 7700480 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 236          |\n",
      "|    time_elapsed         | 32133        |\n",
      "|    total_timesteps      | 7733248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014582423 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 5.37e-05     |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 5640         |\n",
      "|    policy_gradient_loss | -0.000259    |\n",
      "|    value_loss           | 32.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 32266       |\n",
      "|    total_timesteps      | 7766016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002723705 |\n",
      "|    clip_fraction        | 0.0304      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.405      |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 5.31e-05    |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 5664        |\n",
      "|    policy_gradient_loss | -0.000326   |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 238          |\n",
      "|    time_elapsed         | 32400        |\n",
      "|    total_timesteps      | 7798784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019690027 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.404       |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 5.24e-05     |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 5688         |\n",
      "|    policy_gradient_loss | -0.00109     |\n",
      "|    value_loss           | 33.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 239          |\n",
      "|    time_elapsed         | 32532        |\n",
      "|    total_timesteps      | 7831552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022094673 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.399       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 5.18e-05     |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 5712         |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 240          |\n",
      "|    time_elapsed         | 32664        |\n",
      "|    total_timesteps      | 7864320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017810351 |\n",
      "|    clip_fraction        | 0.0326       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.402       |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 5.12e-05     |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 5736         |\n",
      "|    policy_gradient_loss | -0.000647    |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 241          |\n",
      "|    time_elapsed         | 32798        |\n",
      "|    total_timesteps      | 7897088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025467037 |\n",
      "|    clip_fraction        | 0.029        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.402       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 5.06e-05     |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 5760         |\n",
      "|    policy_gradient_loss | -0.000923    |\n",
      "|    value_loss           | 32.6         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7920000, episode_reward=106.85 +/- 9.68\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 107          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7920000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014341539 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.397       |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 5784         |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    value_loss           | 34.8         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 240     |\n",
      "|    iterations      | 242     |\n",
      "|    time_elapsed    | 32962   |\n",
      "|    total_timesteps | 7929856 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 243          |\n",
      "|    time_elapsed         | 33095        |\n",
      "|    total_timesteps      | 7962624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018705903 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.39        |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 4.93e-05     |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 5808         |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    value_loss           | 34.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 244          |\n",
      "|    time_elapsed         | 33260        |\n",
      "|    total_timesteps      | 7995392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019738327 |\n",
      "|    clip_fraction        | 0.0467       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.386       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 4.87e-05     |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 5832         |\n",
      "|    policy_gradient_loss | 0.0018       |\n",
      "|    value_loss           | 33.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", env, learning_rate = learning_rate, batch_size = 2048, n_epochs = 24, policy_kwargs = policy_kwargs, gamma = 0.99,  verbose=1, tensorboard_log = \"C:/Users/kubaw/Desktop/DELFT/THESIS\\CODE/TEST_MODELS/LOGS/logs\")\n",
    "TIMESTEPS = 10000000\n",
    "model.learn(total_timesteps = TIMESTEPS, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa5c9e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r\"C:\\Users\\kubaw\\Desktop\\DELFT\\THESIS\\CODE\\TEST_MODELS\\32_ENV_JA_LOW_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c69a9d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(r\"C:\\Users\\kubaw\\Desktop\\DELFT\\THESIS\\CODE\\TEST_MODELS\\32_ENV_JA_HIGH_2\\best_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d69968a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Act: [6 6] \n",
      " Obs: [0.9885073  0.9697379  0.8736459  0.9415653  0.91794175 0.84082365\n",
      " 1.0022224  0.98446006 1.0024734  0.9947046  0.87113607 0.98956496\n",
      " 0.         0.91676897 0.8619849  0.910265   0.9815112  0.8916455\n",
      " 0.99362576 0.87393075 0.99298745 0.98399216 0.93280506 0.8674039\n",
      " 0.94918245 0.98852605 0.8918726  0.8924189  0.98943555 0.93925124\n",
      " 0.86511976 0.         0.05560338 0.06768829 0.00636943 0.68792313\n",
      " 0.30723476 0.06991712 0.7552     0.9163851 ] \n",
      " Balance -2700.876967822199\n",
      "Act: [1 0] \n",
      " Obs: [0.97678894 0.96784407 0.85785264 0.92827374 0.89972305 0.8319673\n",
      " 0.9901795  0.9718317  0.9979446  0.9917035  0.8615182  0.9896618\n",
      " 0.9833173  0.91052663 0.8578547  0.90303415 0.96781325 0.88546246\n",
      " 0.97719145 0.87464756 0.9822516  0.97714096 0.923392   0.857642\n",
      " 0.93968487 0.98446095 0.8821544  0.8816431  0.9726597  0.93358606\n",
      " 0.86204153 0.         0.08181785 0.08320452 0.00636943 0.6386011\n",
      " 0.09698168 0.07411215 0.176      0.8858736 ] \n",
      " Balance 4345.74493741363\n",
      "Act: [0 0] \n",
      " Obs: [0.96398515 0.9685171  0.8467762  0.92069346 0.901704   0.83437544\n",
      " 0.97391444 0.9547406  0.98741865 0.97853774 0.8577103  0.978214\n",
      " 0.97749454 0.9039472  0.84795403 0.8987921  0.9531155  0.89079934\n",
      " 0.9700271  0.86725056 0.96713436 0.961292   0.92651486 0.8476441\n",
      " 0.92681134 0.98740005 0.8686388  0.87043685 0.9523172  0.9234876\n",
      " 0.8557434  0.         0.11012731 0.06143477 0.0063716  0.6231167\n",
      " 0.05526771 0.07855888 0.3424     0.87568957] \n",
      " Balance 4790.889757550117\n",
      "Act: [1 0] \n",
      " Obs: [0.95448846 0.954935   0.840266   0.9053241  0.89311826 0.98005044\n",
      " 0.9730234  0.9588351  0.98624665 0.9688234  0.85284305 0.9729463\n",
      " 0.96620363 0.8947002  0.8339366  0.88355476 0.9359103  0.87497646\n",
      " 0.9599212  0.86422735 0.96490616 0.9517293  0.91492844 0.84762317\n",
      " 0.9137828  0.97770816 0.8607028  0.86081105 0.94250244 0.91729003\n",
      " 0.85366285 0.         0.12075439 0.08610334 0.07201134 0.58854717\n",
      " 0.07641841 0.0832724  0.1504     0.80922097] \n",
      " Balance 4089.825596069804\n",
      "Act: [0 0] \n",
      " Obs: [0.9509919  0.95158607 0.8326632  0.8977816  0.8812841  0.9833574\n",
      " 0.96631294 0.9516443  0.9805596  0.952214   0.8412194  0.97335327\n",
      " 0.9556203  0.8788336  0.8342774  0.86838865 0.9316199  0.8674972\n",
      " 0.95162374 0.86055475 0.958277   0.9456363  0.9105492  0.83710593\n",
      " 0.91108507 0.96123934 0.85681015 0.8446101  0.9306287  0.90914965\n",
      " 0.85080904 0.         0.1232445  0.04666034 0.08143057 0.5843151\n",
      " 0.05750053 0.         0.944      0.7539813 ] \n",
      " Balance 4297.261338458567\n",
      "Act: [1 0] \n",
      " Obs: [0.9449548  0.9403507  0.9977937  0.8934435  0.86239815 0.97084796\n",
      " 0.9546981  0.9378231  0.9740259  0.9468064  0.82681924 0.9648066\n",
      " 0.95658165 0.882428   0.8288365  0.85622126 0.9204023  0.8622953\n",
      " 0.9386897  0.85953283 0.948657   0.9298181  0.8989956  0.82997674\n",
      " 0.9062188  0.95715654 0.8440889  0.8358962  0.92440075 0.90212846\n",
      " 0.83750945 0.         0.1527921  0.04663157 0.08150633 0.5451549\n",
      " 0.07923323 0.         0.3672     0.69133717] \n",
      " Balance 3312.897931235778\n",
      "Act: [2 0] \n",
      " Obs: [0.93447715 0.9295059  0.99067855 0.8820121  0.8554988  0.96996546\n",
      " 0.9480282  0.92456645 0.9669972  0.9436866  1.0081465  0.9587469\n",
      " 0.94879526 0.87184304 0.9946296  0.84727514 0.908904   0.8577549\n",
      " 0.9420629  0.84979767 0.93659484 0.9244178  0.8916773  0.8131589\n",
      " 0.89754045 0.94014466 0.8292862  0.826042   0.90832347 0.8995042\n",
      " 0.8256672  0.         0.16725102 0.05104438 0.08182629 0.49010324\n",
      " 0.09961167 0.         0.6096     0.68307835] \n",
      " Balance 2364.739910532227\n",
      "Act: [0 1] \n",
      " Obs: [0.92471886 0.92926836 0.9814383  0.86909294 0.83455634 0.9615278\n",
      " 0.9458967  0.91204435 0.9605859  0.93317527 0.99480546 0.95868427\n",
      " 0.9411758  0.86134535 0.985217   0.8445974  0.8924927  0.85419405\n",
      " 0.9369325  0.839383   0.9306115  0.9103871  0.8801777  0.81539005\n",
      " 0.89048123 0.93200564 0.8327364  0.8259011  0.9018534  0.8875495\n",
      " 0.80982924 0.99627185 0.20275977 0.06188152 0.0818263  0.45636398\n",
      " 0.10251985 0.         0.3152     0.6575702 ] \n",
      " Balance 2979.7119478023833\n",
      "Act: [0 0] \n",
      " Obs: [0.9161298  0.92599523 0.9681699  0.87129074 0.82912844 0.9513356\n",
      " 0.9388535  0.89919126 0.95265275 0.9255914  0.9963413  0.94829535\n",
      " 0.93420374 0.862337   0.9773134  0.84278584 0.8828383  0.8447652\n",
      " 0.         0.8251949  0.9201484  0.9068189  0.86806667 0.8134289\n",
      " 0.8788428  0.9191375  0.82010573 0.8032529  0.8876276  0.87460315\n",
      " 0.79774547 0.98899025 0.2386885  0.07284683 0.0818263  0.47426823\n",
      " 0.06424817 0.         0.7088     0.6122137 ] \n",
      " Balance 3391.301865994967\n",
      "Act: [1 5] \n",
      " Obs: [0.9143672  0.91615206 0.9598098  0.85868704 1.0026408  0.94119936\n",
      " 0.92853934 0.883985   0.9328307  0.90987605 0.9871022  0.9413378\n",
      " 0.927572   0.85571194 0.9710357  0.8349523  0.8817971  0.8374548\n",
      " 1.0122421  0.8226733  0.9069449  0.89958656 0.8578012  0.9994133\n",
      " 0.8668401  0.907576   1.0012059  0.99435484 0.8834705  0.8579023\n",
      " 1.0001061  0.9850513  0.28377    0.08660553 0.09350998 0.42118904\n",
      " 0.19476996 0.         0.9376     0.5853047 ] \n",
      " Balance -165.05071485319195\n",
      "Act: [4 1] \n",
      " Obs: [0.91130596 0.9003467  0.94440573 1.0046318  1.0006098  0.93409854\n",
      " 0.9283471  0.99965787 0.9230877  0.90195614 0.9702203  0.9211141\n",
      " 0.9195784  0.9997181  0.96295553 1.0073482  0.8688184  0.8339672\n",
      " 1.0007764  1.0061136  0.9061287  0.8935351  0.85215116 0.99016356\n",
      " 0.85687155 0.9014317  1.0007192  0.9907855  0.88229614 0.8475024\n",
      " 0.9855787  0.97792226 0.33824828 0.1032321  0.25190422 0.40091375\n",
      " 0.16377823 0.         0.1624     0.52492416] \n",
      " Balance 326.7123657682928\n",
      "Act: [0 0] \n",
      " Obs: [0.9080356  0.89041775 0.9288602  0.9869969  0.9818762  0.9238564\n",
      " 0.920538   0.9908738  0.923938   0.884309   0.9569217  0.90877694\n",
      " 0.91621494 0.9978977  0.9654504  0.9942894  0.8603796  0.8215446\n",
      " 0.9981398  0.99979347 0.90579957 0.88775384 0.84444326 0.977952\n",
      " 0.8486832  0.90103316 0.9875016  0.98129386 0.875394   0.84240174\n",
      " 0.9845495  0.9763861  0.37166438 0.11343057 0.25190422 0.36770332\n",
      " 0.06818068 0.         0.3264     0.4908168 ] \n",
      " Balance 2655.8276727281223\n",
      "Act: [0 1] \n",
      " Obs: [0.9106398  0.8793513  0.9200846  0.98314214 0.9752606  0.91924655\n",
      " 0.90969974 0.9948403  0.9110652  0.88179094 0.95364183 0.8968958\n",
      " 0.912191   0.9916853  0.95795083 0.985367   0.8580645  1.0356675\n",
      " 0.99137664 0.98852074 0.8996693  0.87941796 0.8276494  0.964537\n",
      " 0.83807963 0.89474374 0.9746088  0.9806999  0.8600562  0.8371604\n",
      " 0.97710145 0.9665278  0.39184293 0.11958899 0.2539229  0.36366615\n",
      " 0.0917994  0.         0.0392     0.4446974 ] \n",
      " Balance 1858.9843869297788\n",
      "Act: [0 1] \n",
      " Obs: [0.90744376 0.         0.9031425  0.9721088  0.9722263  0.9083927\n",
      " 0.91120106 0.98735744 0.9024685  0.         0.94650495 0.88778365\n",
      " 0.9107757  0.99700147 0.9475973  0.98217386 0.8509998  1.0223787\n",
      " 0.98740125 0.9746134  0.89520675 0.86783046 1.0299493  0.9582825\n",
      " 0.8363935  0.88640046 0.9699071  0.9745364  0.85380805 0.8291767\n",
      " 0.97467476 0.957858   0.4189899  0.12787414 0.26035252 0.32391936\n",
      " 0.09356177 0.         0.9216     0.3995324 ] \n",
      " Balance 1598.706798376407\n",
      "Act: [5 1] \n",
      " Obs: [0.9010672  1.0382563  1.0388963  0.9692167  0.         0.8989347\n",
      " 0.89735866 0.97717446 1.0339764  1.0334507  0.9292673  1.0329014\n",
      " 0.9045467  0.9966851  0.9380117  0.97299534 0.8365771  1.0133256\n",
      " 0.9708973  0.96716595 0.88924235 0.86315084 1.0287893  0.9405061\n",
      " 0.8298887  0.88128227 0.96319777 0.95878047 0.8410418  1.0354967\n",
      " 0.96144223 0.9545613  0.45168078 0.13785127 0.26035252 0.29901138\n",
      " 0.22779842 0.         0.2816     0.3642319 ] \n",
      " Balance -1130.1013125418033\n",
      "Act: [1 0] \n",
      " Obs: [0.89670134 1.02762    1.0322579  0.95548105 1.0217556  0.88915765\n",
      " 0.88439137 0.9676165  1.0312456  1.0195343  0.91742563 1.0221123\n",
      " 0.90443003 0.9954615  0.9292319  0.9575389  0.8262635  1.0051073\n",
      " 0.95506406 0.9608852  0.88534987 0.84772384 1.0221139  0.92945224\n",
      " 0.8209826  0.87827593 0.95612794 0.9474465  0.8115354  1.0283005\n",
      " 0.9551959  0.9522547  0.47229242 0.14414187 0.26099274 0.26069102\n",
      " 0.11144057 0.         0.8144     0.35146472] \n",
      " Balance 1169.6542776737517\n",
      "Act: [1 0] \n",
      " Obs: [0.8850017  1.0211239  1.032626   0.9392371  1.0252893  0.8800972\n",
      " 1.0260572  0.95026666 1.0272713  1.0097082  0.90057    1.0163338\n",
      " 0.90072817 0.99340296 0.91250014 0.9495049  0.8073675  1.0002474\n",
      " 0.93128407 0.9497165  0.8692569  0.8367526  1.0095506  0.92730516\n",
      " 0.81146103 0.87498933 0.94179446 0.9393474  0.80478215 1.0215982\n",
      " 0.9487456  0.95323443 0.53164107 0.16225484 0.26099396 0.24202032\n",
      " 0.09867205 0.         0.8792     0.36973968] \n",
      " Balance 1103.1191338830558\n",
      "Act: [1 1] \n",
      " Obs: [0.8770176  1.001603   1.0273366  0.9277618  1.0282172  1.0350685\n",
      " 1.0148207  0.94720244 1.0180486  1.0037022  0.88553226 1.0026398\n",
      " 0.88367826 0.98557967 0.8982002  0.9422424  0.7896472  0.9946655\n",
      " 0.9277813  0.94502383 0.86368936 0.8293465  1.0068271  0.9218199\n",
      " 0.8058663  0.86991334 0.942979   0.92294174 1.0336202  1.0162383\n",
      " 0.9465263  0.94520855 0.5099442  0.15563305 0.26099396 0.235565\n",
      " 0.12210872 0.         0.4176     0.3832176 ] \n",
      " Balance 770.7775257196053\n",
      "Act: [1 0] \n",
      " Obs: [1.0327888  0.9980837  1.0203469  0.9199944  1.0301068  1.0289841\n",
      " 1.0151256  0.9511056  1.0165454  0.9930318  0.8809527  0.9958503\n",
      " 0.87903893 0.97476923 0.8889144  0.93309987 0.7687788  1.000857\n",
      " 0.9135008  0.9372032  0.8523697  0.81911296 0.993717   0.9178731\n",
      " 0.7951285  0.86836994 0.9421824  0.         1.028039   1.0035567\n",
      " 0.94301444 0.9354382  0.48178864 0.14704007 0.29895976 0.26204482\n",
      " 0.1066378  0.         0.46       0.35975975] \n",
      " Balance 1321.1392345623728\n",
      "Act: [0 1] \n",
      " Obs: [1.0260198  0.9920204  1.019571   0.9190422  1.0140554  1.0250148\n",
      " 1.0056269  0.94327956 1.0092632  0.98355705 0.88198483 0.988559\n",
      " 0.8693474  0.9718183  0.8886153  0.92653435 0.7642833  0.9918841\n",
      " 0.89876467 0.9307872  0.8399414  0.81355995 0.98881483 0.9024089\n",
      " 0.7924656  0.86228555 0.9420111  1.0409267  1.0186927  1.0095798\n",
      " 0.94033927 0.93117404 0.5903859  0.18018354 0.30064538 0.24416924\n",
      " 0.11824747 0.         0.3472     0.32824793] \n",
      " Balance 1190.1763514424863\n",
      "Act: [0 1] \n",
      " Obs: [1.0182186  0.9858249  1.0060432  0.91261053 1.0082334  1.023479\n",
      " 1.0037584  0.93507606 1.0000647  0.9772643  0.8810994  0.98614615\n",
      " 0.87738    0.9687797  0.8799552  0.91505814 1.0455942  0.98444486\n",
      " 0.8890545  0.91044015 0.8329607  0.795702   0.9826455  0.881742\n",
      " 0.78164184 0.856257   0.9350383  1.0370252  1.015262   0.9998928\n",
      " 0.924288   0.92605495 0.5608965  0.17118351 0.30064538 0.21294944\n",
      " 0.10655101 0.         0.0112     0.31555966] \n",
      " Balance 1010.6118297546707\n",
      "Act: [0 0] \n",
      " Obs: [1.0157083  0.98870015 0.9983678  0.89551127 0.99587584 1.006237\n",
      " 0.9939004  0.9309533  0.99757177 0.97643715 0.87663555 0.9787255\n",
      " 0.8700251  0.9663381  0.87626004 0.90629333 1.030826   0.98191154\n",
      " 0.8886947  0.893603   0.8267185  0.787045   0.97598696 0.8709671\n",
      " 0.78120404 0.8387283  0.9200587  1.035266   1.006946   0.98591816\n",
      " 0.9099639  0.9195856  0.6139423  0.1873729  0.31798837 0.20473099\n",
      " 0.08311187 0.         0.3968     0.28620404] \n",
      " Balance 1347.3275961637619\n",
      "Act: [0 0] \n",
      " Obs: [1.0103748  0.9780709  0.99365133 0.         0.98155916 1.0089804\n",
      " 0.9873204  0.92077446 0.97952276 0.96566975 0.869997   0.97472185\n",
      " 0.86884177 0.9521774  0.87558764 0.89691085 1.0231564  0.96292406\n",
      " 0.8921809  0.8885887  0.80861264 0.77620435 0.9663639  0.86839724\n",
      " 0.76911837 0.82353836 0.91334254 1.0239297  1.0006001  0.9828415\n",
      " 0.89618516 0.9032532  0.6373872  0.19452818 0.33638316 0.21383227\n",
      " 0.08477411 0.         0.7376     0.28053942] \n",
      " Balance 1168.2468548684071\n",
      "Act: [1 0] \n",
      " Obs: [1.0054051  0.9685647  0.9961665  1.0440243  0.9781371  1.0001401\n",
      " 0.9840563  0.9178345  0.9702802  0.948157   0.8551235  0.9645481\n",
      " 0.8553653  0.9413968  0.86140066 0.8824434  1.016114   0.95001537\n",
      " 0.8828652  0.8794538  0.7954573  0.7586597  0.94910216 0.86003256\n",
      " 0.76735085 0.         0.9111212  1.0180999  0.98899156 0.9722868\n",
      " 0.89134    0.8912172  0.6643138  0.20274606 0.3368387  0.21649373\n",
      " 0.12535226 0.         0.1048     0.28505012] \n",
      " Balance 751.8391811612858\n",
      "Act: [0 0] \n",
      " Obs: [0.9906556  0.9589454  0.98940736 1.0335581  0.97006243 1.0024989\n",
      " 0.97710466 0.9183342  0.9603446  0.94232863 0.         0.95701224\n",
      " 0.8525911  0.9263887  0.84485656 0.87786597 0.9987601  0.9386357\n",
      " 0.         0.8678658  0.7747505  0.7416647  0.9413823  0.84837186\n",
      " 0.7567787  0.         0.8996066  1.0081737  0.9818632  0.96598774\n",
      " 0.8871473  0.8796762  0.6643138  0.20274606 0.3368387  0.21649373\n",
      " 0.08544276 0.         0.456      0.28505012] \n",
      " Balance 1126.9483318813625\n",
      "total financial balance: (eur) 101578.66443625219 total environmental balance: (kgco2) 42976.415830753656 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate1(1, env_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84b1e177",
   "metadata": {
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def evaluate2(episodes, environment, model):\n",
    "    \n",
    "    mean_irr = 0\n",
    "    mean_fin_balance = 0\n",
    "    irr = 0\n",
    "    fin_balance = 0\n",
    "    count = 0\n",
    "    npv = 0\n",
    "    list_npv = []\n",
    "    env_balance = 0\n",
    "    mean_env_balance = 0\n",
    "\n",
    "    for ep in range(episodes):\n",
    "\n",
    "        obs, _ = environment.reset()  # Unpack the tuple and ignore the info part\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs)  # Now obs is just the observation array\n",
    "            obs, reward, done, truncated, info = environment.step(action)\n",
    "            # Extracting the 2nd and 3rd key-value pairs\n",
    "            keys = list(info.keys())\n",
    "            values = list(info.values())\n",
    "\n",
    "            # Getting the 2nd key-value pair\n",
    "            second_value = values[2]\n",
    "\n",
    "            # Getting the 3rd key-value pair\n",
    "            fourth_value = values[4]\n",
    "            \n",
    "            fith_value = values[5]\n",
    "        \n",
    "        fin_balance += second_value\n",
    "        npv += fith_value\n",
    "        count += 1\n",
    "        \n",
    "        env_balance += second_value\n",
    "        \n",
    "        list_npv.append(fourth_value)\n",
    "            \n",
    "    mean_fin_balance = fin_balance/count\n",
    "    mean_npv = npv/count\n",
    "    mean_env_balance = env_balance / count\n",
    "\n",
    "    #print(mean_npv)\n",
    "\n",
    "    environment.close()\n",
    "    \n",
    "    return(mean_npv, mean_env_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ac8ec3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28832.331212101613, 35878.91282684316)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate2(1000, env_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e0af1d69",
   "metadata": {
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def basepolicy1(episodes, environment):\n",
    "    \n",
    "    mean_irr = 0\n",
    "    mean_fin_balance = 0\n",
    "    irr = 0\n",
    "    fin_balance = 0\n",
    "    count = 0\n",
    "    irr_count = 0\n",
    "    npv = 0\n",
    "    list_npv = []\n",
    "    env_balance = 0\n",
    "    mean_env_balance = 0\n",
    "\n",
    "    for ep in range(episodes):\n",
    "\n",
    "        obs, _ = environment.reset()  # Unpack the tuple and ignore the info part\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            \n",
    "            action = np.array([0, 0])\n",
    "            for i, n in enumerate(obs):\n",
    "                if i < 32:\n",
    "                    if i < 16:\n",
    "                        if n < 0.80:\n",
    "                            action[0] += 1\n",
    "                    if i >= 16:\n",
    "                        if n < 0.80:\n",
    "                            action[1] += 1\n",
    "                    \n",
    "\n",
    "            obs, reward, done, truncated, info = environment.step(action)\n",
    "\n",
    "            # Extracting the 2nd and 3rd key-value pairs\n",
    "            keys = list(info.keys())\n",
    "            values = list(info.values())\n",
    "\n",
    "            # Getting the 2nd key-value pair\n",
    "            second_value = values[1]\n",
    "\n",
    "            # Getting the 3rd key-value pair\n",
    "    \n",
    "            third_value = values[2]\n",
    "            fourth_value = values[4]\n",
    "            fith_value = values[5]\n",
    "            \n",
    "        \n",
    "        fin_balance += second_value\n",
    "        npv += fourth_value\n",
    "        count += 1\n",
    "        \n",
    "        env_balance += fith_value\n",
    "        \n",
    "        list_npv.append(fourth_value)\n",
    "            \n",
    "    mean_fin_balance = fin_balance/count\n",
    "    mean_env_balance = env_balance/count\n",
    "    mean_npv = npv/count\n",
    "\n",
    "    #print(mean_npv, \"\\n\", mean_irr, \"\\n\" )\n",
    "\n",
    "    environment.close()\n",
    "    \n",
    "    return(mean_npv, mean_env_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "52278c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9306.736562061036, 44404.16625475614)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basepolicy1(5000, env_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
