{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c7702da",
   "metadata": {
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kubaw\\miniforge3\\envs\\pytorch-env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy_financial as npf\n",
    "import random  \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import PPO, DQN, A2C\n",
    "from stable_baselines3.common.callbacks import CallbackList, CheckpointCallback, EvalCallback\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from sb3_contrib import RecurrentPPO\n",
    "\n",
    "from environment_fx_no_env import calculate_import_export, test1, test2, test3, evaluate1, evaluate2, basepolicy\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from typing import Callable\n",
    "\n",
    "import torch\n",
    "import torch as th\n",
    "from torch import nn\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27f3f975",
   "metadata": {
    "code_folding": [
     25
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# import and modify data\n",
    "\n",
    "# Assuming the file is a CSV and specifying the correct path and filename\n",
    "file_path = r\"file_path\"\n",
    "\n",
    "# Use pandas to read the CSV file\n",
    "JA_60 = pd.read_csv(file_path + \"/JA_60\")\n",
    "JA_240 = pd.read_csv(file_path + \"/JA_240\")\n",
    "\n",
    "elec_df = pd.read_csv(file_path + \"/hourly_consumption_gemany2.csv\")\n",
    "import_price = pd.read_csv(file_path + \"/electricity_tariff.csv\")\n",
    "\n",
    "#elec_df = elec_df * 1000\n",
    "elec_df = elec_df.drop('HourOfYear', axis=1)\n",
    "\n",
    "elec_df['hour_of_day'] = np.arange(8760) % 24\n",
    "elec_df['day_of_week'] = np.arange(8760) // 24 % 7  # 0 is Monday, 6 is Sunday\n",
    "\n",
    "# Define rates\n",
    "peak_rate = 1.45\n",
    "normal_rate = 1\n",
    "off_peak_rate = 0.85\n",
    "\n",
    "# Function to determine rate based on hour and day\n",
    "def determine_rate(hour, day):\n",
    "    if day < 5:  # Monday to Friday\n",
    "        if 16 <= hour < 21:  # 4pm to 9pm\n",
    "            return peak_rate\n",
    "        elif 6 <= hour < 10:  # 7am to 9am and 10am to 3pm\n",
    "            return normal_rate\n",
    "        else:  # Off-peak times\n",
    "            return off_peak_rate\n",
    "    else:  # Weekend\n",
    "        if 16 <= hour < 21:  # 4pm to 9pm\n",
    "            return normal_rate\n",
    "        else:  # Off-peak times\n",
    "            return off_peak_rate\n",
    "    \n",
    "# Apply the function to each row to determine the rate\n",
    "elec_df['rate'] = elec_df.apply(lambda row: determine_rate(row['hour_of_day'], row['day_of_week']), axis=1)\n",
    "\n",
    "import_price_df = import_price.drop(columns=['x'])\n",
    "import_price_df = import_price_df[:-26]\n",
    "\n",
    "train_cols = random.sample(list(import_price_df.columns), 7000)\n",
    "import_price_train = import_price_df[train_cols]\n",
    "test_cols = [col for col in import_price_df.columns if col not in train_cols]\n",
    "import_price_test = import_price_df[test_cols]\n",
    "\n",
    "Eff = pd.read_csv(file_path + \"/Efficency_impr\")\n",
    "Eff = (Eff)/100 + 1\n",
    "\n",
    "CAPEX = pd.read_csv(file_path + \"/CAPEX_JA.csv\")\n",
    "CAPEX_JA = (CAPEX[:26])\n",
    "\n",
    "train_cols_CAPEX = random.sample(list(CAPEX_JA.columns), 7000)\n",
    "test_cols_CAPEX = [col for col in CAPEX_JA.columns if col not in train_cols_CAPEX]\n",
    "\n",
    "CAPEX_JA_train = CAPEX_JA[train_cols_CAPEX]\n",
    "CAPEX_JA_test = CAPEX_JA[test_cols_CAPEX]\n",
    "\n",
    "train_cols_Eff = random.sample(list(Eff.columns), 7000)\n",
    "test_cols_Eff = [col for col in Eff.columns if col not in train_cols_Eff]\n",
    "\n",
    "Eff_train = Eff[train_cols_Eff]\n",
    "Eff_test = Eff[test_cols_Eff]\n",
    "\n",
    "JA_60_arr = (np.array(JA_60.T)).flatten()\n",
    "JA_240_arr = (np.array(JA_240.T)).flatten()\n",
    "\n",
    "Eff_train_arr = np.array(Eff_train.T)\n",
    "Eff_test_arr = np.array(Eff_test.T)\n",
    "\n",
    "CAPEX_JA_train_arr = np.array(CAPEX_JA_train.T)\n",
    "CAPEX_JA_test_arr = np.array(CAPEX_JA_test.T)\n",
    "\n",
    "elec_consum_arr = np.array(elec_df[\"Consumption\"])\n",
    "import_price_rate = np.array(elec_df[\"rate\"])\n",
    "\n",
    "import_price_train_arr = np.array(import_price_train.T)\n",
    "import_price_test_arr = np.array(import_price_train.T)\n",
    "\n",
    "grid_factor = pd.read_csv(file_path + \"/grid_factor.csv\")\n",
    "grid_factor =  grid_factor.T\n",
    "\n",
    "train_cols_grid = random.sample(list(grid_factor.columns), 7000)\n",
    "grid_factor_train = grid_factor[train_cols_grid]\n",
    "test_cols_grid = [col for col in grid_factor.columns if col not in train_cols]\n",
    "grid_factor_test = grid_factor[test_cols_grid]\n",
    "\n",
    "grid_factor_train_arr = np.array(grid_factor_train.T)\n",
    "grid_factor_test_arr = np.array(grid_factor_test.T)\n",
    "\n",
    "pv_co2 = pd.read_csv(file_path + \"/pv_emissions.csv\")\n",
    "pv_co2_arr = np.array(pv_co2)\n",
    "pv_co2_arr = np.insert(pv_co2_arr, 0, 1.620)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e01482e1",
   "metadata": {
    "code_folding": [
     0,
     48,
     213,
     265
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "class TrainEnvironment(gym.Env):\n",
    "    def __init__(self, PV_90_arr, PV_270_arr, elec_consum_arr, import_price_rate, import_tariff, efficency, CAPEX):\n",
    "        \n",
    "        # Price per watthour\n",
    "        self.import_price_df = import_tariff\n",
    "        self.import_price_at_zero = np.float32(0.00035)\n",
    "        self.import_price_rate = import_price_rate\n",
    "        \n",
    "        # Energy Balance\n",
    "        self.PV_90_arr = PV_90_arr\n",
    "        self.PV_270_arr = PV_270_arr\n",
    "        self.elec_df = elec_consum_arr\n",
    "        self.max_export = 4000\n",
    "        self.number_of_panels = 32\n",
    "        \n",
    "        # Degradation\n",
    "        self.deg_mu = 0.82 # Trina: 1.19, JA: 0.82, Maxeon: 0.67\n",
    "        self.deg_std = 0.555 \n",
    "        self.phi = 30 # Trina: 15, JA: 30, Maxeon: 50\n",
    "        \n",
    "        # Efficency Development\n",
    "        self.efficency_develop_df = efficency\n",
    "        self.efficency_at_zero = 1.0\n",
    "        \n",
    "        # Costs\n",
    "        self.power_at_zero = 415  # Trina: 265, JA: 415, Maxeon: 435\n",
    "        self.cost_per_Wp_df_at_zero = 0.69 # Trina: 0.36, JA: 0.69, Maxeon: 1.58\n",
    "        self.cost_per_Wp_df = CAPEX\n",
    "        self.initial_other_costs = 150\n",
    "        \n",
    "        self.operational_cost = 16.8\n",
    "        \n",
    "        self.loan_interest_rate = 1.10\n",
    "        self.normal_interest_rate = 1.02\n",
    "        \n",
    "        self.low_budget = 0 # Low budget: 0, High Budget: 750\n",
    "        self.high_budget = 750 # Low budget: 750, High Budget: 1500\n",
    "                        \n",
    "        # Spaces and length\n",
    "        self.action_space = spaces.MultiDiscrete([self.number_of_panels // 2, self.number_of_panels // 2])\n",
    "        self.observation_space = spaces.Box(0, 1.25, shape=(self.number_of_panels + 7,))\n",
    "        self.episode_len = 25\n",
    "        self.months_per_timestep = 12\n",
    "        \n",
    "    def _get_obs(self):\n",
    "        \n",
    "        return self.observation\n",
    "    \n",
    "    def calculate_import_export(self, elec_df, export_price, import_price):\n",
    "        \n",
    "        \"\"\"\n",
    "        Calculate the annual Wh of energy exported to the grid (exported) and saved (minimised)\n",
    "        \"\"\"\n",
    "        \n",
    "        PV_90_tot = self._get_obs()[0:self.number_of_panels // 2].sum() * self.PV_90_arr \n",
    "        PV_270_tot = self._get_obs()[(self.number_of_panels // 2) : self.number_of_panels].sum() * self.PV_270_arr \n",
    "        \n",
    "        AC_OUTPUT_tot = PV_90_tot + PV_270_tot\n",
    "        \n",
    "        exported = (AC_OUTPUT_tot - self.elec_df).clip(min=0, max = self.max_export)        \n",
    "        export_revenue = (export_price * exported).sum()\n",
    "\n",
    "        \n",
    "        minimised = AC_OUTPUT_tot - exported \n",
    "        minimised_revenue = (minimised * (self.import_price_rate * import_price)).sum()\n",
    "        \n",
    "\n",
    "        return export_revenue, AC_OUTPUT_tot, minimised_revenue\n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Reset the environment to the original state at t=1\n",
    "        \"\"\"\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        # Panels\n",
    "        self.init_obs = np.random.uniform(0, 1, size=self.number_of_panels).astype(np.float32)\n",
    "        self.init_obs = np.where(self.init_obs < 0.5, 0.0, np.random.uniform(0.85, 1.0, size=self.number_of_panels))\n",
    "\n",
    "        # Combine all initialization into a single step for efficiency\n",
    "        self.import_price_at_zero_norm = (self.import_price_at_zero - self.import_price_df.min().min()) / (self.import_price_df.max().max() - self.import_price_df.min().min())\n",
    "        self.FiT_at_zero_norm = (self.import_price_at_zero - self.import_price_df.min().min() * 0.33) / (self.import_price_df.max().max() - self.import_price_df.min().min() * 0.33)\n",
    "        self.efficency_at_zero_norm = (self.efficency_at_zero - 0.999) / (1.156 - 0.999)\n",
    "        self.panel_cost_and_inverter_at_zero_norm = (self.cost_per_Wp_df_at_zero - self.cost_per_Wp_df.min().min()) / (self.cost_per_Wp_df.max().max() - self.cost_per_Wp_df.min().min())\n",
    "        \n",
    "        self.current_budget_constraint = np.random.randint(self.low_budget, self.high_budget)\n",
    "        self.next_step_budget_constraint = 0\n",
    "        \n",
    "        \n",
    "        # Complete observation initialization in one go\n",
    "        self.observation = np.concatenate([\n",
    "            self.init_obs,\n",
    "            [self.import_price_at_zero_norm, self.FiT_at_zero_norm, self.efficency_at_zero_norm, \n",
    "             self.panel_cost_and_inverter_at_zero_norm, 0., 0., 0.]\n",
    "        ]).astype(np.float32)\n",
    "\n",
    "        self.previous_observation = self.observation.copy()\n",
    "\n",
    "        # RANDOM IMPORT PRICE\n",
    "        self.random_import_price = self.import_price_df[np.random.choice(self.import_price_df.shape[0])] \n",
    "\n",
    "        # RANDOM EFFICENCY\n",
    "        self.random_efficency_develop = self.efficency_develop_df[np.random.choice(self.efficency_develop_df.shape[0])]   \n",
    "        \n",
    "        # RANDOM COST PER WP\n",
    "        self.random_cost_per_Wp = self.cost_per_Wp_df[np.random.choice(self.cost_per_Wp_df.shape[0])]   \n",
    "        \n",
    "        \n",
    "        self.episode_len = 25  \n",
    "    \n",
    "        info = {}\n",
    "        \n",
    "        # RESET BALANCES\n",
    "        self.fin_balance_tot = 0\n",
    "        self.reward_tot = 0\n",
    "        self.env_balance_tot = 0\n",
    "        self.produced = 0\n",
    "        self.other_costs = 0\n",
    "        self.FiT = 0.0004\n",
    "        self.next_FiT = 0.0004\n",
    "\n",
    "        self.total_cash_flow = []\n",
    "        self.annual_cash_flow = 0\n",
    "                \n",
    "        self.due_loans = [0, 0, 0, 0] \n",
    "        self.current_interest = 0\n",
    "        self.step_total_interest = 1\n",
    "        self.survival = np.zeros(self.number_of_panels, dtype=np.float32)\n",
    "        self.resale_values = array_of_zeros = np.zeros(self.number_of_panels, dtype=np.float32)\n",
    "        \n",
    "        self.broke = np.zeros(self.number_of_panels, dtype=np.float32)\n",
    "        \n",
    "        self.two_year_ago_interest = 0\n",
    "        self.first_year_interest = []\n",
    "        self.second_year_interest = [0]\n",
    "        self.third_year_interest = [0, 0]\n",
    "        self.fourth_year_interest = [0, 0, 0]\n",
    "        self.next_year_total = 0\n",
    "        \n",
    "        self.survival = np.zeros(self.number_of_panels, dtype=np.float32)\n",
    "    \n",
    "        return self.observation, info\n",
    "    \n",
    "    def calculate_resale(self, initial_panel_cost, indices):\n",
    "        \n",
    "        self.resale_values[indices] = initial_panel_cost\n",
    "        \n",
    "        self.resale_values = self.resale_values * 0.85\n",
    "        \n",
    "        for count, i in enumerate(self.broke):\n",
    "            if i == 1:\n",
    "                self.resale_values[count] = 0\n",
    "        \n",
    "        resale_step = self.resale_values[indices].sum()\n",
    "        \n",
    "        return resale_step\n",
    "    \n",
    "    def calculate_panel_inv_cost(self, cost_per_Wp):\n",
    "        \n",
    "        PW_ep = self.efficency_develop * self.power_at_zero\n",
    "        \n",
    "        panel_cost_and_inverter = PW_ep * cost_per_Wp\n",
    "        \n",
    "        return panel_cost_and_inverter\n",
    "        \n",
    "    def calculate_penalty(self, current_step, annual_expense):\n",
    "              \n",
    "        year = 25 - current_step\n",
    "        \n",
    "        if year > 0:\n",
    "            self.current_budget_constraint = self.next_step_budget_constraint    \n",
    "            \n",
    "        \n",
    "        self.current_interest = self.next_year_total\n",
    "        annual_expense = (-annual_expense)\n",
    "        value = 0 \n",
    "        loan = 0\n",
    "        annual_interest = 0\n",
    "\n",
    "        if annual_expense > self.current_budget_constraint:\n",
    "            loan = (self.current_budget_constraint - annual_expense)\n",
    "            value = annual_expense / self.current_budget_constraint\n",
    "            periods = 2 if value < 2 else 3 if value < 3 else 4\n",
    "\n",
    "            annual_interest = loan / periods\n",
    "            interest_multiplier = 1\n",
    "\n",
    "            for i in range(4):\n",
    "                if i < periods:\n",
    "                    self.due_loans[i] = annual_interest * interest_multiplier\n",
    "                    interest_multiplier *= self.loan_interest_rate\n",
    "                else:\n",
    "                    self.due_loans[i] = 0\n",
    "        else:\n",
    "             self.due_loans = [0, 0, 0, 0]\n",
    "    \n",
    "        self.first_year_interest.append(self.due_loans[0])\n",
    "        self.second_year_interest.append(self.due_loans[1])\n",
    "        self.third_year_interest.append(self.due_loans[2])\n",
    "        self.fourth_year_interest.append(self.due_loans[3])\n",
    "    \n",
    "    \n",
    "        self.next_year_total = self.first_year_interest[year] + self.second_year_interest[year] + self.third_year_interest[year] + self.fourth_year_interest[year]\n",
    "        \n",
    "        self.next_step_budget_constraint = np.random.randint(self.low_budget, self.high_budget) * self.step_total_interest\n",
    "        current_budget_observation = (self.next_step_budget_constraint - self.low_budget * self.step_total_interest) / (self.high_budget * self.step_total_interest - self.low_budget * self.step_total_interest) \n",
    "        self.observation[self.number_of_panels + 6] = current_budget_observation\n",
    "                \n",
    "        return self.current_interest, self.due_loans, self.next_year_total\n",
    "        \n",
    "    def calculate_total_CAPEX(self, action_step, panel_cost_and_inverter):\n",
    "        \"\"\"\n",
    "        Calculate CAPEX each step in a vectorized manner.\n",
    "        \"\"\"\n",
    "        BOS = panel_cost_and_inverter * 0.55\n",
    "        number_installed = int(np.sum(action_step))\n",
    "\n",
    "        # Calculate costs from module and inverter\n",
    "        panel_cost_and_inverter_step = panel_cost_and_inverter * number_installed\n",
    "\n",
    "        # Calculate other installation costs\n",
    "        if number_installed == 0:\n",
    "            other_costs = 0\n",
    "        elif number_installed == 1:\n",
    "            other_costs = self.initial_other_costs * self.step_total_interest\n",
    "        else:\n",
    "            discounts = 0.9 ** np.arange(number_installed)\n",
    "            other_costs = (self.initial_other_costs * self.step_total_interest * discounts).sum()\n",
    "\n",
    "        # Calculate BOS costs using vector operations\n",
    "        is_new_installation = (self.previous_observation[:number_installed] == 0) & (action_step[:number_installed] == 1)\n",
    "        is_replacement = (self.previous_observation[:number_installed] > 0) & (action_step[:number_installed] == 1)\n",
    "        BOS_cost = np.sum(BOS * is_new_installation) + np.sum((BOS / 2) * is_replacement)\n",
    "\n",
    "        # Sum total CAPEX\n",
    "        total_CAPEX = panel_cost_and_inverter_step + BOS_cost + other_costs\n",
    "\n",
    "        return total_CAPEX, panel_cost_and_inverter\n",
    "        \n",
    "    def failure(self, actions):\n",
    "        \n",
    "        beta = 3  # Shape parameter\n",
    "\n",
    "        # Determine which panels are active based on the actions and previous observations.\n",
    "        if self.episode_len == 24:\n",
    "            active_panels = (self.observation[:self.number_of_panels] > 0.85)\n",
    "        else:\n",
    "            active_panels = (self.observation[:self.number_of_panels] == self.efficency_develop)\n",
    "\n",
    "        # Calculate lifespan for all active panels at once\n",
    "        lifespans = np.random.weibull(beta, self.number_of_panels) * self.phi\n",
    "        lifespans = np.where(active_panels, lifespans, 0)  # Apply lifespan only to active panels\n",
    "\n",
    "        # Adjust survival times based on episode length\n",
    "        self.survival[:self.number_of_panels] = np.where(\n",
    "            active_panels,\n",
    "            np.abs(lifespans.astype(int)) + np.abs(self.episode_len - 25),\n",
    "            self.survival[:self.number_of_panels]\n",
    "        )\n",
    "\n",
    "        return self.survival\n",
    "\n",
    "    def calculate_FiT(self, episodes, import_price):\n",
    "            \n",
    "        self.FiT = import_price\n",
    "            \n",
    "        if episodes == 25:\n",
    "            self.FiT = self.FiT\n",
    "            \n",
    "        elif episodes == 24 or episodes == 23:\n",
    "            self.FiT = self.FiT * 0.64\n",
    "            \n",
    "        elif episodes == 22:\n",
    "            self.FiT = self.FiT * 0.46\n",
    "            \n",
    "        elif episodes == 21:\n",
    "            self.FiT = self.FiT * 0.55\n",
    "            \n",
    "        elif episodes < 20:\n",
    "            self.FiT = self.FiT * 0.33\n",
    "            \n",
    "        elif episodes == 20:\n",
    "            self.FiT = self.FiT * 0.37\n",
    "            \n",
    "        return self.FiT\n",
    "                        \n",
    "    def step(self, action):\n",
    "        \n",
    "        \"\"\"\n",
    "        defines actions, reward etc.\n",
    "        \"\"\"\n",
    "        \n",
    "        # RESET THE ANNUAL BALANCES\n",
    "        self.total_CAPEX = 0\n",
    "        self.pv_costs = 0\n",
    "        self.fin_balance = 0\n",
    "        self.number_installed = 0\n",
    "        current_penalty = 0\n",
    "        self.other_costs = 0\n",
    "        next_step_penalty = 0\n",
    "        self.step_total_interest = self.step_total_interest * self.normal_interest_rate\n",
    "        current_operational_costs = self.operational_cost * self.step_total_interest\n",
    "        \n",
    "        \n",
    "        self.cost_per_Wp = self.random_cost_per_Wp[abs(self.episode_len - 25)]\n",
    "        self.import_price = self.random_import_price[abs(self.episode_len - 25)]\n",
    "        self.efficency_develop = self.random_efficency_develop[abs(self.episode_len - 25)]\n",
    "           \n",
    "        self.panel_cost_and_inverter = self.calculate_panel_inv_cost(self.cost_per_Wp)\n",
    "        FiT = self.calculate_FiT(self.episode_len, self.import_price)\n",
    "        \n",
    "        reward = 0   \n",
    "        \n",
    "        # Find indices of the lowest 'action' values in previous_observation\n",
    "        indices_0 = np.argsort(self.previous_observation[:(self.number_of_panels // 2)])[:action[0]]\n",
    "        indices_1 = np.argsort(self.previous_observation[(self.number_of_panels // 2):self.number_of_panels])[:action[1]]\n",
    "\n",
    "        indices = np.concatenate([indices_0, indices_1 + (self.number_of_panels // 2)])\n",
    "        \n",
    "        # Replace these indices in the observation with efficiency_develop\n",
    "        self.observation[:self.number_of_panels][indices] = self.efficency_develop\n",
    "        \n",
    "        # Copy over the other values from previous_observation to observation\n",
    "        mask = np.ones(len(self.previous_observation[:self.number_of_panels]), dtype=bool)\n",
    "        mask[indices] = False\n",
    "        self.observation[:self.number_of_panels][mask] = self.previous_observation[:self.number_of_panels][mask]\n",
    "\n",
    "        replaced_panels = np.zeros(len(self.previous_observation[:self.number_of_panels]), dtype=int)\n",
    "        replaced_panels[indices] = 1\n",
    "\n",
    "        instaltion = (self.observation[:self.number_of_panels] > 0).astype(int)\n",
    "        self.pv_costs -= instaltion.sum() * current_operational_costs\n",
    "\n",
    "        actions_step = np.array(replaced_panels)\n",
    "        \n",
    "        action = action[0] + action[1]\n",
    "\n",
    "            \n",
    "        if action > 0:\n",
    "            step_CAPEX, panel_cost_and_inverter = self.calculate_total_CAPEX(actions_step, self.panel_cost_and_inverter)\n",
    "            self.pv_costs -= step_CAPEX\n",
    "            \n",
    "        else:\n",
    "            panel_cost_and_inverter = 0\n",
    "                \n",
    "        next_observation = self._get_obs()\n",
    "\n",
    "        \n",
    "        # Calculate the Reslae value\n",
    "        resale = self.calculate_resale(panel_cost_and_inverter, indices) #  ***\n",
    "        \n",
    "        self.pv_costs += resale\n",
    " \n",
    "        \n",
    "        # CALCULATE THE BUDGET INTEREST\n",
    "        current_penalty, due_loans, next_step_penalty = self.calculate_penalty(self.episode_len, self.pv_costs)\n",
    "\n",
    "        \n",
    "        # CALCULATE THE ENERGY YIELD\n",
    "        exported_revenue, AC_OUTPUT_tot, minimised_revenue = self.calculate_import_export(self.elec_df, FiT, self.import_price)        \n",
    "        \n",
    "        pv_costs_observation = - self.pv_costs / 10000\n",
    "        self.observation[self.number_of_panels + 4] = pv_costs_observation\n",
    "        \n",
    "        next_step_penalty_observation = - next_step_penalty / 8000\n",
    "        self.observation[self.number_of_panels + 5] = next_step_penalty_observation\n",
    "        \n",
    "        \n",
    "        # CALCULATE STEP BALANCES\n",
    "        self.fin_balance += self.pv_costs\n",
    "        self.fin_balance += current_penalty\n",
    "        self.fin_balance += float(exported_revenue + minimised_revenue)\n",
    "        \n",
    "        # CALCULATE TOTAL BALANCES\n",
    "        self.fin_balance_tot += self.fin_balance                \n",
    "        \n",
    "        # SUBSTRACT 1 FOR TIMESTEP\n",
    "        self.episode_len -= 1\n",
    "        done = self.episode_len <= 0\n",
    "        \n",
    "        #reward = self.fin_balance_tot / 1000 if done else 0\n",
    "        reward = self.fin_balance / 1000\n",
    "        \n",
    "        # FAILURE\n",
    "        self.broke = np.zeros(self.number_of_panels, dtype=np.float32)\n",
    "        survival = self.failure(actions_step)\n",
    "        \n",
    "        for c, p in enumerate(survival):\n",
    "            \n",
    "            if c < self.number_of_panels:\n",
    "\n",
    "                if p - 1 <= abs(self.episode_len - 24):\n",
    "                    self.broke[c] = 1\n",
    "                    self.observation[c] = 0\n",
    "        \n",
    "        # DEGRADATION RATE\n",
    "        # Applying degradation only to panels that are operational (above 0.1 efficiency)\n",
    "        active_panels = self.observation[:self.number_of_panels] > 0.1\n",
    "        degradations = np.random.normal(self.deg_mu, self.deg_std, size=self.number_of_panels) / 100\n",
    "        self.observation[:self.number_of_panels][active_panels] -= degradations[active_panels]\n",
    "        \n",
    "        if not done: \n",
    "        \n",
    "            self.next_cost_per_Wp = self.random_cost_per_Wp[abs(self.episode_len - 25)]\n",
    "            self.next_import_price = self.random_import_price[abs(self.episode_len - 25)]\n",
    "            self.next_efficency_develop = self.random_efficency_develop[abs(self.episode_len - 25)]\n",
    "            next_FIT = self.calculate_FiT(self.episode_len, self.next_import_price)\n",
    "        \n",
    "            price_observation = (self.next_import_price - 0.00022499) / (0.0020798 - 0.00022499)\n",
    "            self.observation[self.number_of_panels] = price_observation\n",
    "\n",
    "            FiT_observation = (next_FIT - 0.00022499 * 0.33) / (0.0020798 - 0.00022499 * 0.33)\n",
    "            self.observation[self.number_of_panels + 1] = FiT_observation\n",
    "\n",
    "            eff_observation = (self.next_efficency_develop - 0.999) / (1.156 - 0.999)\n",
    "            self.observation[self.number_of_panels + 2] = eff_observation\n",
    "\n",
    "            cost_per_Wp_observation = (self.cost_per_Wp_df_at_zero - self.cost_per_Wp_df.min().min()) / (self.cost_per_Wp_df.max().max() - self.cost_per_Wp_df.min().min())\n",
    "            self.observation[self.number_of_panels + 3] = cost_per_Wp_observation\n",
    "        \n",
    "        info = {\"step financial balance (eur):\": self.fin_balance,\n",
    "               \"total financial balance: (eur)\": self.fin_balance_tot,\n",
    "               \"internal rate of return\": 0,\n",
    "               \"current_interest\": resale,\n",
    "                \"net present value\": 0}\n",
    "         \n",
    "        \n",
    "        self.previous_observation = self.observation.copy()\n",
    "        \n",
    "        return self.observation, reward, done, False, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ff95454",
   "metadata": {
    "code_folding": [
     0,
     158,
     170,
     192,
     258,
     310,
     459
    ]
   },
   "outputs": [],
   "source": [
    "class TestEnvironment(gym.Env):\n",
    "    def __init__(self, PV_90_arr, PV_270_arr, elec_consum_arr, import_price_rate, import_tariff, efficency, CAPEX, \n",
    "                 GRID_FACTOR, pv_co2_arr):\n",
    "        \n",
    "        # Price per watthour\n",
    "        self.import_price_df = import_tariff\n",
    "        self.import_price_at_zero = np.float32(0.00035)\n",
    "        self.import_price_rate = import_price_rate\n",
    "        \n",
    "        # Energy Balance\n",
    "        self.PV_90_arr = PV_90_arr\n",
    "        self.PV_270_arr = PV_270_arr\n",
    "        self.elec_df = elec_consum_arr\n",
    "        self.max_export = 4000\n",
    "        self.number_of_panels = 32\n",
    "        \n",
    "        # Degradation\n",
    "        self.deg_mu = 0.82 # Trina: 1.19, JA: 0.82, Maxeon: 0.67\n",
    "        self.deg_std = 0.555 \n",
    "        \n",
    "        self.phi = 30 # Trina: 15, JA: 30, Maxeon: 50\n",
    "        \n",
    "        # Efficency Development\n",
    "        self.efficency_develop_df = efficency\n",
    "        self.efficency_at_zero = 1.0\n",
    "        \n",
    "        # Costs\n",
    "        self.power_at_zero = 415  # Trina: 265, JA: 415, Maxeon: 435\n",
    "        self.cost_per_Wp_df_at_zero = 0.69 # Trina: 0.36, JA: 0.69, Maxeon: 1.58\n",
    "        self.cost_per_Wp_df = CAPEX\n",
    "        self.initial_other_costs = 150\n",
    "        \n",
    "        self.operational_cost = 16.8\n",
    "        \n",
    "        self.loan_interest_rate = 1.10\n",
    "        self.normal_interest_rate = 1.02\n",
    "        \n",
    "        self.low_budget = 0 # Low budget: 0, High Budget: 750\n",
    "        self.high_budget = 750 # Low budget: 750, High Budget: 1500\n",
    "        \n",
    "        # Spaces and length\n",
    "        self.action_space = spaces.MultiDiscrete([self.number_of_panels // 2, self.number_of_panels // 2])\n",
    "        self.observation_space = spaces.Box(0, 1.25, shape=(self.number_of_panels + 7,))\n",
    "        self.episode_len = 25\n",
    "        self.months_per_timestep = 12\n",
    "        \n",
    "        # Emission\n",
    "        self.grid_factor_df = GRID_FACTOR \n",
    "        self.grid_factor_at_zero = 0.553 \n",
    "        self.pv_emission = pv_co2_arr * self.power_at_zero\n",
    "        \n",
    "    def _get_obs(self):\n",
    "        \n",
    "        return self.observation\n",
    "    \n",
    "    def calculate_import_export(self, elec_df, export_price, import_price):\n",
    "        \n",
    "        \"\"\"\n",
    "        Calculate the annual Wh of energy exported to the grid (exported) and saved (minimised)\n",
    "        \"\"\"\n",
    "        \n",
    "        PV_90_tot = self._get_obs()[0:self.number_of_panels // 2].sum() * self.PV_90_arr \n",
    "        PV_270_tot = self._get_obs()[(self.number_of_panels // 2) : self.number_of_panels].sum() * self.PV_270_arr \n",
    "        \n",
    "        AC_OUTPUT_tot = PV_90_tot + PV_270_tot\n",
    "\n",
    "        exported = (AC_OUTPUT_tot - self.elec_df).clip(min=0, max = self.max_export)  \n",
    "        excess_energy = (AC_OUTPUT_tot - self.elec_df - self.max_export).clip(min=0)\n",
    "        \n",
    "        export_revenue = (export_price * exported).sum()\n",
    "\n",
    "        \n",
    "        minimised = AC_OUTPUT_tot - exported \n",
    "        minimised_revenue = (minimised * (self.import_price_rate * import_price)).sum()\n",
    "        \n",
    "        AC_for_env = AC_OUTPUT_tot - excess_energy\n",
    "\n",
    "        return export_revenue, AC_OUTPUT_tot, AC_for_env, minimised_revenue\n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Reset the environment to the original state at t=1\n",
    "        \"\"\"\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            \n",
    "        # Panels\n",
    "        self.init_obs = np.random.uniform(0, 1, size=self.number_of_panels).astype(np.float32)\n",
    "        self.init_obs = np.where(self.init_obs < 0.5, 0.0, np.random.uniform(0.85, 1.0, size=self.number_of_panels))\n",
    "\n",
    "        # Combine all initialization into a single step for efficiency\n",
    "        self.import_price_at_zero_norm = (self.import_price_at_zero - self.import_price_df.min().min()) / (self.import_price_df.max().max() - self.import_price_df.min().min())\n",
    "        self.FiT_at_zero_norm = (self.import_price_at_zero - self.import_price_df.min().min() * 0.33) / (self.import_price_df.max().max() - self.import_price_df.min().min() * 0.33)\n",
    "        self.efficency_at_zero_norm = (self.efficency_at_zero - 0.999) / (1.156 - 0.999)\n",
    "        self.panel_cost_and_inverter_at_zero_norm = (self.cost_per_Wp_df_at_zero - self.cost_per_Wp_df.min().min()) / (self.cost_per_Wp_df.max().max() - self.cost_per_Wp_df.min().min())\n",
    "                \n",
    "        self.grid_factor_at_zero_norm = (self.grid_factor_at_zero - 0.553) / (0.553 - 0.00022499) \n",
    "        \n",
    "        self.current_budget_constraint = np.random.randint(self.low_budget, self.high_budget)\n",
    "        self.next_step_budget_constraint = 0\n",
    "        \n",
    "        \n",
    "        # Complete observation initialization in one go\n",
    "        self.observation = np.concatenate([\n",
    "            self.init_obs,\n",
    "            [self.import_price_at_zero_norm, self.FiT_at_zero_norm, self.efficency_at_zero_norm, \n",
    "             self.panel_cost_and_inverter_at_zero_norm, 0., 0., 0.]\n",
    "        ]).astype(np.float32) #***\n",
    "\n",
    "        self.previous_observation = self.observation.copy()\n",
    "\n",
    "        # RANDOM IMPORT PRICE\n",
    "        self.random_import_price = self.import_price_df[np.random.choice(self.import_price_df.shape[0])] \n",
    "\n",
    "        # RANDOM EFFICENCY\n",
    "        self.random_efficency_develop = self.efficency_develop_df[np.random.choice(self.efficency_develop_df.shape[0])]   \n",
    "        \n",
    "        # RANDOM COST PER WP\n",
    "        self.random_cost_per_Wp = self.cost_per_Wp_df[np.random.choice(self.cost_per_Wp_df.shape[0])]   \n",
    "        \n",
    "        # RANDOM Grid Factor\n",
    "        self.random_grid_factor = self.grid_factor_df[np.random.choice(self.grid_factor_df.shape[0])]   #***\n",
    "        \n",
    "        self.episode_len = 25  \n",
    "    \n",
    "        info = {}\n",
    "        \n",
    "        # RESET BALANCES\n",
    "        self.fin_balance_tot = 0\n",
    "        self.reward_tot = 0\n",
    "        self.env_balance_tot = 0\n",
    "        self.produced = 0\n",
    "        self.other_costs = 0\n",
    "        self.FiT = 0.0004\n",
    "        self.next_FiT = 0.0004\n",
    "        self.resale_values = array_of_zeros = np.zeros(self.number_of_panels, dtype=np.float32)\n",
    "        \n",
    "        self.broke = np.zeros(self.number_of_panels, dtype=np.float32)\n",
    "        self.total_cash_flow = []\n",
    "        self.annual_cash_flow = 0\n",
    "                \n",
    "        self.due_loans = [0, 0, 0, 0] \n",
    "        self.current_interest = 0\n",
    "        self.step_total_interest = 1\n",
    "        \n",
    "        self.two_year_ago_interest = 0\n",
    "        self.first_year_interest = []\n",
    "        self.second_year_interest = [0]\n",
    "        self.third_year_interest = [0, 0]\n",
    "        self.fourth_year_interest = [0, 0, 0]\n",
    "        self.next_year_total = 0\n",
    "        \n",
    "        self.survival = np.zeros(self.number_of_panels, dtype=np.float32)\n",
    "    \n",
    "        return self.observation, info\n",
    "    \n",
    "    def emission_balance(self, pv_production, grid_factor, panel_emission, action_step):\n",
    "        \n",
    "        curtailed = (pv_production.sum() * grid_factor)/1000\n",
    "        \n",
    "        number_installed = int(np.sum(action_step))\n",
    "        \n",
    "        panel_emission_tot = number_installed * panel_emission\n",
    "        \n",
    "        emission_balance = curtailed - panel_emission_tot\n",
    "        \n",
    "        return emission_balance \n",
    "    \n",
    "    def calculate_resale(self, initial_panel_cost, indices):\n",
    "        \n",
    "        self.resale_values[indices] = initial_panel_cost\n",
    "        \n",
    "        self.resale_values = self.resale_values * 0.85\n",
    "        \n",
    "        for count, i in enumerate(self.broke):\n",
    "            if i == 1:\n",
    "                self.resale_values[count] = 0\n",
    "        \n",
    "        resale_step = self.resale_values[indices].sum()\n",
    "        \n",
    "        return resale_step\n",
    "    \n",
    "    def calculate_panel_inv_cost(self, cost_per_Wp):\n",
    "        \n",
    "        PW_ep = self.efficency_develop * self.power_at_zero\n",
    "        \n",
    "        panel_cost_and_inverter = PW_ep * cost_per_Wp\n",
    "        \n",
    "        return panel_cost_and_inverter\n",
    "    \n",
    "    def calculate_irr_and_npv(self, pv_cost, minimised_revenue, export_revenue, penalty):\n",
    "                \n",
    "        \"\"\"\n",
    "        Calculates total cash flow of the project needed for the internal rate of return\n",
    "        \"\"\" \n",
    "        self.expences = 0\n",
    "        self.annual_cash_flow = 0\n",
    "        initial_cost = 0\n",
    "        \n",
    "        self.expences = pv_cost\n",
    "        self.annual_cash_flow = self.expences + export_revenue + minimised_revenue + penalty\n",
    "        initial_cost_q, x = self.calculate_total_CAPEX(self.init_obs, self.panel_cost_and_inverter)\n",
    "        #initial_cost = - initial_cost_q\n",
    "        \n",
    "        if self.episode_len == 24:\n",
    "            self.total_cash_flow.append(initial_cost + self.annual_cash_flow) \n",
    "        else:\n",
    "            self.total_cash_flow.append(self.annual_cash_flow) \n",
    "        \n",
    "        return self.total_cash_flow\n",
    "        \n",
    "    def calculate_penalty(self, current_step, annual_expense):\n",
    "              \n",
    "        year = 25 - current_step\n",
    "        \n",
    "        if year > 0:\n",
    "            self.current_budget_constraint = self.next_step_budget_constraint    \n",
    "            \n",
    "        \n",
    "        self.current_interest = self.next_year_total\n",
    "        annual_expense = (-annual_expense)\n",
    "        value = 0 \n",
    "        loan = 0\n",
    "        annual_interest = 0\n",
    "\n",
    "        if annual_expense > self.current_budget_constraint:\n",
    "            loan = (self.current_budget_constraint - annual_expense)\n",
    "            value = annual_expense / self.current_budget_constraint\n",
    "            periods = 2 if value < 2 else 3 if value < 3 else 4\n",
    "\n",
    "            annual_interest = loan / periods\n",
    "            interest_multiplier = 1\n",
    "\n",
    "            for i in range(4):\n",
    "                if i < periods:\n",
    "                    self.due_loans[i] = annual_interest * interest_multiplier\n",
    "                    interest_multiplier *= self.loan_interest_rate\n",
    "                else:\n",
    "                    self.due_loans[i] = 0\n",
    "        else:\n",
    "             self.due_loans = [0, 0, 0, 0]\n",
    "    \n",
    "        self.first_year_interest.append(self.due_loans[0])\n",
    "        self.second_year_interest.append(self.due_loans[1])\n",
    "        self.third_year_interest.append(self.due_loans[2])\n",
    "        self.fourth_year_interest.append(self.due_loans[3])\n",
    "    \n",
    "    \n",
    "        self.next_year_total = self.first_year_interest[year] + self.second_year_interest[year] + self.third_year_interest[year] + self.fourth_year_interest[year]\n",
    "        \n",
    "        self.next_step_budget_constraint = np.random.randint(self.low_budget, self.high_budget) * self.step_total_interest\n",
    "        current_budget_observation = (self.next_step_budget_constraint - self.low_budget * self.step_total_interest) / (self.high_budget * self.step_total_interest - self.low_budget * self.step_total_interest) \n",
    "        self.observation[self.number_of_panels + 6] = current_budget_observation\n",
    "                \n",
    "        return self.current_interest, self.due_loans, self.next_year_total\n",
    "        \n",
    "    def calculate_total_CAPEX(self, action_step, panel_cost_and_inverter):\n",
    "        \"\"\"\n",
    "        Calculate CAPEX each step in a vectorized manner.\n",
    "        \"\"\"\n",
    "        BOS = panel_cost_and_inverter * 0.55\n",
    "        number_installed = int(np.sum(action_step))\n",
    "\n",
    "        # Calculate costs from module and inverter\n",
    "        panel_cost_and_inverter_step = panel_cost_and_inverter * number_installed\n",
    "\n",
    "        # Calculate other installation costs\n",
    "        if number_installed == 0:\n",
    "            other_costs = 0\n",
    "        elif number_installed == 1:\n",
    "            other_costs = self.initial_other_costs * self.step_total_interest\n",
    "        else:\n",
    "            discounts = 0.9 ** np.arange(number_installed)\n",
    "            other_costs = (self.initial_other_costs * self.step_total_interest * discounts).sum()\n",
    "\n",
    "        # Calculate BOS costs using vector operations\n",
    "        is_new_installation = (self.previous_observation[:number_installed] == 0) & (action_step[:number_installed] == 1)\n",
    "        is_replacement = (self.previous_observation[:number_installed] > 0) & (action_step[:number_installed] == 1)\n",
    "        BOS_cost = np.sum(BOS * is_new_installation) + np.sum((BOS / 2) * is_replacement)\n",
    "\n",
    "        # Sum total CAPEX\n",
    "        total_CAPEX = panel_cost_and_inverter_step + BOS_cost + other_costs\n",
    "\n",
    "        return total_CAPEX, panel_cost_and_inverter\n",
    "        \n",
    "    def failure(self, actions):\n",
    "        \n",
    "        beta = 3  # Shape parameter\n",
    "\n",
    "        # Determine which panels are active based on the actions and previous observations.\n",
    "        if self.episode_len == 24:\n",
    "            active_panels = (self.observation[:self.number_of_panels] > 0.85)\n",
    "        else:\n",
    "            active_panels = (self.observation[:self.number_of_panels] == self.efficency_develop)\n",
    "\n",
    "        # Calculate lifespan for all active panels at once\n",
    "        lifespans = np.random.weibull(beta, self.number_of_panels) * self.phi\n",
    "        lifespans = np.where(active_panels, lifespans, 0)  # Apply lifespan only to active panels\n",
    "\n",
    "        # Adjust survival times based on episode length\n",
    "        self.survival[:self.number_of_panels] = np.where(\n",
    "            active_panels,\n",
    "            np.abs(lifespans.astype(int)) + np.abs(self.episode_len - 25),\n",
    "            self.survival[:self.number_of_panels]\n",
    "        )\n",
    "\n",
    "        return self.survival\n",
    "\n",
    "    def calculate_FiT(self, episodes, import_price):\n",
    "            \n",
    "        self.FiT = import_price\n",
    "            \n",
    "        if episodes == 25:\n",
    "            self.FiT = self.FiT\n",
    "            \n",
    "        elif episodes == 24 or episodes == 23:\n",
    "            self.FiT = self.FiT * 0.64\n",
    "            \n",
    "        elif episodes == 22:\n",
    "            self.FiT = self.FiT * 0.46\n",
    "            \n",
    "        elif episodes == 21:\n",
    "            self.FiT = self.FiT * 0.55\n",
    "            \n",
    "        elif episodes < 20:\n",
    "            self.FiT = self.FiT * 0.33\n",
    "            \n",
    "        elif episodes == 20:\n",
    "            self.FiT = self.FiT * 0.37\n",
    "            \n",
    "        return self.FiT\n",
    "                        \n",
    "    def step(self, action):\n",
    "        \n",
    "        \"\"\"\n",
    "        defines actions, reward etc.\n",
    "        \"\"\"\n",
    "        \n",
    "        # RESET THE ANNUAL BALANCES\n",
    "        self.total_CAPEX = 0\n",
    "        self.pv_costs = 0\n",
    "        self.fin_balance = 0\n",
    "        self.env_balance = 0\n",
    "        self.number_installed = 0\n",
    "        irr_fin = 0\n",
    "        npv_fin = 0\n",
    "        current_penalty = 0\n",
    "        self.other_costs = 0\n",
    "        next_step_penalty = 0\n",
    "        self.step_total_interest = self.step_total_interest * self.normal_interest_rate\n",
    "        current_operational_costs = self.operational_cost * self.step_total_interest\n",
    "        \n",
    "        \n",
    "        self.cost_per_Wp = self.random_cost_per_Wp[abs(self.episode_len - 25)]\n",
    "        self.import_price = self.random_import_price[abs(self.episode_len - 25)]\n",
    "        self.efficency_develop = self.random_efficency_develop[abs(self.episode_len - 25)]\n",
    "        self.grid_factor = self.random_grid_factor[abs(self.episode_len - 25)]\n",
    "        self.step_pv_emission = (self.pv_emission[abs(self.episode_len - 25)] * self.efficency_develop) / 100000\n",
    "           \n",
    "        self.panel_cost_and_inverter = self.calculate_panel_inv_cost(self.cost_per_Wp)\n",
    "        FiT = self.calculate_FiT(self.episode_len, self.import_price)\n",
    "        \n",
    "        reward = 0   \n",
    "        \n",
    "        # Find indices of the lowest 'action' values in previous_observation\n",
    "        indices_0 = np.argsort(self.previous_observation[:(self.number_of_panels // 2)])[:action[0]]\n",
    "        indices_1 = np.argsort(self.previous_observation[(self.number_of_panels // 2):self.number_of_panels])[:action[1]]\n",
    "\n",
    "        indices = np.concatenate([indices_0, indices_1 + (self.number_of_panels // 2)])\n",
    "        \n",
    "        # Replace these indices in the observation with efficiency_develop\n",
    "        self.observation[:self.number_of_panels][indices] = self.efficency_develop\n",
    "\n",
    "        # Copy over the other values from previous_observation to observation\n",
    "        mask = np.ones(len(self.previous_observation[:self.number_of_panels]), dtype=bool)\n",
    "        mask[indices] = False\n",
    "        self.observation[:self.number_of_panels][mask] = self.previous_observation[:self.number_of_panels][mask]\n",
    "\n",
    "        replaced_panels = np.zeros(len(self.previous_observation[:self.number_of_panels]), dtype=int)\n",
    "        replaced_panels[indices] = 1\n",
    "\n",
    "        instaltion = (self.observation[:self.number_of_panels] > 0).astype(int)\n",
    "        self.pv_costs -= instaltion.sum() * current_operational_costs\n",
    "\n",
    "        actions_step = np.array(replaced_panels)\n",
    "\n",
    "        action = action[0] + action[1]\n",
    "        \n",
    "        if action > 0:\n",
    "            step_CAPEX, panel_cost_and_inverter = self.calculate_total_CAPEX(actions_step, self.panel_cost_and_inverter)\n",
    "            self.pv_costs -= step_CAPEX\n",
    "            \n",
    "        else:\n",
    "            panel_cost_and_inverter = 0\n",
    "                \n",
    "        next_observation = self._get_obs()\n",
    "\n",
    "        # Calculate the Reslae value\n",
    "        resale = self.calculate_resale(panel_cost_and_inverter, indices) #  ***\n",
    "        \n",
    "        self.pv_costs += resale\n",
    "\n",
    "        \n",
    "        # CALCULATE THE BUDGET INTEREST\n",
    "        current_penalty, due_loans, next_step_penalty = self.calculate_penalty(self.episode_len, self.pv_costs)\n",
    "        \n",
    "        \n",
    "        # CALCULATE THE ENERGY YIELD\n",
    "        exported_revenue, AC_OUTPUT_tot, AC_for_env, minimised_revenue = self.calculate_import_export(self.elec_df, FiT, self.import_price)        \n",
    "        \n",
    "        \n",
    "        # CALCULATE STEP EMISSIONS\n",
    "        self.env_balance = self.emission_balance(AC_for_env, self.grid_factor, self.step_pv_emission, actions_step)\n",
    "        \n",
    "        self.env_balance_tot += self.env_balance\n",
    "        \n",
    "        pv_costs_observation = - self.pv_costs / 10000\n",
    "        self.observation[self.number_of_panels + 4] = pv_costs_observation\n",
    "        \n",
    "        next_step_penalty_observation = - next_step_penalty / 8000\n",
    "        self.observation[self.number_of_panels + 5] = next_step_penalty_observation\n",
    "        \n",
    "        \n",
    "        # CALCULATE STEP BALANCES\n",
    "        self.fin_balance += self.pv_costs\n",
    "        self.fin_balance += current_penalty\n",
    "        self.fin_balance += float(exported_revenue + minimised_revenue)\n",
    "        \n",
    "        # CALCULATE TOTAL BALANCES\n",
    "        self.fin_balance_tot += self.fin_balance                \n",
    "        \n",
    "        # SUBSTRACT 1 FOR TIMESTEP\n",
    "        self.episode_len -= 1\n",
    "        done = self.episode_len <= 0\n",
    "        \n",
    "        # CALCULATE IRR, NPV AND CARBON INTENSITY\n",
    "        total_cash_flow = self.calculate_irr_and_npv(self.pv_costs, exported_revenue, minimised_revenue, current_penalty)\n",
    "        irr = npf.irr(total_cash_flow) * 100\n",
    "        npv = npf.npv(0.04 ,total_cash_flow)\n",
    "            \n",
    "        # RETURNS AND CALCULATE REWARD\n",
    "        if self.episode_len == 0:\n",
    "            irr_fin = irr\n",
    "            npv_fin = npv\n",
    "        \n",
    "        reward = self.fin_balance / 1000\n",
    "        #reward = self.fin_balance_tot / 1000 if done else 0\n",
    "        \n",
    "        # FAILURE\n",
    "         \n",
    "        survival = self.failure(actions_step)\n",
    "        self.broke = np.zeros(self.number_of_panels, dtype=np.float32)\n",
    "\n",
    "        for c, p in enumerate(survival):\n",
    "            \n",
    "            if c < self.number_of_panels:\n",
    "\n",
    "                if p - 1 <= abs(self.episode_len - 24):\n",
    "                    self.broke[c] = 1\n",
    "\n",
    "                    self.observation[c] = 0\n",
    "        \n",
    "        # DEGRADATION RATE\n",
    "        # Applying degradation only to panels that are operational (above 0.1 efficiency)\n",
    "        active_panels = self.observation[:self.number_of_panels] > 0.1\n",
    "        degradations = np.random.normal(self.deg_mu, self.deg_std, size=self.number_of_panels) / 100\n",
    "        self.observation[:self.number_of_panels][active_panels] -= degradations[active_panels]\n",
    "        \n",
    "        if not done: \n",
    "        \n",
    "            self.next_cost_per_Wp = self.random_cost_per_Wp[abs(self.episode_len - 25)]\n",
    "            self.next_import_price = self.random_import_price[abs(self.episode_len - 25)]\n",
    "            self.next_efficency_develop = self.random_efficency_develop[abs(self.episode_len - 25)]\n",
    "            self.next_grid_factor = self.random_grid_factor[abs(self.episode_len - 25)]\n",
    "            next_FIT = self.calculate_FiT(self.episode_len, self.next_import_price)\n",
    "        \n",
    "            price_observation = (self.next_import_price - 0.00022499) / (0.0020798 - 0.00022499)\n",
    "            self.observation[self.number_of_panels] = price_observation\n",
    "\n",
    "            FiT_observation = (next_FIT - 0.00022499 * 0.33) / (0.0020798 - 0.00022499 * 0.33)\n",
    "            self.observation[self.number_of_panels + 1] = FiT_observation\n",
    "\n",
    "            eff_observation = (self.next_efficency_develop - 0.999) / (1.156 - 0.999)\n",
    "            self.observation[self.number_of_panels + 2] = eff_observation\n",
    "\n",
    "            cost_per_Wp_observation = (self.cost_per_Wp_df_at_zero - self.cost_per_Wp_df.min().min()) / (self.cost_per_Wp_df.max().max() - self.cost_per_Wp_df.min().min())\n",
    "            self.observation[self.number_of_panels + 3] = cost_per_Wp_observation\n",
    "            \n",
    "            grid_factor_observation = (self.next_grid_factor - 0.553) / (0.553 - 0.00022499)\n",
    "            #self.observation[self.number_of_panels + 7] = cost_per_Wp_observation\n",
    "        \n",
    "        \n",
    "        info = {\"step financial balance (eur):\": self.fin_balance,\n",
    "               \"total financial balance: (eur)\": self.fin_balance_tot,\n",
    "               \"internal rate of return\": irr_fin,\n",
    "               \"current_interest\": current_penalty,\n",
    "                \"net present value\": npv_fin,\n",
    "               \"enironmental balance\": self.env_balance_tot}\n",
    "         \n",
    "        \n",
    "        self.previous_observation = self.observation.copy()\n",
    "        \n",
    "        return self.observation, reward, done, False, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18c69028",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TrainEnvironment(JA_60_arr, JA_240_arr, elec_consum_arr, import_price_rate, import_price_train_arr, Eff_train_arr, CAPEX_JA_train_arr)\n",
    "env_test = TestEnvironment(JA_60_arr, JA_240_arr, elec_consum_arr, import_price_rate, import_price_test_arr, Eff_test_arr, \n",
    "                           CAPEX_JA_test_arr, grid_factor_test_arr, pv_co2_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60c5c35c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#check_env(env)\n",
    "def test4(episodes, environment):    \n",
    "    for episode in range(episodes):\n",
    "        done = False\n",
    "        obs = environment.reset()\n",
    "        step = 0\n",
    "        print(obs, \"\\n\")\n",
    "        while not done:\n",
    "            step += 1\n",
    "            random_action = environment.action_space.sample()\n",
    "            obs, reward, done, trun, info = environment.step(random_action)\n",
    "            \n",
    "            \n",
    "            # Extracting the 2nd and 3rd key-value pairs\n",
    "            keys = list(info.keys())\n",
    "            values = list(info.values())\n",
    "\n",
    "            # Getting the 2nd key-value pair\n",
    "            zeroth_key = keys[0]\n",
    "            zeroth_value = values[0]\n",
    "\n",
    "            # Getting the 3rd key-value pair\n",
    "\n",
    "            sixth_key = keys[5]\n",
    "            sixth_value = values[5]\n",
    "            \n",
    "            print(\"STEP:\", step)\n",
    "            print(\"ACT\",\"\\n\",  random_action)\n",
    "            print(\"OBS\",\"\\n\",  obs)\n",
    "            print(zeroth_key, zeroth_value, sixth_key, sixth_value)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4903b5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.        , 0.        , 0.99974245, 0.9552167 , 0.9129922 ,\n",
      "       0.85152084, 0.8910442 , 0.        , 0.8731456 , 0.8863569 ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.9739295 ,\n",
      "       0.88317055, 0.99905765, 0.89180017, 0.        , 0.9793925 ,\n",
      "       0.        , 0.        , 0.9632497 , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.06935652, 0.11512984, 0.00636943,\n",
      "       0.7395664 , 0.        , 0.        , 0.        ], dtype=float32), {}) \n",
      "\n",
      "STEP: 1\n",
      "ACT \n",
      " [0 8]\n",
      "OBS \n",
      " [0.         0.         0.9926012  0.9361801  0.8982248  0.8408973\n",
      " 0.8817504  0.         0.8557852  0.8766868  0.         0.\n",
      " 0.         0.         0.         0.         0.997946   0.99029624\n",
      " 0.983579   0.9625607  0.8741782  0.988195   0.8943921  0.9914194\n",
      " 0.9760588  1.0018206  0.99068755 0.95381486 0.99135894 0.99299407\n",
      " 0.         0.         0.0654806  0.07353458 0.01116958 0.7395664\n",
      " 0.15748611 0.04587066 0.228     ]\n",
      "step financial balance (eur): 992.5942915183741 current_interest 1947.18\n",
      "\n",
      "\n",
      "STEP: 2\n",
      "ACT \n",
      " [12  5]\n",
      "OBS \n",
      " [0.9981597  0.9965252  0.98647714 0.9362109  0.8936342  0.9943588\n",
      " 0.871817   0.9845665  0.9848187  0.9972343  0.9883723  0.99604195\n",
      " 0.9938082  0.9948372  1.0014043  1.0007939  0.9917583  0.97703457\n",
      " 0.98022735 0.94749695 0.9927381  0.98712546 0.987889   0.974853\n",
      " 0.9721632  0.99220055 0.9803523  0.9859384  0.9778741  0.9849976\n",
      " 0.9892917  0.997215   0.06522389 0.07338262 0.01116958 0.7395664\n",
      " 0.6669773  0.25343752 0.27466667]\n",
      "step financial balance (eur): -3997.5837822411677 current_interest 1387.9268\n",
      "\n",
      "\n",
      "STEP: 3\n",
      "ACT \n",
      " [7 1]\n",
      "OBS \n",
      " [0.99202967 0.986915   0.9815481  0.9943624  1.0010942  0.9930421\n",
      " 0.9953037  0.99605155 0.99692225 0.97765994 0.9867562  0.98931515\n",
      " 0.98775494 0.9850654  0.9926432  0.99872607 0.9843827  0.9698273\n",
      " 0.9700363  0.99350166 0.9913875  0.9844171  0.9754533  0.95892453\n",
      " 0.9577651  0.98375016 0.96339756 0.9794432  0.9723953  0.9770543\n",
      " 0.98208296 0.98288643 0.09958044 0.05694787 0.01116959 0.7395664\n",
      " 0.2168524  0.33985007 0.58666664]\n",
      "step financial balance (eur): -1143.1998896392633 current_interest 1825.9104\n",
      "\n",
      "\n",
      "STEP: 4\n",
      "ACT \n",
      " [10  9]\n",
      "OBS \n",
      " [0.98500246 0.99390435 0.9957335  0.98741    0.985622   0.9832628\n",
      " 0.98331046 0.99795645 0.99378717 0.9931912  0.9972027  0.9983796\n",
      " 0.9958265  1.0022998  0.98490673 0.9871569  0.978706   0.998081\n",
      " 0.99252754 0.9832368  0.98291427 0.98065305 0.9889559  0.99052465\n",
      " 0.98770803 0.98432636 0.986556   0.9976813  0.9937161  0.98942524\n",
      " 0.971698   0.9766024  0.10710342 0.07915964 0.01123104 0.7395664\n",
      " 0.35579655 0.47042987 0.15466666]\n",
      "step financial balance (eur): -3238.388337105153 current_interest 4127.396\n",
      "\n",
      "\n",
      "STEP: 5\n",
      "ACT \n",
      " [0 3]\n",
      "OBS \n",
      " [0.97384083 0.9818942  0.99706346 0.9759941  0.9713127  0.9749359\n",
      " 0.98682755 0.9817458  0.9854999  0.99527127 0.99587375 0.9909176\n",
      " 0.98207307 0.9945016  0.9704226  0.9714943  0.9858172  0.99105424\n",
      " 0.989858   0.9710573  0.96836025 0.96718895 0.9816477  0.985419\n",
      " 0.9815195  0.9734789  0.97408915 0.98678446 0.98805624 0.9816269\n",
      " 1.0022469  0.99793226 0.11148259 0.04263554 0.01123117 0.7395664\n",
      " 0.11553331 0.48249397 0.916     ]\n",
      "step financial balance (eur): -1490.7474887714052 current_interest 640.16583\n",
      "\n",
      "\n",
      "STEP: 6\n",
      "ACT \n",
      " [14  2]\n",
      "OBS \n",
      " [0.99359363 0.9901067  0.9951654  0.9881436  0.9952453  0.9937343\n",
      " 1.0032104  0.9910265  0.9875211  0.9862092  0.98808235 0.9967004\n",
      " 0.99552333 0.98776215 0.99308264 0.98915553 0.9690416  0.9927644\n",
      " 0.9784925  0.950526   0.98946834 0.98956627 0.9651684  0.9802072\n",
      " 0.97462785 0.9575706  0.95782155 0.9799958  0.9818942  0.97156423\n",
      " 0.991651   0.99583036 0.12290046 0.03750876 0.0113564  0.7395664\n",
      " 0.34619498 0.31804338 0.7226667 ]\n",
      "step financial balance (eur): -4443.425029332295 current_interest 3221.1365\n",
      "\n",
      "\n",
      "STEP: 7\n",
      "ACT \n",
      " [9 6]\n",
      "OBS \n",
      " [0.9839056  0.99609137 0.9954362  0.99071413 0.9932989  0.9804823\n",
      " 0.9961907  0.97911435 0.9983161  0.9815321  0.9996212  0.99387884\n",
      " 0.98674685 0.9810757  0.985639   0.9891917  0.98486835 0.9869961\n",
      " 0.9742158  0.9943126  0.988007   0.97684574 0.99680555 0.9725934\n",
      " 0.9595727  0.9891216  0.99339074 0.96673995 0.97315836 1.0000316\n",
      " 0.9773091  0.9855585  0.15187946 0.04635304 0.01135658 0.7395664\n",
      " 0.2958068  0.33380213 0.42133334]\n",
      "step financial balance (eur): -2623.970294784169 current_interest 2785.6968\n",
      "\n",
      "\n",
      "STEP: 8\n",
      "ACT \n",
      " [ 7 14]\n",
      "OBS \n",
      " [0.9904107  0.9849404  1.0028648  0.97277296 0.97994864 0.9855575\n",
      " 0.9952892  0.98736495 0.9906031  0.9862048  0.977742   0.99087983\n",
      " 0.9947203  0.9914078  0.98863363 0.979772   0.99212515 0.99327266\n",
      " 0.9891784  0.99583507 0.99180156 0.98381895 0.98282194 0.9837593\n",
      " 0.99929625 0.9853294  0.99887264 0.99016446 0.99005455 1.0059141\n",
      " 0.9943115  1.0011762  0.16582365 0.05060875 0.02109207 0.7395664\n",
      " 0.3583493  0.32639876 0.72933334]\n",
      "step financial balance (eur): -3019.1563159627894 current_interest 3842.3792\n",
      "\n",
      "\n",
      "STEP: 9\n",
      "ACT \n",
      " [13 15]\n",
      "OBS \n",
      " [0.9931498  0.99600613 0.9929436  0.98972803 1.0065202  0.9928311\n",
      " 0.98178303 0.98783016 0.99303705 0.99313146 0.9911006  1.0061054\n",
      " 0.9866945  0.9959912  0.9980287  0.9931977  0.9970605  0.9935474\n",
      " 1.0108849  0.99603856 1.0053731  0.98861045 0.9896349  0.9898728\n",
      " 1.0007252  0.99206597 0.9884454  0.9952663  0.9870746  0.9983764\n",
      " 0.9887623  0.99223924 0.19406001 0.05922639 0.13919967 0.7395664\n",
      " 0.45184347 0.4330964  0.38266668]\n",
      "step financial balance (eur): -3717.191651053578 current_interest 4678.6226\n",
      "\n",
      "\n",
      "STEP: 10\n",
      "ACT \n",
      " [3 7]\n",
      "OBS \n",
      " [0.9919503  0.99666435 0.9894557  0.9821877  1.0026423  0.9733253\n",
      " 1.0145929  1.015408   0.991858   0.9814274  0.9851915  1.0005893\n",
      " 1.0108256  0.98877406 0.9925595  0.98249775 0.9933736  0.9836448\n",
      " 1.0098214  0.9880336  1.0011288  1.0148336  1.0055318  1.011459\n",
      " 0.9868113  1.016673   1.0073701  0.9934622  1.0159585  0.98627585\n",
      " 1.0177922  0.98599017 0.18748732 0.05722042 0.15337284 0.7395664\n",
      " 0.22306892 0.4117055  0.33066666]\n",
      "step financial balance (eur): -1937.1641977389563 current_interest 1593.9434\n",
      "\n",
      "\n",
      "STEP: 11\n",
      "ACT \n",
      " [0 1]\n",
      "OBS \n",
      " [0.9850905  0.9957288  0.98371166 0.97475207 1.0054016  0.965245\n",
      " 1.005658   1.0082527  0.9829557  0.97074413 0.9777918  0.9884619\n",
      " 1.00287    0.9773453  0.98487043 0.971611   0.98371077 1.0199251\n",
      " 1.0003198  0.9807032  0.99186456 1.0055306  1.0021431  0.99781036\n",
      " 0.9834149  1.0091327  0.9989297  0.9790171  1.0058249  0.97666013\n",
      " 1.011015   0.9784601  0.16456057 0.05022326 0.15337284 0.7395664\n",
      " 0.08826929 0.36964458 0.13066667]\n",
      "step financial balance (eur): -521.5262711196933 current_interest 157.24246\n",
      "\n",
      "\n",
      "STEP: 12\n",
      "ACT \n",
      " [4 8]\n",
      "OBS \n",
      " [0.98255545 0.9960527  0.9642213  1.0103554  0.9997563  1.0181978\n",
      " 0.99126506 1.0084999  0.971954   1.016723   0.9764561  0.97937\n",
      " 0.99935687 0.96570617 0.9840192  1.0128092  1.0056138  1.0025136\n",
      " 1.0082384  1.0124669  1.0134257  0.99971366 0.9843253  1.0188471\n",
      " 1.0145664  0.99837637 0.99150103 1.0091784  1.0074325  1.0121205\n",
      " 1.0041614  1.0092406  0.18228231 0.05563188 0.15337288 0.7395664\n",
      " 0.25104478 0.3339044  0.26533332]\n",
      "step financial balance (eur): -2050.026751545426 current_interest 1801.2686\n",
      "\n",
      "\n",
      "STEP: 13\n",
      "ACT \n",
      " [14  4]\n",
      "OBS \n",
      " [1.0095671  1.0191871  1.0201027  1.01617    1.0114499  1.0092545\n",
      " 1.0089867  1.0052426  1.0164815  1.0060688  1.0184075  1.0109408\n",
      " 1.014926   1.0178692  1.0052311  1.008152   0.9883722  0.99210924\n",
      " 0.9900039  1.007072   1.0022289  1.0191692  1.013701   1.0205448\n",
      " 1.0028174  1.0158833  1.0040683  1.0097985  0.9950085  0.9931712\n",
      " 0.99587446 1.0109144  0.20231408 0.06174549 0.15337288 0.7395664\n",
      " 0.3418056  0.28881276 0.028     ]\n",
      "step financial balance (eur): -2411.846652310427 current_interest 2507.4443\n",
      "\n",
      "\n",
      "STEP: 14\n",
      "ACT \n",
      " [11  3]\n",
      "OBS \n",
      " [1.0168033  1.0110711  1.0049798  1.0201313  1.0156797  1.0233151\n",
      " 1.0129721  1.0208857  1.0084807  1.016349   1.0115715  1.0115657\n",
      " 1.0128665  1.0003736  1.0171015  1.0105058  1.0212415  1.011296\n",
      " 1.0215662  1.0045782  1.0036069  1.0225371  1.0055803  1.0159246\n",
      " 0.9941652  1.0049446  0.99736893 1.0061394  0.9892827  0.9846563\n",
      " 0.98273414 0.99365366 0.25769544 0.07864768 0.1534207  0.7395664\n",
      " 0.29977772 0.29197055 0.5053333 ]\n",
      "step financial balance (eur): -1397.1575159434478 current_interest 1982.0033\n",
      "\n",
      "\n",
      "STEP: 15\n",
      "ACT \n",
      " [2 0]\n",
      "OBS \n",
      " [1.0044655  0.99645346 1.0063514  1.0064939  1.0161072  1.0181596\n",
      " 1.0053291  1.0115995  0.9800459  1.0033739  1.0007442  1.0030138\n",
      " 1.0145495  1.0210212  1.0112189  0.9999339  1.0105726  1.0105071\n",
      " 1.0131738  0.99394375 0.99717164 1.0065057  0.9962005  0.99798506\n",
      " 0.99194884 0.99423295 0.98473847 0.9916107  0.99035645 0.9850133\n",
      " 0.9731992  0.98450595 0.25108692 0.07663078 0.15617009 0.7395664\n",
      " 0.11542353 0.34842396 0.28133333]\n",
      "step financial balance (eur): 1057.987028410079 current_interest 267.03595\n",
      "\n",
      "\n",
      "STEP: 16\n",
      "ACT \n",
      " [ 8 13]\n",
      "OBS \n",
      " [1.0228938  1.0082257  1.0056261  0.9926911  1.0129015  1.0082431\n",
      " 1.0058231  0.99216634 1.0168765  1.021314   1.0149354  1.0232525\n",
      " 1.011227   1.0047295  1.0032973  1.0201118  1.0019104  1.0026867\n",
      " 0.9971774  1.0141269  1.0193383  1.0112442  1.011164   1.0127499\n",
      " 1.0179656  1.0199119  1.013915   1.0103313  1.0078465  1.0087485\n",
      " 1.0120746  1.0159496  0.2842698  0.08675808 0.15619613 0.7395664\n",
      " 0.34484535 0.37287042 0.71466666]\n",
      "step financial balance (eur): -1714.969313990172 current_interest 2652.023\n",
      "\n",
      "\n",
      "STEP: 17\n",
      "ACT \n",
      " [1 1]\n",
      "OBS \n",
      " [1.0131366  1.002972   1.008137   0.9741585  1.0041327  1.000958\n",
      " 0.9966721  1.0093465  1.0055361  1.0249759  1.0137764  1.0117955\n",
      " 1.0100951  0.9999426  0.9930438  1.0118445  0.988993   0.9876811\n",
      " 1.0155455  1.0005357  1.0069171  0.9998169  1.0007359  1.0034232\n",
      " 1.0148009  1.0172174  1.0051178  0.9979687  0.99535197 0.99215245\n",
      " 1.0009685  1.0031506  0.26612532 0.08122045 0.15619613 0.7395664\n",
      " 0.11966571 0.29412067 0.78      ]\n",
      "step financial balance (eur): 701.4985941785844 current_interest 253.97151\n",
      "\n",
      "\n",
      "STEP: 18\n",
      "ACT \n",
      " [ 6 13]\n",
      "OBS \n",
      " [1.0031672  1.0163647  1.0035589  1.0152947  0.98905545 1.0108675\n",
      " 1.0126535  0.99344623 0.9847658  1.0032703  1.0088667  1.0084376\n",
      " 1.0016999  1.0122142  1.0228891  1.0148104  1.0124662  1.0142361\n",
      " 1.0141181  1.0113413  1.0146339  1.0178474  1.0217103  1.015206\n",
      " 1.0093963  1.0077432  1.0105323  1.0092934  1.0188392  1.0176227\n",
      " 1.0154575  1.0193233  0.2671595  0.08153607 0.15626675 0.7395664\n",
      " 0.33190623 0.22946228 0.96133333]\n",
      "step financial balance (eur): -973.4788946899125 current_interest 2233.0825\n",
      "\n",
      "\n",
      "STEP: 19\n",
      "ACT \n",
      " [14 15]\n",
      "OBS \n",
      " [1.0122901  1.0047071  1.0183145  1.0101217  1.0087539  1.0087563\n",
      " 1.0132501  1.0227786  1.0149349  1.0117362  1.0150932  1.0126878\n",
      " 1.0221856  1.0135208  1.0095568  1.0052433  1.0076987  1.0218173\n",
      " 1.0215755  1.0163393  1.0112184  1.0170548  1.0167215  1.0249246\n",
      " 1.0155944  1.0094953  1.0227287  1.012748   1.0108408  1.0147715\n",
      " 1.0153855  1.0294594  0.28538018 0.08709695 0.15626675 0.7395664\n",
      " 0.4409883  0.32318586 0.14133333]\n",
      "step financial balance (eur): -1510.1001774267324 current_interest 3310.4119\n",
      "\n",
      "\n",
      "STEP: 20\n",
      "ACT \n",
      " [13  9]\n",
      "OBS \n",
      " [1.014535   1.0113646  1.0034297  1.0198838  1.005466   1.0215011\n",
      " 1.0225474  1.0172215  1.0191376  1.0166401  1.0159768  1.0231134\n",
      " 1.0130577  1.0131191  1.0100422  1.0245076  1.0114237  1.0204139\n",
      " 1.008858   1.0185843  1.0149106  1.0066602  1.0108125  1.0166059\n",
      " 1.0161555  1.0135312  1.0125583  1.0051193  1.0190108  1.0075268\n",
      " 1.0081402  1.0165172  0.29164812 0.0890099  0.15626675 0.7395664\n",
      " 0.3837516  0.3258165  0.33066666]\n",
      "step financial balance (eur): -1466.8474421828341 current_interest 2499.6003\n",
      "\n",
      "\n",
      "STEP: 21\n",
      "ACT \n",
      " [ 7 13]\n",
      "OBS \n",
      " [1.0091258  1.0150212  1.0191066  1.0178188  1.0118304  1.0137272\n",
      " 1.0132802  1.0123335  0.99552447 1.0026792  1.0097641  1.0222974\n",
      " 1.0188577  1.0267811  1.0029093  1.007865   1.0226806  1.0064509\n",
      " 1.018302   1.0098531  1.017575   1.0152305  1.0305307  1.0029333\n",
      " 1.022137   1.0273446  1.0105387  1.029518   1.017236   1.0229927\n",
      " 1.0093601  1.0231751  0.26666722 0.08138583 0.15639758 0.7395664\n",
      " 0.35321355 0.4572613  0.12666667]\n",
      "step financial balance (eur): -1111.118596910078 current_interest 2236.2944\n",
      "\n",
      "\n",
      "STEP: 22\n",
      "ACT \n",
      " [11 11]\n",
      "OBS \n",
      " [1.0189189  1.0137246  1.004159   1.0152384  1.0237302  1.0068301\n",
      " 1.0176281  1.0133562  1.0161026  1.0151312  1.017656   1.0161345\n",
      " 1.0143902  1.0260041  1.0156543  1.0237807  1.0193648  1.0202328\n",
      " 1.0073022  1.0066339  1.012292   1.0200331  1.0124266  1.0167859\n",
      " 1.0178452  1.0162942  1.0194436  1.0164896  1.0139887  1.0154654\n",
      " 1.0132145  1.0174675  0.2653008  0.0809688  0.16006806 0.7395664\n",
      " 0.39480433 0.5074849  0.11866666]\n",
      "step financial balance (eur): -2874.4702113870107 current_interest 2406.545\n",
      "\n",
      "\n",
      "STEP: 23\n",
      "ACT \n",
      " [10 13]\n",
      "OBS \n",
      " [1.0214     1.0230193  1.0181056  1.0241123  1.0207187  1.0268788\n",
      " 1.0162644  1.0119132  1.0256063  1.0123963  1.0097936  1.0177473\n",
      " 1.0139564  1.0161973  1.024403   1.0143332  1.0221688  1.0140553\n",
      " 1.0135736  1.014207   1.0080785  1.0094063  1.0073347  1.0056171\n",
      " 1.0191354  1.0087212  1.0186801  1.0175097  1.0178293  1.0241382\n",
      " 1.0187789  1.0244176  0.30952936 0.09446719 0.19939108 0.7395664\n",
      " 0.3948789  0.52268237 0.136     ]\n",
      "step financial balance (eur): -3296.0131462051904 current_interest 2439.7847\n",
      "\n",
      "\n",
      "STEP: 24\n",
      "ACT \n",
      " [15  8]\n",
      "OBS \n",
      " [1.0221826  1.0168387  1.0260125  1.0271932  1.0238723  1.0204699\n",
      " 1.013768   1.0202359  1.0210352  1.0230047  1.0285071  1.0128086\n",
      " 1.0226716  1.0172694  1.0277879  1.0212356  1.016198   1.0282758\n",
      " 1.0083461  1.0282364  1.0223452  1.0184257  1.0314342  1.0188724\n",
      " 1.0070395  1.0171509  1.0093397  1.0018657  1.0056586  1.0147561\n",
      " 1.0164186  1.0243473  0.34132868 0.10417222 0.19974792 0.7395664\n",
      " 0.41779736 0.5319729  0.972     ]\n",
      "step financial balance (eur): -3079.027666272448 current_interest 2361.7974\n",
      "\n",
      "\n",
      "STEP: 25\n",
      "ACT \n",
      " [7 4]\n",
      "OBS \n",
      " [1.019192   1.0251154  1.0211464  1.0185056  1.0166622  1.0168946\n",
      " 1.0258092  1.0271151  1.029535   1.0338922  1.0139397  1.014308\n",
      " 1.0154915  1.0215704  1.0234108  1.016941   1.0112194  1.0199066\n",
      " 1.0202662  1.0156709  1.0050046  1.0145608  1.0183964  1.0154835\n",
      " 1.0208741  1.0077059  1.0052545  1.0236636  1.0162632  1.003609\n",
      " 1.0109752  1.0156671  0.34132868 0.10417222 0.19974792 0.7395664\n",
      " 0.291293   0.5129404  0.892     ]\n",
      "step financial balance (eur): -1516.2896910991713 current_interest 1057.9888\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test3(1, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1279284b",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Reward:-2.5342593958167416 \n",
      "\n",
      "total financial balance: (eur) -80418.55369434791 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -51769.51169815731 \n",
      "\n",
      "Episode:2 Reward:-3.647412439672943 \n",
      "\n",
      "total financial balance: (eur) -80308.9055916943 \n",
      "\n",
      "internal rate of return 294.152830666034 \n",
      "\n",
      "net present value -51994.867591901944 \n",
      "\n",
      "Episode:3 Reward:-2.719391640985068 \n",
      "\n",
      "total financial balance: (eur) -93743.6933685955 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -59182.75871330115 \n",
      "\n",
      "Episode:4 Reward:-1.2503599397677134 \n",
      "\n",
      "total financial balance: (eur) -69528.9024093443 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -45658.886840428575 \n",
      "\n",
      "Episode:5 Reward:-0.5886773663306339 \n",
      "\n",
      "total financial balance: (eur) -67903.83693100762 \n",
      "\n",
      "internal rate of return 753.3031100444558 \n",
      "\n",
      "net present value -45317.608796142704 \n",
      "\n",
      "Episode:6 Reward:-5.70775762690567 \n",
      "\n",
      "total financial balance: (eur) -71179.2048637658 \n",
      "\n",
      "internal rate of return 217.93306789473883 \n",
      "\n",
      "net present value -43721.38999970594 \n",
      "\n",
      "Episode:7 Reward:-2.8302628384603596 \n",
      "\n",
      "total financial balance: (eur) -81344.4347892234 \n",
      "\n",
      "internal rate of return 593.8199570256895 \n",
      "\n",
      "net present value -49229.30641123407 \n",
      "\n",
      "Episode:8 Reward:-2.273059374644149 \n",
      "\n",
      "total financial balance: (eur) -64680.87214189826 \n",
      "\n",
      "internal rate of return 205.48320040186377 \n",
      "\n",
      "net present value -40831.875807034456 \n",
      "\n",
      "Episode:9 Reward:-5.234659853912863 \n",
      "\n",
      "total financial balance: (eur) -64277.925202798884 \n",
      "\n",
      "internal rate of return 157.85803378996422 \n",
      "\n",
      "net present value -37901.17038185374 \n",
      "\n",
      "Episode:10 Reward:-2.799641021855923 \n",
      "\n",
      "total financial balance: (eur) -63690.03095850867 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -39963.46295450796 \n",
      "\n",
      "Episode:11 Reward:-1.948362521916727 \n",
      "\n",
      "total financial balance: (eur) -64425.585975928574 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -44292.713101196474 \n",
      "\n",
      "Episode:12 Reward:-4.554008000947408 \n",
      "\n",
      "total financial balance: (eur) -75892.58793538783 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -47276.200764529465 \n",
      "\n",
      "Episode:13 Reward:-4.452472047359319 \n",
      "\n",
      "total financial balance: (eur) -63538.142421656565 \n",
      "\n",
      "internal rate of return 197.95917719256843 \n",
      "\n",
      "net present value -40664.009266973226 \n",
      "\n",
      "Episode:14 Reward:-0.26522616010254885 \n",
      "\n",
      "total financial balance: (eur) -76267.5462428062 \n",
      "\n",
      "internal rate of return 486.09457177753404 \n",
      "\n",
      "net present value -49410.330063597845 \n",
      "\n",
      "Episode:15 Reward:-1.5109854807506782 \n",
      "\n",
      "total financial balance: (eur) -66706.60863140099 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -43866.63935277736 \n",
      "\n",
      "Episode:16 Reward:-3.4341022791704217 \n",
      "\n",
      "total financial balance: (eur) -88067.68286363552 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -56731.40539392414 \n",
      "\n",
      "Episode:17 Reward:-4.118301191501256 \n",
      "\n",
      "total financial balance: (eur) -58678.0856526325 \n",
      "\n",
      "internal rate of return 427.86847568749346 \n",
      "\n",
      "net present value -39041.895788051035 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kubaw\\AppData\\Local\\Temp\\ipykernel_84356\\1983629845.py:228: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  value = annual_expense / self.current_budget_constraint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:18 Reward:-2.279843965412834 \n",
      "\n",
      "total financial balance: (eur) -76323.7962088045 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -52619.086651227146 \n",
      "\n",
      "Episode:19 Reward:-2.05616171648775 \n",
      "\n",
      "total financial balance: (eur) -67584.64893408843 \n",
      "\n",
      "internal rate of return 162.65554084919637 \n",
      "\n",
      "net present value -45292.582108908675 \n",
      "\n",
      "Episode:20 Reward:-0.09532370508377153 \n",
      "\n",
      "total financial balance: (eur) -43924.884839871236 \n",
      "\n",
      "internal rate of return 320.61356457596435 \n",
      "\n",
      "net present value -27713.694842657365 \n",
      "\n",
      "Episode:21 Reward:-1.8845726056455332 \n",
      "\n",
      "total financial balance: (eur) -61486.425926682554 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -41449.324976539596 \n",
      "\n",
      "Episode:22 Reward:-2.0206869488630748 \n",
      "\n",
      "total financial balance: (eur) -64099.61674412859 \n",
      "\n",
      "internal rate of return 252.03758940743774 \n",
      "\n",
      "net present value -42608.97846101613 \n",
      "\n",
      "Episode:23 Reward:-4.474851746164064 \n",
      "\n",
      "total financial balance: (eur) -74223.95826910475 \n",
      "\n",
      "internal rate of return 187.80601707688422 \n",
      "\n",
      "net present value -46330.008756789844 \n",
      "\n",
      "Episode:24 Reward:-3.213507868896674 \n",
      "\n",
      "total financial balance: (eur) -44689.06817544104 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -27915.01870448318 \n",
      "\n",
      "Episode:25 Reward:-1.5161055696449266 \n",
      "\n",
      "total financial balance: (eur) -46835.56585422191 \n",
      "\n",
      "internal rate of return 79.79978874311087 \n",
      "\n",
      "net present value -31126.902593528925 \n",
      "\n",
      "Episode:26 Reward:-3.311563079949892 \n",
      "\n",
      "total financial balance: (eur) -92499.54870156196 \n",
      "\n",
      "internal rate of return 128.8126534327032 \n",
      "\n",
      "net present value -57640.217183223416 \n",
      "\n",
      "Episode:27 Reward:-1.8649008539378025 \n",
      "\n",
      "total financial balance: (eur) -46505.63804113152 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -27320.33304484291 \n",
      "\n",
      "Episode:28 Reward:-2.48265337948685 \n",
      "\n",
      "total financial balance: (eur) -65793.80906084464 \n",
      "\n",
      "internal rate of return 1848.5091332203087 \n",
      "\n",
      "net present value -40656.20707753412 \n",
      "\n",
      "Episode:29 Reward:-1.7637319663926874 \n",
      "\n",
      "total financial balance: (eur) -65156.58619186395 \n",
      "\n",
      "internal rate of return 315.75891076502785 \n",
      "\n",
      "net present value -41418.43404058965 \n",
      "\n",
      "Episode:30 Reward:-0.8146963116933285 \n",
      "\n",
      "total financial balance: (eur) -52410.08375984704 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -34390.87056701148 \n",
      "\n",
      "Episode:31 Reward:-0.7425796315968719 \n",
      "\n",
      "total financial balance: (eur) -83341.62499012215 \n",
      "\n",
      "internal rate of return 447.6829639089645 \n",
      "\n",
      "net present value -54957.94072553598 \n",
      "\n",
      "Episode:32 Reward:-3.9092623151150248 \n",
      "\n",
      "total financial balance: (eur) -91272.21395662698 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -58415.20911890993 \n",
      "\n",
      "Episode:33 Reward:-2.5621334366050013 \n",
      "\n",
      "total financial balance: (eur) -63503.623738996976 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -39914.30111966401 \n",
      "\n",
      "Episode:34 Reward:-1.3539703988990277 \n",
      "\n",
      "total financial balance: (eur) -62098.47423171593 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -39893.84199991848 \n",
      "\n",
      "Episode:35 Reward:5.7222482351716915 \n",
      "\n",
      "total financial balance: (eur) 13879.739798632507 \n",
      "\n",
      "internal rate of return 3.9215124709536697 \n",
      "\n",
      "net present value -159.04325784183902 \n",
      "\n",
      "Episode:36 Reward:-1.9297012662893522 \n",
      "\n",
      "total financial balance: (eur) -66550.09569079184 \n",
      "\n",
      "internal rate of return 583.9353410870709 \n",
      "\n",
      "net present value -41922.689905453604 \n",
      "\n",
      "Episode:37 Reward:-2.701158524350315 \n",
      "\n",
      "total financial balance: (eur) -61751.28537654341 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -39198.6262688706 \n",
      "\n",
      "Episode:38 Reward:-0.7925566814753402 \n",
      "\n",
      "total financial balance: (eur) -55962.33733754697 \n",
      "\n",
      "internal rate of return 1045.937037957123 \n",
      "\n",
      "net present value -39128.697474566296 \n",
      "\n",
      "Episode:39 Reward:-1.9024340239355533 \n",
      "\n",
      "total financial balance: (eur) -48286.80450330131 \n",
      "\n",
      "internal rate of return 113.36282220180043 \n",
      "\n",
      "net present value -29563.282001446736 \n",
      "\n",
      "Episode:40 Reward:1.130707049931808 \n",
      "\n",
      "total financial balance: (eur) -59913.03093481617 \n",
      "\n",
      "internal rate of return -43.9326133181097 \n",
      "\n",
      "net present value -40709.00787629327 \n",
      "\n",
      "Episode:41 Reward:-0.14969970097240912 \n",
      "\n",
      "total financial balance: (eur) -78992.01726889522 \n",
      "\n",
      "internal rate of return 493.45301587597606 \n",
      "\n",
      "net present value -49660.10586088804 \n",
      "\n",
      "Episode:42 Reward:-2.4222854332137467 \n",
      "\n",
      "total financial balance: (eur) -61725.725133694024 \n",
      "\n",
      "internal rate of return 149.14125847695047 \n",
      "\n",
      "net present value -38562.38423430919 \n",
      "\n",
      "Episode:43 Reward:-1.8535928726802777 \n",
      "\n",
      "total financial balance: (eur) -85170.22754248876 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -56000.16015425482 \n",
      "\n",
      "Episode:44 Reward:1.4974449060849802 \n",
      "\n",
      "total financial balance: (eur) -53944.36862085885 \n",
      "\n",
      "internal rate of return -43.73287769463581 \n",
      "\n",
      "net present value -36659.14244033051 \n",
      "\n",
      "Episode:45 Reward:1.2782849093594695 \n",
      "\n",
      "total financial balance: (eur) -46976.34573381002 \n",
      "\n",
      "internal rate of return -31.799552743312287 \n",
      "\n",
      "net present value -34745.19491588215 \n",
      "\n",
      "Episode:46 Reward:-2.099836737531132 \n",
      "\n",
      "total financial balance: (eur) -55881.702204426474 \n",
      "\n",
      "internal rate of return 1105.055411437224 \n",
      "\n",
      "net present value -37221.166980027316 \n",
      "\n",
      "Episode:47 Reward:0.9426739729998963 \n",
      "\n",
      "total financial balance: (eur) -51748.911702380545 \n",
      "\n",
      "internal rate of return -52.027558877448264 \n",
      "\n",
      "net present value -34812.94102300365 \n",
      "\n",
      "Episode:48 Reward:1.6391326628312277 \n",
      "\n",
      "total financial balance: (eur) -46428.94768936984 \n",
      "\n",
      "internal rate of return -48.425744026770836 \n",
      "\n",
      "net present value -30046.113451445253 \n",
      "\n",
      "Episode:49 Reward:1.3194244651612088 \n",
      "\n",
      "total financial balance: (eur) -19607.972635825518 \n",
      "\n",
      "internal rate of return -8.29697529136666 \n",
      "\n",
      "net present value -18077.72964006126 \n",
      "\n",
      "Episode:50 Reward:-5.908559886257173 \n",
      "\n",
      "total financial balance: (eur) -83659.74977902016 \n",
      "\n",
      "internal rate of return 183.85965964962162 \n",
      "\n",
      "net present value -48174.99364735046 \n",
      "\n",
      "Episode:51 Reward:-2.1165540708858335 \n",
      "\n",
      "total financial balance: (eur) -61417.76757637327 \n",
      "\n",
      "internal rate of return 187.47593708507182 \n",
      "\n",
      "net present value -38582.451827266435 \n",
      "\n",
      "Episode:52 Reward:-0.5528395077265049 \n",
      "\n",
      "total financial balance: (eur) -35695.83556564269 \n",
      "\n",
      "internal rate of return 320.7114754909581 \n",
      "\n",
      "net present value -25719.510154516545 \n",
      "\n",
      "Episode:53 Reward:-1.0290837793963592 \n",
      "\n",
      "total financial balance: (eur) -49281.43102230829 \n",
      "\n",
      "internal rate of return 375.91092787378557 \n",
      "\n",
      "net present value -33899.49512222594 \n",
      "\n",
      "Episode:54 Reward:-2.2201481650286676 \n",
      "\n",
      "total financial balance: (eur) -86437.71156650131 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -53956.8147835046 \n",
      "\n",
      "Episode:55 Reward:-5.9928976992119924 \n",
      "\n",
      "total financial balance: (eur) -82997.6676511417 \n",
      "\n",
      "internal rate of return 136.05374006264697 \n",
      "\n",
      "net present value -48533.10334754073 \n",
      "\n",
      "Episode:56 Reward:-3.748205168646526 \n",
      "\n",
      "total financial balance: (eur) -100633.66851982503 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -63238.100724883 \n",
      "\n",
      "Episode:57 Reward:-0.8124850901822065 \n",
      "\n",
      "total financial balance: (eur) -32339.098290339407 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -21915.96411218713 \n",
      "\n",
      "Episode:58 Reward:1.8217051153370503 \n",
      "\n",
      "total financial balance: (eur) -33141.44248421284 \n",
      "\n",
      "internal rate of return -28.021070586921738 \n",
      "\n",
      "net present value -23244.738398729096 \n",
      "\n",
      "Episode:59 Reward:-1.650872797630319 \n",
      "\n",
      "total financial balance: (eur) -69870.50376138413 \n",
      "\n",
      "internal rate of return 141.8260662267409 \n",
      "\n",
      "net present value -44783.43881790437 \n",
      "\n",
      "Episode:60 Reward:0.08676163305069622 \n",
      "\n",
      "total financial balance: (eur) -42284.95965817787 \n",
      "\n",
      "internal rate of return -28.328802622673056 \n",
      "\n",
      "net present value -29153.21601002384 \n",
      "\n",
      "Episode:61 Reward:-2.8100939922276416 \n",
      "\n",
      "total financial balance: (eur) -66074.94485655124 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -42074.45349401965 \n",
      "\n",
      "Episode:62 Reward:-0.8109087816878755 \n",
      "\n",
      "total financial balance: (eur) -64665.440154188 \n",
      "\n",
      "internal rate of return 235.54670936626164 \n",
      "\n",
      "net present value -43275.86696085984 \n",
      "\n",
      "Episode:63 Reward:-2.765098996419114 \n",
      "\n",
      "total financial balance: (eur) -49594.323573896516 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -34753.06172216622 \n",
      "\n",
      "Episode:64 Reward:-2.9823383454353425 \n",
      "\n",
      "total financial balance: (eur) -77025.31707480943 \n",
      "\n",
      "internal rate of return 140.97551320155435 \n",
      "\n",
      "net present value -48145.11216725458 \n",
      "\n",
      "Episode:65 Reward:-1.0345006387483444 \n",
      "\n",
      "total financial balance: (eur) -66351.47558572338 \n",
      "\n",
      "internal rate of return 225.28387867919895 \n",
      "\n",
      "net present value -44773.45663626956 \n",
      "\n",
      "Episode:66 Reward:-2.359301893678485 \n",
      "\n",
      "total financial balance: (eur) -63949.71839679847 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -40974.663247534365 \n",
      "\n",
      "Episode:67 Reward:-2.7398493521636857 \n",
      "\n",
      "total financial balance: (eur) -58262.0723463412 \n",
      "\n",
      "internal rate of return 161.00208394333976 \n",
      "\n",
      "net present value -34542.901713608015 \n",
      "\n",
      "Episode:68 Reward:-0.5016307761676071 \n",
      "\n",
      "total financial balance: (eur) -51224.30376828471 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -36779.51530423721 \n",
      "\n",
      "Episode:69 Reward:-0.8447876302892237 \n",
      "\n",
      "total financial balance: (eur) -39214.27788703058 \n",
      "\n",
      "internal rate of return 450.7107468260334 \n",
      "\n",
      "net present value -28250.81928983646 \n",
      "\n",
      "Episode:70 Reward:-0.2475491993575597 \n",
      "\n",
      "total financial balance: (eur) -39912.32383785132 \n",
      "\n",
      "internal rate of return -28.357482057830364 \n",
      "\n",
      "net present value -28728.838451732383 \n",
      "\n",
      "Episode:71 Reward:-2.338219211263885 \n",
      "\n",
      "total financial balance: (eur) -57602.44007550508 \n",
      "\n",
      "internal rate of return 83.90175241874498 \n",
      "\n",
      "net present value -34285.740832356016 \n",
      "\n",
      "Episode:72 Reward:-3.0785269182797474 \n",
      "\n",
      "total financial balance: (eur) -73050.79840350663 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -46187.94378730883 \n",
      "\n",
      "Episode:73 Reward:-4.661561125031747 \n",
      "\n",
      "total financial balance: (eur) -76658.35690951257 \n",
      "\n",
      "internal rate of return 306.00219950709595 \n",
      "\n",
      "net present value -47720.51020309205 \n",
      "\n",
      "Episode:74 Reward:0.4411395335416437 \n",
      "\n",
      "total financial balance: (eur) -63304.983376418764 \n",
      "\n",
      "internal rate of return -30.993721529052888 \n",
      "\n",
      "net present value -45534.827300695615 \n",
      "\n",
      "Episode:75 Reward:-4.745623400497036 \n",
      "\n",
      "total financial balance: (eur) -81949.76896790549 \n",
      "\n",
      "internal rate of return 1380.8604077678976 \n",
      "\n",
      "net present value -50345.928496693035 \n",
      "\n",
      "Episode:76 Reward:-3.64106379484725 \n",
      "\n",
      "total financial balance: (eur) -39543.31286793558 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -26120.022603447098 \n",
      "\n",
      "Episode:77 Reward:-4.633660919838136 \n",
      "\n",
      "total financial balance: (eur) -100396.5999245131 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -62842.72712603147 \n",
      "\n",
      "Episode:78 Reward:-0.3947463640060141 \n",
      "\n",
      "total financial balance: (eur) -48534.60423195112 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -34017.06691124492 \n",
      "\n",
      "Episode:79 Reward:-2.683919995955676 \n",
      "\n",
      "total financial balance: (eur) -68365.45422810753 \n",
      "\n",
      "internal rate of return 129.08202735371717 \n",
      "\n",
      "net present value -42201.64252624988 \n",
      "\n",
      "Episode:80 Reward:-5.637640345430595 \n",
      "\n",
      "total financial balance: (eur) -70814.35984076456 \n",
      "\n",
      "internal rate of return 170.95954876564988 \n",
      "\n",
      "net present value -41270.39723808424 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:81 Reward:-1.8430610581938753 \n",
      "\n",
      "total financial balance: (eur) -82813.55299343639 \n",
      "\n",
      "internal rate of return 159.59815014487225 \n",
      "\n",
      "net present value -53268.24239528539 \n",
      "\n",
      "Episode:82 Reward:-3.3399140567775976 \n",
      "\n",
      "total financial balance: (eur) -68915.0639950152 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -43888.7928325329 \n",
      "\n",
      "Episode:83 Reward:-2.126526861797055 \n",
      "\n",
      "total financial balance: (eur) -60332.01763239199 \n",
      "\n",
      "internal rate of return 171.86727464598994 \n",
      "\n",
      "net present value -39028.33518084645 \n",
      "\n",
      "Episode:84 Reward:-3.7584417186052494 \n",
      "\n",
      "total financial balance: (eur) -61735.48158193283 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -38974.66253998677 \n",
      "\n",
      "Episode:85 Reward:-0.22821262252634916 \n",
      "\n",
      "total financial balance: (eur) -79975.98533025062 \n",
      "\n",
      "internal rate of return 205.8541137789576 \n",
      "\n",
      "net present value -52570.779286469595 \n",
      "\n",
      "Episode:86 Reward:-4.864013405822677 \n",
      "\n",
      "total financial balance: (eur) -80106.88273721113 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -52736.686844793156 \n",
      "\n",
      "Episode:87 Reward:2.070693978862556 \n",
      "\n",
      "total financial balance: (eur) -36933.12211497446 \n",
      "\n",
      "internal rate of return -27.196026172322508 \n",
      "\n",
      "net present value -25552.071448317532 \n",
      "\n",
      "Episode:88 Reward:-3.675059852799942 \n",
      "\n",
      "total financial balance: (eur) -102645.88728962727 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -64866.96841880789 \n",
      "\n",
      "Episode:89 Reward:-2.674166441884181 \n",
      "\n",
      "total financial balance: (eur) -77142.85867705624 \n",
      "\n",
      "internal rate of return 1380.0268851769224 \n",
      "\n",
      "net present value -51222.710430054634 \n",
      "\n",
      "Episode:90 Reward:-1.0974395777813206 \n",
      "\n",
      "total financial balance: (eur) -45771.81833842106 \n",
      "\n",
      "internal rate of return 198.69193298325297 \n",
      "\n",
      "net present value -28945.28685385938 \n",
      "\n",
      "Episode:91 Reward:-3.126904298934789 \n",
      "\n",
      "total financial balance: (eur) -72929.72564965565 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -47785.94015701094 \n",
      "\n",
      "Episode:92 Reward:-2.618735287287489 \n",
      "\n",
      "total financial balance: (eur) -57887.0127142647 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -38112.019701925004 \n",
      "\n",
      "Episode:93 Reward:-1.8265708729361858 \n",
      "\n",
      "total financial balance: (eur) -72030.61562263475 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -46343.80426611594 \n",
      "\n",
      "Episode:94 Reward:-5.612244966847542 \n",
      "\n",
      "total financial balance: (eur) -90954.52122106907 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -54960.02569083529 \n",
      "\n",
      "Episode:95 Reward:-2.6920847845454947 \n",
      "\n",
      "total financial balance: (eur) -80644.77723566811 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -50460.49022738444 \n",
      "\n",
      "Episode:96 Reward:1.252781364892635 \n",
      "\n",
      "total financial balance: (eur) -17844.680308201274 \n",
      "\n",
      "internal rate of return -5.25974637503408 \n",
      "\n",
      "net present value -19745.038715227493 \n",
      "\n",
      "Episode:97 Reward:-1.2315494593347476 \n",
      "\n",
      "total financial balance: (eur) -48631.0965729682 \n",
      "\n",
      "internal rate of return 394.4973547413691 \n",
      "\n",
      "net present value -32361.52372209491 \n",
      "\n",
      "Episode:98 Reward:-3.1834856617411496 \n",
      "\n",
      "total financial balance: (eur) -72744.02701062817 \n",
      "\n",
      "internal rate of return 771.5790366668548 \n",
      "\n",
      "net present value -45879.8644850277 \n",
      "\n",
      "Episode:99 Reward:1.1462079233428348 \n",
      "\n",
      "total financial balance: (eur) -10560.711498044078 \n",
      "\n",
      "internal rate of return -12.092584827778918 \n",
      "\n",
      "net present value -8189.4179474360835 \n",
      "\n",
      "Episode:100 Reward:-5.69224210949193 \n",
      "\n",
      "total financial balance: (eur) -66761.84135289058 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -38211.92155934961 \n",
      "\n",
      "Episode:101 Reward:-2.424381384880464 \n",
      "\n",
      "total financial balance: (eur) -55886.607798355086 \n",
      "\n",
      "internal rate of return 120.719195829346 \n",
      "\n",
      "net present value -35214.048439164464 \n",
      "\n",
      "Episode:102 Reward:-3.6463453105474026 \n",
      "\n",
      "total financial balance: (eur) -69303.63887425556 \n",
      "\n",
      "internal rate of return 1006.9965615669652 \n",
      "\n",
      "net present value -44956.18562832784 \n",
      "\n",
      "Episode:103 Reward:-2.3754688763838563 \n",
      "\n",
      "total financial balance: (eur) -66527.99403355944 \n",
      "\n",
      "internal rate of return 183.97918931597323 \n",
      "\n",
      "net present value -37933.41197579907 \n",
      "\n",
      "Episode:104 Reward:-0.0711697641547662 \n",
      "\n",
      "total financial balance: (eur) -17538.524154079725 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -14673.303904154194 \n",
      "\n",
      "Episode:105 Reward:-2.6607938469544985 \n",
      "\n",
      "total financial balance: (eur) -75650.95791671173 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -46085.32804029144 \n",
      "\n",
      "Episode:106 Reward:0.6180191991051351 \n",
      "\n",
      "total financial balance: (eur) -55518.52089642634 \n",
      "\n",
      "internal rate of return -66.17897534284533 \n",
      "\n",
      "net present value -39376.015566491755 \n",
      "\n",
      "Episode:107 Reward:-3.9378910682845727 \n",
      "\n",
      "total financial balance: (eur) -93614.58107328473 \n",
      "\n",
      "internal rate of return 550.0085637402668 \n",
      "\n",
      "net present value -60310.51017486004 \n",
      "\n",
      "Episode:108 Reward:-1.1761023812740314 \n",
      "\n",
      "total financial balance: (eur) -60290.2340503141 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -40516.50004320223 \n",
      "\n",
      "Episode:109 Reward:-1.2470385805705264 \n",
      "\n",
      "total financial balance: (eur) -32204.201869849236 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -23042.753095909102 \n",
      "\n",
      "Episode:110 Reward:-0.4597728178079651 \n",
      "\n",
      "total financial balance: (eur) -54892.015269292475 \n",
      "\n",
      "internal rate of return 106.67047620717689 \n",
      "\n",
      "net present value -34542.47119472777 \n",
      "\n",
      "Episode:111 Reward:-1.2019244463513379 \n",
      "\n",
      "total financial balance: (eur) -52292.38798405953 \n",
      "\n",
      "internal rate of return 1839.7557253744915 \n",
      "\n",
      "net present value -36490.26548094222 \n",
      "\n",
      "Episode:112 Reward:-2.96318726403697 \n",
      "\n",
      "total financial balance: (eur) -54127.54271007335 \n",
      "\n",
      "internal rate of return 774.0693083819205 \n",
      "\n",
      "net present value -33042.6452256753 \n",
      "\n",
      "Episode:113 Reward:-2.3024797279965377 \n",
      "\n",
      "total financial balance: (eur) -77680.69536417362 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -50267.92432710545 \n",
      "\n",
      "Episode:114 Reward:4.998977842835882 \n",
      "\n",
      "total financial balance: (eur) 14470.056288180765 \n",
      "\n",
      "internal rate of return 6.091531462851019 \n",
      "\n",
      "net present value 2885.2731100346796 \n",
      "\n",
      "Episode:115 Reward:-2.593785446435183 \n",
      "\n",
      "total financial balance: (eur) -62629.21633596955 \n",
      "\n",
      "internal rate of return 1873.357444429528 \n",
      "\n",
      "net present value -38853.947541514965 \n",
      "\n",
      "Episode:116 Reward:7.060641318390548 \n",
      "\n",
      "total financial balance: (eur) 3394.5680229826476 \n",
      "\n",
      "internal rate of return 0.7983858117727616 \n",
      "\n",
      "net present value -7878.04466100923 \n",
      "\n",
      "Episode:117 Reward:-3.533870779226891 \n",
      "\n",
      "total financial balance: (eur) -80873.38242424083 \n",
      "\n",
      "internal rate of return 208.64016051424449 \n",
      "\n",
      "net present value -51477.16292102573 \n",
      "\n",
      "Episode:118 Reward:-1.7801291029805033 \n",
      "\n",
      "total financial balance: (eur) -30074.562274122854 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -19020.560773036665 \n",
      "\n",
      "Episode:119 Reward:-0.3032939034868341 \n",
      "\n",
      "total financial balance: (eur) -66561.82053394426 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -50143.64503848981 \n",
      "\n",
      "Episode:120 Reward:3.74380381660614 \n",
      "\n",
      "total financial balance: (eur) -14973.761373394025 \n",
      "\n",
      "internal rate of return -4.9121802954471105 \n",
      "\n",
      "net present value -16907.29914052273 \n",
      "\n",
      "Episode:121 Reward:-2.3420180187574786 \n",
      "\n",
      "total financial balance: (eur) -45889.4993303729 \n",
      "\n",
      "internal rate of return 365.9370108274844 \n",
      "\n",
      "net present value -30275.75882983912 \n",
      "\n",
      "Episode:122 Reward:-5.661157455856458 \n",
      "\n",
      "total financial balance: (eur) -96707.58627564447 \n",
      "\n",
      "internal rate of return 103.34349887321923 \n",
      "\n",
      "net present value -57216.07658623034 \n",
      "\n",
      "Episode:123 Reward:-1.3480136279073267 \n",
      "\n",
      "total financial balance: (eur) -65512.41472940272 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -46986.9294398352 \n",
      "\n",
      "Episode:124 Reward:-2.5238945633795558 \n",
      "\n",
      "total financial balance: (eur) -60213.04235320797 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -40387.86255080766 \n",
      "\n",
      "Episode:125 Reward:-2.6928751212173374 \n",
      "\n",
      "total financial balance: (eur) -78823.12419015926 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -47963.68584857466 \n",
      "\n",
      "Episode:126 Reward:-4.4296600096054295 \n",
      "\n",
      "total financial balance: (eur) -74182.97964187442 \n",
      "\n",
      "internal rate of return 632.9080553627255 \n",
      "\n",
      "net present value -45883.91221333943 \n",
      "\n",
      "Episode:127 Reward:-3.751298122691958 \n",
      "\n",
      "total financial balance: (eur) -79085.80904023835 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -48293.488129682926 \n",
      "\n",
      "Episode:128 Reward:-2.3918015763031963 \n",
      "\n",
      "total financial balance: (eur) -56665.79366275822 \n",
      "\n",
      "internal rate of return 4107.293219321539 \n",
      "\n",
      "net present value -37966.07788018169 \n",
      "\n",
      "Episode:129 Reward:-1.0297052544367762 \n",
      "\n",
      "total financial balance: (eur) -43367.45082814127 \n",
      "\n",
      "internal rate of return 274.43365070514403 \n",
      "\n",
      "net present value -27400.573917818518 \n",
      "\n",
      "Episode:130 Reward:-3.3986013989118264 \n",
      "\n",
      "total financial balance: (eur) -71367.05174311587 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -44524.48567807754 \n",
      "\n",
      "Episode:131 Reward:-0.01719163043798835 \n",
      "\n",
      "total financial balance: (eur) -39738.73117555956 \n",
      "\n",
      "internal rate of return -15.430495805925215 \n",
      "\n",
      "net present value -31582.230656794138 \n",
      "\n",
      "Episode:132 Reward:1.509042493783917 \n",
      "\n",
      "total financial balance: (eur) -34406.24066179443 \n",
      "\n",
      "internal rate of return -15.43408287632787 \n",
      "\n",
      "net present value -25989.032623745574 \n",
      "\n",
      "Episode:133 Reward:-1.77636014019478 \n",
      "\n",
      "total financial balance: (eur) -62982.871094267786 \n",
      "\n",
      "internal rate of return 233.74570509370108 \n",
      "\n",
      "net present value -41536.35092705606 \n",
      "\n",
      "Episode:134 Reward:-3.6797956926513633 \n",
      "\n",
      "total financial balance: (eur) -91767.49580854623 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -60064.01790549917 \n",
      "\n",
      "Episode:135 Reward:-1.893934245064258 \n",
      "\n",
      "total financial balance: (eur) -43140.45440158588 \n",
      "\n",
      "internal rate of return 135.5683446546049 \n",
      "\n",
      "net present value -26313.92609356731 \n",
      "\n",
      "Episode:136 Reward:-1.723581426294682 \n",
      "\n",
      "total financial balance: (eur) -82548.16982842241 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -52763.20796401835 \n",
      "\n",
      "Episode:137 Reward:-1.1316567239777968 \n",
      "\n",
      "total financial balance: (eur) -54878.674320600156 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -34408.671716025994 \n",
      "\n",
      "Episode:138 Reward:-1.03466701019677 \n",
      "\n",
      "total financial balance: (eur) -32638.00274333151 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -21853.887612340543 \n",
      "\n",
      "Episode:139 Reward:-2.2333941804356936 \n",
      "\n",
      "total financial balance: (eur) -24751.33273717301 \n",
      "\n",
      "internal rate of return 61.83665652746395 \n",
      "\n",
      "net present value -16059.919113873917 \n",
      "\n",
      "Episode:140 Reward:-1.226985753113333 \n",
      "\n",
      "total financial balance: (eur) -54761.675511345595 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -36832.99609890565 \n",
      "\n",
      "Episode:141 Reward:-6.47781838191251 \n",
      "\n",
      "total financial balance: (eur) -96538.96355476248 \n",
      "\n",
      "internal rate of return 165.70042695605406 \n",
      "\n",
      "net present value -56168.70587237663 \n",
      "\n",
      "Episode:142 Reward:-0.16720219680689935 \n",
      "\n",
      "total financial balance: (eur) -50077.308580190496 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -37498.330981432766 \n",
      "\n",
      "Episode:143 Reward:-4.370649516036151 \n",
      "\n",
      "total financial balance: (eur) -86009.19709675113 \n",
      "\n",
      "internal rate of return 93.35134941767184 \n",
      "\n",
      "net present value -50294.732279749405 \n",
      "\n",
      "Episode:144 Reward:-3.9234226801199927 \n",
      "\n",
      "total financial balance: (eur) -89823.13446931078 \n",
      "\n",
      "internal rate of return 1425.8420634727524 \n",
      "\n",
      "net present value -53980.76066854109 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:145 Reward:-2.6320782418596536 \n",
      "\n",
      "total financial balance: (eur) -65792.32803753206 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -42835.268588562394 \n",
      "\n",
      "Episode:146 Reward:-0.9429190966199203 \n",
      "\n",
      "total financial balance: (eur) -66814.45424110837 \n",
      "\n",
      "internal rate of return 428.60039887653835 \n",
      "\n",
      "net present value -48225.41491722569 \n",
      "\n",
      "Episode:147 Reward:0.11203507267907845 \n",
      "\n",
      "total financial balance: (eur) -60841.858836452484 \n",
      "\n",
      "internal rate of return -89.14544125793982 \n",
      "\n",
      "net present value -41174.8278333413 \n",
      "\n",
      "Episode:148 Reward:-1.3170879442557357 \n",
      "\n",
      "total financial balance: (eur) -81736.303555769 \n",
      "\n",
      "internal rate of return 360.33706317002753 \n",
      "\n",
      "net present value -51379.31726085735 \n",
      "\n",
      "Episode:149 Reward:-1.5106091077203436 \n",
      "\n",
      "total financial balance: (eur) -82500.55507781843 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -53414.366130399016 \n",
      "\n",
      "Episode:150 Reward:-2.6817439224040482 \n",
      "\n",
      "total financial balance: (eur) -69390.73511301448 \n",
      "\n",
      "internal rate of return 121.65680135162572 \n",
      "\n",
      "net present value -44028.423450237584 \n",
      "\n",
      "Episode:151 Reward:-2.9999593801297797 \n",
      "\n",
      "total financial balance: (eur) -60864.198593977606 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -40326.18788623686 \n",
      "\n",
      "Episode:152 Reward:-1.6294343056827947 \n",
      "\n",
      "total financial balance: (eur) -63838.949993693794 \n",
      "\n",
      "internal rate of return 150.75689626495995 \n",
      "\n",
      "net present value -40694.7600475328 \n",
      "\n",
      "Episode:153 Reward:-2.0049946284818274 \n",
      "\n",
      "total financial balance: (eur) -99298.9411560762 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -62196.33368465525 \n",
      "\n",
      "Episode:154 Reward:-3.0886102742528463 \n",
      "\n",
      "total financial balance: (eur) -63230.72860211339 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -37722.960177207744 \n",
      "\n",
      "Episode:155 Reward:0.45621069375071055 \n",
      "\n",
      "total financial balance: (eur) -20124.739996215074 \n",
      "\n",
      "internal rate of return -78.07781120434427 \n",
      "\n",
      "net present value -14181.868302295243 \n",
      "\n",
      "Episode:156 Reward:-2.836022182929787 \n",
      "\n",
      "total financial balance: (eur) -97269.7475389788 \n",
      "\n",
      "internal rate of return 217.55411595725928 \n",
      "\n",
      "net present value -62815.59500434473 \n",
      "\n",
      "Episode:157 Reward:0.9332836040469774 \n",
      "\n",
      "total financial balance: (eur) -51397.977338473785 \n",
      "\n",
      "internal rate of return -34.304063785564956 \n",
      "\n",
      "net present value -36895.15279456851 \n",
      "\n",
      "Episode:158 Reward:-0.16428074928343267 \n",
      "\n",
      "total financial balance: (eur) -53841.53437942937 \n",
      "\n",
      "internal rate of return 15689.214454293957 \n",
      "\n",
      "net present value -38241.06986600579 \n",
      "\n",
      "Episode:159 Reward:-2.8294868604357544 \n",
      "\n",
      "total financial balance: (eur) -54074.63652494173 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -35617.77220894335 \n",
      "\n",
      "Episode:160 Reward:-1.1444677523130466 \n",
      "\n",
      "total financial balance: (eur) -40732.81402963996 \n",
      "\n",
      "internal rate of return 388.14465538017646 \n",
      "\n",
      "net present value -27471.79827094277 \n",
      "\n",
      "Episode:161 Reward:-1.3920368965261205 \n",
      "\n",
      "total financial balance: (eur) -80552.54222187633 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -52303.85299717047 \n",
      "\n",
      "Episode:162 Reward:0.5054817821191 \n",
      "\n",
      "total financial balance: (eur) -36602.28952913444 \n",
      "\n",
      "internal rate of return -44.06673377693464 \n",
      "\n",
      "net present value -26304.377861302757 \n",
      "\n",
      "Episode:163 Reward:2.603571459038734 \n",
      "\n",
      "total financial balance: (eur) -12501.284904122089 \n",
      "\n",
      "internal rate of return -4.133583164424581 \n",
      "\n",
      "net present value -14338.05936062358 \n",
      "\n",
      "Episode:164 Reward:-1.8262240318119771 \n",
      "\n",
      "total financial balance: (eur) -85077.41457864684 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -54722.40531987758 \n",
      "\n",
      "Episode:165 Reward:1.991918511698662 \n",
      "\n",
      "total financial balance: (eur) 13418.583204254417 \n",
      "\n",
      "internal rate of return 14.129004157081004 \n",
      "\n",
      "net present value 5221.512065482106 \n",
      "\n",
      "Episode:166 Reward:-1.190631943984573 \n",
      "\n",
      "total financial balance: (eur) -42005.41790654401 \n",
      "\n",
      "internal rate of return 138.02747718633773 \n",
      "\n",
      "net present value -27823.11778875831 \n",
      "\n",
      "Episode:167 Reward:-5.802236353024399 \n",
      "\n",
      "total financial balance: (eur) -99402.63148378575 \n",
      "\n",
      "internal rate of return 214.72050726484744 \n",
      "\n",
      "net present value -57196.9826123927 \n",
      "\n",
      "Episode:168 Reward:-1.7423726607080199 \n",
      "\n",
      "total financial balance: (eur) -53995.93863387377 \n",
      "\n",
      "internal rate of return 201.43428277846618 \n",
      "\n",
      "net present value -35751.4583902071 \n",
      "\n",
      "Episode:169 Reward:-2.744610937182014 \n",
      "\n",
      "total financial balance: (eur) -88544.68960572654 \n",
      "\n",
      "internal rate of return 865.2145089384927 \n",
      "\n",
      "net present value -56009.253633764165 \n",
      "\n",
      "Episode:170 Reward:-0.7764365063029509 \n",
      "\n",
      "total financial balance: (eur) -55311.74949978755 \n",
      "\n",
      "internal rate of return 392.72521024904046 \n",
      "\n",
      "net present value -38768.09298360588 \n",
      "\n",
      "Episode:171 Reward:-2.4195999980068317 \n",
      "\n",
      "total financial balance: (eur) -75539.64150666396 \n",
      "\n",
      "internal rate of return 156.87979200858447 \n",
      "\n",
      "net present value -47923.097775548085 \n",
      "\n",
      "Episode:172 Reward:1.2972826090989193 \n",
      "\n",
      "total financial balance: (eur) -31832.63025169309 \n",
      "\n",
      "internal rate of return -21.09848195773121 \n",
      "\n",
      "net present value -21459.145957294102 \n",
      "\n",
      "Episode:173 Reward:-2.1347531192285003 \n",
      "\n",
      "total financial balance: (eur) -71758.94616723098 \n",
      "\n",
      "internal rate of return 8895.142213241274 \n",
      "\n",
      "net present value -45172.58004680399 \n",
      "\n",
      "Episode:174 Reward:-4.762986280850929 \n",
      "\n",
      "total financial balance: (eur) -96466.65742689 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -60728.6930533116 \n",
      "\n",
      "Episode:175 Reward:-0.9720399861273991 \n",
      "\n",
      "total financial balance: (eur) -45357.33239947039 \n",
      "\n",
      "internal rate of return 285.97958942325613 \n",
      "\n",
      "net present value -33329.0459669994 \n",
      "\n",
      "Episode:176 Reward:0.899248606942615 \n",
      "\n",
      "total financial balance: (eur) -51799.04888910462 \n",
      "\n",
      "internal rate of return -20.09869383373394 \n",
      "\n",
      "net present value -37746.584155034034 \n",
      "\n",
      "Episode:177 Reward:-1.6898065642981455 \n",
      "\n",
      "total financial balance: (eur) -56462.23930235671 \n",
      "\n",
      "internal rate of return 230.1966889241549 \n",
      "\n",
      "net present value -36486.44823257781 \n",
      "\n",
      "Episode:178 Reward:0.19868113967647877 \n",
      "\n",
      "total financial balance: (eur) -33826.68312987118 \n",
      "\n",
      "internal rate of return -16.793987590661473 \n",
      "\n",
      "net present value -25633.571545833925 \n",
      "\n",
      "Episode:179 Reward:-1.5615295044876403 \n",
      "\n",
      "total financial balance: (eur) -47275.601433969714 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -31260.34055491113 \n",
      "\n",
      "Episode:180 Reward:-3.5281169175928353 \n",
      "\n",
      "total financial balance: (eur) -58326.54373427636 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -36166.47245947441 \n",
      "\n",
      "Episode:181 Reward:-4.67733694742273 \n",
      "\n",
      "total financial balance: (eur) -83713.25757290643 \n",
      "\n",
      "internal rate of return 794.604132194426 \n",
      "\n",
      "net present value -51705.44470542418 \n",
      "\n",
      "Episode:182 Reward:-2.033140638782651 \n",
      "\n",
      "total financial balance: (eur) -65149.62415809399 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -44052.84346193957 \n",
      "\n",
      "Episode:183 Reward:-1.2298391280994347 \n",
      "\n",
      "total financial balance: (eur) -72988.31691313679 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -48272.726821094635 \n",
      "\n",
      "Episode:184 Reward:-1.623870713633777 \n",
      "\n",
      "total financial balance: (eur) -49088.795712013045 \n",
      "\n",
      "internal rate of return 194.2919705614646 \n",
      "\n",
      "net present value -30248.737809812807 \n",
      "\n",
      "Episode:185 Reward:-1.3541693045703032 \n",
      "\n",
      "total financial balance: (eur) -65078.990352552486 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -40883.14949319159 \n",
      "\n",
      "Episode:186 Reward:-0.12094622321933002 \n",
      "\n",
      "total financial balance: (eur) -37295.23757529256 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -26950.062797815735 \n",
      "\n",
      "Episode:187 Reward:0.332186276206683 \n",
      "\n",
      "total financial balance: (eur) -59397.487279106645 \n",
      "\n",
      "internal rate of return -79.05259380394776 \n",
      "\n",
      "net present value -38032.08257586627 \n",
      "\n",
      "Episode:188 Reward:0.3634887856108517 \n",
      "\n",
      "total financial balance: (eur) -28794.299505861232 \n",
      "\n",
      "internal rate of return -18.66590443402917 \n",
      "\n",
      "net present value -22164.079079212042 \n",
      "\n",
      "Episode:189 Reward:-2.704417366287903 \n",
      "\n",
      "total financial balance: (eur) -69749.81471048415 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -43635.24997932629 \n",
      "\n",
      "Episode:190 Reward:-1.0507434603867796 \n",
      "\n",
      "total financial balance: (eur) -45808.068863625835 \n",
      "\n",
      "internal rate of return 116.1411134532648 \n",
      "\n",
      "net present value -30208.27393794986 \n",
      "\n",
      "Episode:191 Reward:-5.421590038728643 \n",
      "\n",
      "total financial balance: (eur) -66675.30386175848 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -40574.40683045985 \n",
      "\n",
      "Episode:192 Reward:5.231501700918821 \n",
      "\n",
      "total financial balance: (eur) 1770.883942272084 \n",
      "\n",
      "internal rate of return 0.5823414869396748 \n",
      "\n",
      "net present value -6149.669070822359 \n",
      "\n",
      "Episode:193 Reward:0.11947597919864893 \n",
      "\n",
      "total financial balance: (eur) -40075.66614237858 \n",
      "\n",
      "internal rate of return -61.26135291922571 \n",
      "\n",
      "net present value -29776.309796521964 \n",
      "\n",
      "Episode:194 Reward:-1.6385905669872718 \n",
      "\n",
      "total financial balance: (eur) -60872.495985527166 \n",
      "\n",
      "internal rate of return 189.869431503254 \n",
      "\n",
      "net present value -37686.30691807449 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:195 Reward:0.5543484385673273 \n",
      "\n",
      "total financial balance: (eur) -54880.649611911824 \n",
      "\n",
      "internal rate of return -69.12592328427276 \n",
      "\n",
      "net present value -36717.84134242754 \n",
      "\n",
      "Episode:196 Reward:0.38839578687604265 \n",
      "\n",
      "total financial balance: (eur) -42049.96279747793 \n",
      "\n",
      "internal rate of return -54.31576849401951 \n",
      "\n",
      "net present value -27428.96211991033 \n",
      "\n",
      "Episode:197 Reward:6.240758852885374 \n",
      "\n",
      "total financial balance: (eur) -19391.52977952073 \n",
      "\n",
      "internal rate of return -5.507147202371854 \n",
      "\n",
      "net present value -20452.420635063852 \n",
      "\n",
      "Episode:198 Reward:-2.1968293000132864 \n",
      "\n",
      "total financial balance: (eur) -82852.10288279038 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -53670.8633559963 \n",
      "\n",
      "Episode:199 Reward:-1.7168909753511088 \n",
      "\n",
      "total financial balance: (eur) -47808.9741892406 \n",
      "\n",
      "internal rate of return 668.0576105254255 \n",
      "\n",
      "net present value -30430.17449875647 \n",
      "\n",
      "Episode:200 Reward:0.5008128041539412 \n",
      "\n",
      "total financial balance: (eur) -22373.30151619155 \n",
      "\n",
      "internal rate of return -9.27961069279226 \n",
      "\n",
      "net present value -20647.29416964733 \n",
      "\n",
      "Episode:201 Reward:-3.0311616747481813 \n",
      "\n",
      "total financial balance: (eur) -75817.28136093289 \n",
      "\n",
      "internal rate of return 2476.1359542577025 \n",
      "\n",
      "net present value -46806.61584709142 \n",
      "\n",
      "Episode:202 Reward:-1.0089909434334277 \n",
      "\n",
      "total financial balance: (eur) -71231.1352339122 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -46521.16609952573 \n",
      "\n",
      "Episode:203 Reward:-2.1491356342833234 \n",
      "\n",
      "total financial balance: (eur) -45493.08315249487 \n",
      "\n",
      "internal rate of return 350.6252416196583 \n",
      "\n",
      "net present value -31422.550566606256 \n",
      "\n",
      "Episode:204 Reward:-2.4098801591295667 \n",
      "\n",
      "total financial balance: (eur) -78173.39681294288 \n",
      "\n",
      "internal rate of return 376.2526574304454 \n",
      "\n",
      "net present value -52352.53755760158 \n",
      "\n",
      "Episode:205 Reward:-4.558733950412963 \n",
      "\n",
      "total financial balance: (eur) -99895.84805245418 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -63226.106917313555 \n",
      "\n",
      "Episode:206 Reward:-4.170473863967854 \n",
      "\n",
      "total financial balance: (eur) -67929.06250109646 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -39078.99345735409 \n",
      "\n",
      "Episode:207 Reward:-1.8250160545865939 \n",
      "\n",
      "total financial balance: (eur) -57184.768371972874 \n",
      "\n",
      "internal rate of return 392.822168255798 \n",
      "\n",
      "net present value -38542.95269331911 \n",
      "\n",
      "Episode:208 Reward:-2.0453088896013396 \n",
      "\n",
      "total financial balance: (eur) -89366.12058806328 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -59740.11458922332 \n",
      "\n",
      "Episode:209 Reward:-0.3898592954612195 \n",
      "\n",
      "total financial balance: (eur) -71521.17114152442 \n",
      "\n",
      "internal rate of return 419.10727589026175 \n",
      "\n",
      "net present value -45770.22107523704 \n",
      "\n",
      "Episode:210 Reward:-4.1946923998658585 \n",
      "\n",
      "total financial balance: (eur) -79949.14967923678 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -50516.14783488678 \n",
      "\n",
      "Episode:211 Reward:1.003936666030484 \n",
      "\n",
      "total financial balance: (eur) -40059.447032004115 \n",
      "\n",
      "internal rate of return -23.061447328680195 \n",
      "\n",
      "net present value -29336.89713838517 \n",
      "\n",
      "Episode:212 Reward:-0.7022743414325441 \n",
      "\n",
      "total financial balance: (eur) -54875.68352443697 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -39346.95524583511 \n",
      "\n",
      "Episode:213 Reward:-1.3163087569098388 \n",
      "\n",
      "total financial balance: (eur) -49219.90939052071 \n",
      "\n",
      "internal rate of return 1097.3633098914913 \n",
      "\n",
      "net present value -32164.17785706715 \n",
      "\n",
      "Episode:214 Reward:-2.2208440885898635 \n",
      "\n",
      "total financial balance: (eur) -84861.71887267394 \n",
      "\n",
      "internal rate of return 157.27913667116482 \n",
      "\n",
      "net present value -52159.912913783985 \n",
      "\n",
      "Episode:215 Reward:1.8405956309955964 \n",
      "\n",
      "total financial balance: (eur) -35770.75894132696 \n",
      "\n",
      "internal rate of return -11.32244153934574 \n",
      "\n",
      "net present value -29853.964623090626 \n",
      "\n",
      "Episode:216 Reward:0.6259194848674597 \n",
      "\n",
      "total financial balance: (eur) -56432.20647054287 \n",
      "\n",
      "internal rate of return -34.9408207233808 \n",
      "\n",
      "net present value -38820.93797823855 \n",
      "\n",
      "Episode:217 Reward:-1.9239251361682836 \n",
      "\n",
      "total financial balance: (eur) -70275.16566481986 \n",
      "\n",
      "internal rate of return 1416.2462542369985 \n",
      "\n",
      "net present value -48722.07158493476 \n",
      "\n",
      "Episode:218 Reward:-0.796710893133124 \n",
      "\n",
      "total financial balance: (eur) -64547.49282650907 \n",
      "\n",
      "internal rate of return 298.7038032509396 \n",
      "\n",
      "net present value -42611.98127512298 \n",
      "\n",
      "Episode:219 Reward:-4.054168103095626 \n",
      "\n",
      "total financial balance: (eur) -56333.68612283769 \n",
      "\n",
      "internal rate of return 188.94202731671842 \n",
      "\n",
      "net present value -34712.87213216179 \n",
      "\n",
      "Episode:220 Reward:-0.14789010788397444 \n",
      "\n",
      "total financial balance: (eur) -60460.394368206595 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -39940.723445177304 \n",
      "\n",
      "Episode:221 Reward:-0.3659292616158632 \n",
      "\n",
      "total financial balance: (eur) -59495.337595152916 \n",
      "\n",
      "internal rate of return 886.0558349469212 \n",
      "\n",
      "net present value -39378.598527239476 \n",
      "\n",
      "Episode:222 Reward:-2.387831252013917 \n",
      "\n",
      "total financial balance: (eur) -34206.01477940163 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -24917.139355441763 \n",
      "\n",
      "Episode:223 Reward:-0.7073012656476967 \n",
      "\n",
      "total financial balance: (eur) -40715.80385309516 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -27572.26761291852 \n",
      "\n",
      "Episode:224 Reward:0.09538246237867497 \n",
      "\n",
      "total financial balance: (eur) -37692.69906378437 \n",
      "\n",
      "internal rate of return -77.73595532616878 \n",
      "\n",
      "net present value -26086.28265114869 \n",
      "\n",
      "Episode:225 Reward:-3.516196110556949 \n",
      "\n",
      "total financial balance: (eur) -79564.9930325039 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -53083.350914503164 \n",
      "\n",
      "Episode:226 Reward:-2.632057751579073 \n",
      "\n",
      "total financial balance: (eur) -50356.09582678225 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -31537.682135382896 \n",
      "\n",
      "Episode:227 Reward:-3.724220306471273 \n",
      "\n",
      "total financial balance: (eur) -82165.250384632 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -50924.27255610662 \n",
      "\n",
      "Episode:228 Reward:-3.187782737095893 \n",
      "\n",
      "total financial balance: (eur) -70713.4921892386 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -46290.09007111971 \n",
      "\n",
      "Episode:229 Reward:1.1837887446348787 \n",
      "\n",
      "total financial balance: (eur) -34260.90444726582 \n",
      "\n",
      "internal rate of return -19.683511149912803 \n",
      "\n",
      "net present value -26580.458220979646 \n",
      "\n",
      "Episode:230 Reward:2.934335401843239 \n",
      "\n",
      "total financial balance: (eur) -44464.81807110784 \n",
      "\n",
      "internal rate of return -17.86305636870097 \n",
      "\n",
      "net present value -33270.27249084264 \n",
      "\n",
      "Episode:231 Reward:-3.2811667155379745 \n",
      "\n",
      "total financial balance: (eur) -87586.51100324922 \n",
      "\n",
      "internal rate of return 144.9352200412792 \n",
      "\n",
      "net present value -53904.259890775735 \n",
      "\n",
      "Episode:232 Reward:1.235400278318194 \n",
      "\n",
      "total financial balance: (eur) -48545.629116716824 \n",
      "\n",
      "internal rate of return -41.68774745418891 \n",
      "\n",
      "net present value -32302.957053634833 \n",
      "\n",
      "Episode:233 Reward:-2.4849262360514204 \n",
      "\n",
      "total financial balance: (eur) -62327.60518713475 \n",
      "\n",
      "internal rate of return 484.4356838352834 \n",
      "\n",
      "net present value -42947.99701248899 \n",
      "\n",
      "Episode:234 Reward:-1.7887781941797647 \n",
      "\n",
      "total financial balance: (eur) -73350.92575299552 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -48453.155291525145 \n",
      "\n",
      "Episode:235 Reward:-1.017387693209518 \n",
      "\n",
      "total financial balance: (eur) -48379.41223497642 \n",
      "\n",
      "internal rate of return 443.09279104891505 \n",
      "\n",
      "net present value -31467.166246168985 \n",
      "\n",
      "Episode:236 Reward:-0.7616218967142849 \n",
      "\n",
      "total financial balance: (eur) -42341.549067615415 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -29997.092612237644 \n",
      "\n",
      "Episode:237 Reward:0.32803964781461037 \n",
      "\n",
      "total financial balance: (eur) -15098.278865155577 \n",
      "\n",
      "internal rate of return -7.924712718324489 \n",
      "\n",
      "net present value -14198.819444267263 \n",
      "\n",
      "Episode:238 Reward:-2.8207012834233964 \n",
      "\n",
      "total financial balance: (eur) -85091.09601661013 \n",
      "\n",
      "internal rate of return 174.45687587146662 \n",
      "\n",
      "net present value -52819.52930288721 \n",
      "\n",
      "Episode:239 Reward:-1.90148202561374 \n",
      "\n",
      "total financial balance: (eur) -57058.91104754443 \n",
      "\n",
      "internal rate of return 126.75609473623139 \n",
      "\n",
      "net present value -38951.3292299163 \n",
      "\n",
      "Episode:240 Reward:1.5899657612147822 \n",
      "\n",
      "total financial balance: (eur) -32858.93443976306 \n",
      "\n",
      "internal rate of return -33.23627301021689 \n",
      "\n",
      "net present value -21681.968684210402 \n",
      "\n",
      "Episode:241 Reward:0.3675542526627405 \n",
      "\n",
      "total financial balance: (eur) -22307.13031665194 \n",
      "\n",
      "internal rate of return -77.09293860538322 \n",
      "\n",
      "net present value -15657.446440044845 \n",
      "\n",
      "Episode:242 Reward:3.1875964988327525 \n",
      "\n",
      "total financial balance: (eur) -29200.75002051925 \n",
      "\n",
      "internal rate of return -7.095950525871764 \n",
      "\n",
      "net present value -27541.311241319694 \n",
      "\n",
      "Episode:243 Reward:-0.689131767718437 \n",
      "\n",
      "total financial balance: (eur) -70953.97465589958 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -46599.72275061397 \n",
      "\n",
      "Episode:244 Reward:-0.40774958197115846 \n",
      "\n",
      "total financial balance: (eur) -50351.20200082124 \n",
      "\n",
      "internal rate of return 267.04791117813335 \n",
      "\n",
      "net present value -33869.785522877064 \n",
      "\n",
      "Episode:245 Reward:-2.5295853103450834 \n",
      "\n",
      "total financial balance: (eur) -61751.54726556769 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -40133.209039926216 \n",
      "\n",
      "Episode:246 Reward:-4.058929775823631 \n",
      "\n",
      "total financial balance: (eur) -92831.67474857917 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -58736.888701487325 \n",
      "\n",
      "Episode:247 Reward:-2.8497452188129135 \n",
      "\n",
      "total financial balance: (eur) -66123.84236941084 \n",
      "\n",
      "internal rate of return 131.78995788979938 \n",
      "\n",
      "net present value -41946.82192206094 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:248 Reward:-3.2360106235549733 \n",
      "\n",
      "total financial balance: (eur) -57310.531462951614 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -35270.0116304472 \n",
      "\n",
      "Episode:249 Reward:0.055868208243675326 \n",
      "\n",
      "total financial balance: (eur) -60614.03757553508 \n",
      "\n",
      "internal rate of return -97.0550445437715 \n",
      "\n",
      "net present value -40810.491653806115 \n",
      "\n",
      "Episode:250 Reward:-3.9722116729926364 \n",
      "\n",
      "total financial balance: (eur) -82056.93619180347 \n",
      "\n",
      "internal rate of return 262.97498416713074 \n",
      "\n",
      "net present value -51751.85465211629 \n",
      "\n",
      "Episode:251 Reward:-2.302370914275406 \n",
      "\n",
      "total financial balance: (eur) -47056.88133757626 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -34497.857239207384 \n",
      "\n",
      "Episode:252 Reward:-1.6201143724262366 \n",
      "\n",
      "total financial balance: (eur) -38471.957592530925 \n",
      "\n",
      "internal rate of return 81.86539063841127 \n",
      "\n",
      "net present value -22612.129181448145 \n",
      "\n",
      "Episode:253 Reward:-3.1745486592829457 \n",
      "\n",
      "total financial balance: (eur) -76765.09481939062 \n",
      "\n",
      "internal rate of return 484.844582442914 \n",
      "\n",
      "net present value -46145.88692013546 \n",
      "\n",
      "Episode:254 Reward:-1.8360267526614016 \n",
      "\n",
      "total financial balance: (eur) -61870.02033429596 \n",
      "\n",
      "internal rate of return 180.30997879105848 \n",
      "\n",
      "net present value -42321.70915995717 \n",
      "\n",
      "Episode:255 Reward:0.1169573694558676 \n",
      "\n",
      "total financial balance: (eur) -60374.23058547183 \n",
      "\n",
      "internal rate of return 73.51555679690958 \n",
      "\n",
      "net present value -36342.052430670024 \n",
      "\n",
      "Episode:256 Reward:-1.6271674307155282 \n",
      "\n",
      "total financial balance: (eur) -86717.0168188486 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -56710.93963204501 \n",
      "\n",
      "Episode:257 Reward:-2.167701558961048 \n",
      "\n",
      "total financial balance: (eur) -55285.385941390225 \n",
      "\n",
      "internal rate of return 380.0059609974964 \n",
      "\n",
      "net present value -35696.16940235774 \n",
      "\n",
      "Episode:258 Reward:-2.8755765529127686 \n",
      "\n",
      "total financial balance: (eur) -89254.7397300436 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -57541.93594817212 \n",
      "\n",
      "Episode:259 Reward:-0.7749916698600373 \n",
      "\n",
      "total financial balance: (eur) -43469.47021294458 \n",
      "\n",
      "internal rate of return 175.53699025472716 \n",
      "\n",
      "net present value -29295.773308774103 \n",
      "\n",
      "Episode:260 Reward:-2.2177500058912725 \n",
      "\n",
      "total financial balance: (eur) -64180.70394691937 \n",
      "\n",
      "internal rate of return 281.948716994708 \n",
      "\n",
      "net present value -40794.24011729032 \n",
      "\n",
      "Episode:261 Reward:-3.0600723214714955 \n",
      "\n",
      "total financial balance: (eur) -77438.42459744499 \n",
      "\n",
      "internal rate of return 453.5754775283228 \n",
      "\n",
      "net present value -48079.92261143612 \n",
      "\n",
      "Episode:262 Reward:1.5875910910512157 \n",
      "\n",
      "total financial balance: (eur) -52490.34009938454 \n",
      "\n",
      "internal rate of return -37.47203552697729 \n",
      "\n",
      "net present value -36573.455875818916 \n",
      "\n",
      "Episode:263 Reward:-1.57661165452338 \n",
      "\n",
      "total financial balance: (eur) -46415.6549707286 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -29752.104007835507 \n",
      "\n",
      "Episode:264 Reward:-2.022486868963143 \n",
      "\n",
      "total financial balance: (eur) -59129.203287997545 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -40494.31082209702 \n",
      "\n",
      "Episode:265 Reward:-5.8456683809603405 \n",
      "\n",
      "total financial balance: (eur) -88541.3135298957 \n",
      "\n",
      "internal rate of return 945.2176340786735 \n",
      "\n",
      "net present value -52739.6978117232 \n",
      "\n",
      "Episode:266 Reward:-5.2216511144870505 \n",
      "\n",
      "total financial balance: (eur) -79283.57509194814 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -47964.05084758718 \n",
      "\n",
      "Episode:267 Reward:-1.4815169400251125 \n",
      "\n",
      "total financial balance: (eur) -89672.95298268116 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -58145.01980723255 \n",
      "\n",
      "Episode:268 Reward:-1.263972281164346 \n",
      "\n",
      "total financial balance: (eur) -73543.3047778653 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -48187.61739651075 \n",
      "\n",
      "Episode:269 Reward:-0.7106430365774858 \n",
      "\n",
      "total financial balance: (eur) -53292.30079079729 \n",
      "\n",
      "internal rate of return 246.90155523498413 \n",
      "\n",
      "net present value -37093.13545858371 \n",
      "\n",
      "Episode:270 Reward:-3.5594754998624523 \n",
      "\n",
      "total financial balance: (eur) -77446.57209429749 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -51139.75564753948 \n",
      "\n",
      "Episode:271 Reward:-2.315406346781855 \n",
      "\n",
      "total financial balance: (eur) -65793.39731158763 \n",
      "\n",
      "internal rate of return 128.0204489926136 \n",
      "\n",
      "net present value -39783.1653696283 \n",
      "\n",
      "Episode:272 Reward:-3.176386878266385 \n",
      "\n",
      "total financial balance: (eur) -74130.78814489226 \n",
      "\n",
      "internal rate of return 518.1597356842544 \n",
      "\n",
      "net present value -49133.98736052214 \n",
      "\n",
      "Episode:273 Reward:-3.905040911053242 \n",
      "\n",
      "total financial balance: (eur) -78361.01186631393 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -49663.17447402696 \n",
      "\n",
      "Episode:274 Reward:-2.324649497584197 \n",
      "\n",
      "total financial balance: (eur) -66756.40594152028 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -44401.3569025138 \n",
      "\n",
      "Episode:275 Reward:2.1022045976097505 \n",
      "\n",
      "total financial balance: (eur) -34438.855648885714 \n",
      "\n",
      "internal rate of return -13.028406081174515 \n",
      "\n",
      "net present value -27833.217455058326 \n",
      "\n",
      "Episode:276 Reward:-1.6786033050984162 \n",
      "\n",
      "total financial balance: (eur) -55886.467724187976 \n",
      "\n",
      "internal rate of return 131.56014912625534 \n",
      "\n",
      "net present value -33407.01349019171 \n",
      "\n",
      "Episode:277 Reward:-2.3660453106712778 \n",
      "\n",
      "total financial balance: (eur) -68423.10754007976 \n",
      "\n",
      "internal rate of return 156.0667166141517 \n",
      "\n",
      "net present value -44485.05253535104 \n",
      "\n",
      "Episode:278 Reward:-1.757142724109077 \n",
      "\n",
      "total financial balance: (eur) -65378.720640504616 \n",
      "\n",
      "internal rate of return 1816.0213789232969 \n",
      "\n",
      "net present value -45602.10916626988 \n",
      "\n",
      "Episode:279 Reward:-3.3506802170573873 \n",
      "\n",
      "total financial balance: (eur) -92005.54438497454 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -59557.362952595875 \n",
      "\n",
      "Episode:280 Reward:-0.325675634093499 \n",
      "\n",
      "total financial balance: (eur) -28527.20991476382 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -21438.748417542825 \n",
      "\n",
      "Episode:281 Reward:-3.2174955136861954 \n",
      "\n",
      "total financial balance: (eur) -64516.02555149467 \n",
      "\n",
      "internal rate of return 2102.645677290565 \n",
      "\n",
      "net present value -40843.825556499505 \n",
      "\n",
      "Episode:282 Reward:-0.3248448298300109 \n",
      "\n",
      "total financial balance: (eur) -60433.22196432256 \n",
      "\n",
      "internal rate of return 922.6503674801108 \n",
      "\n",
      "net present value -44138.65701914448 \n",
      "\n",
      "Episode:283 Reward:-2.601166274797218 \n",
      "\n",
      "total financial balance: (eur) -101563.20068686508 \n",
      "\n",
      "internal rate of return 497.33850820358833 \n",
      "\n",
      "net present value -67643.65024560086 \n",
      "\n",
      "Episode:284 Reward:-0.9690814858672002 \n",
      "\n",
      "total financial balance: (eur) -50349.8097386361 \n",
      "\n",
      "internal rate of return 198.77757204570966 \n",
      "\n",
      "net present value -34041.4933203566 \n",
      "\n",
      "Episode:285 Reward:-0.9792723349785692 \n",
      "\n",
      "total financial balance: (eur) -29136.347058827097 \n",
      "\n",
      "internal rate of return 331.75435866072445 \n",
      "\n",
      "net present value -20344.18018737394 \n",
      "\n",
      "Episode:286 Reward:2.8694804150906195 \n",
      "\n",
      "total financial balance: (eur) -30759.008558681526 \n",
      "\n",
      "internal rate of return -11.164042817137332 \n",
      "\n",
      "net present value -25971.11268007711 \n",
      "\n",
      "Episode:287 Reward:-2.0960968053213773 \n",
      "\n",
      "total financial balance: (eur) -83841.98427918927 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -54455.44339757759 \n",
      "\n",
      "Episode:288 Reward:-2.0658385476249888 \n",
      "\n",
      "total financial balance: (eur) -67216.35599400812 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -46135.5305060222 \n",
      "\n",
      "Episode:289 Reward:0.13701417376692188 \n",
      "\n",
      "total financial balance: (eur) -50582.256971949464 \n",
      "\n",
      "internal rate of return -92.1804856954469 \n",
      "\n",
      "net present value -33247.93016813103 \n",
      "\n",
      "Episode:290 Reward:-2.7052902861189896 \n",
      "\n",
      "total financial balance: (eur) -62795.53270990805 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -40187.669129924216 \n",
      "\n",
      "Episode:291 Reward:-2.2648019898693037 \n",
      "\n",
      "total financial balance: (eur) -56576.7556041778 \n",
      "\n",
      "internal rate of return 268.31500992200057 \n",
      "\n",
      "net present value -35855.931986443975 \n",
      "\n",
      "Episode:292 Reward:-1.0397913814487947 \n",
      "\n",
      "total financial balance: (eur) -66777.59282761373 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -44916.64765848558 \n",
      "\n",
      "Episode:293 Reward:0.1565438078139582 \n",
      "\n",
      "total financial balance: (eur) -61948.53694032848 \n",
      "\n",
      "internal rate of return -94.73706428029449 \n",
      "\n",
      "net present value -42255.139979574626 \n",
      "\n",
      "Episode:294 Reward:0.3851333946232744 \n",
      "\n",
      "total financial balance: (eur) -26068.743432542436 \n",
      "\n",
      "internal rate of return -18.00605918791338 \n",
      "\n",
      "net present value -20727.759661316686 \n",
      "\n",
      "Episode:295 Reward:-3.0841704551596645 \n",
      "\n",
      "total financial balance: (eur) -80044.44810703532 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -49710.651436359876 \n",
      "\n",
      "Episode:296 Reward:-3.177592335027399 \n",
      "\n",
      "total financial balance: (eur) -69113.99975679997 \n",
      "\n",
      "internal rate of return 162.7939680422107 \n",
      "\n",
      "net present value -41741.79553397131 \n",
      "\n",
      "Episode:297 Reward:-2.5029647825717474 \n",
      "\n",
      "total financial balance: (eur) -70969.31937529752 \n",
      "\n",
      "internal rate of return 303.1921360821236 \n",
      "\n",
      "net present value -45560.778059915865 \n",
      "\n",
      "Episode:298 Reward:-4.641215328494787 \n",
      "\n",
      "total financial balance: (eur) -78755.59823319402 \n",
      "\n",
      "internal rate of return 155.79134953746473 \n",
      "\n",
      "net present value -46380.43330870613 \n",
      "\n",
      "Episode:299 Reward:-3.317212291554276 \n",
      "\n",
      "total financial balance: (eur) -73812.01950531048 \n",
      "\n",
      "internal rate of return 2308.9508302602026 \n",
      "\n",
      "net present value -49362.271830293685 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:300 Reward:-0.27033213895475 \n",
      "\n",
      "total financial balance: (eur) -61848.45617536259 \n",
      "\n",
      "internal rate of return 203.12840221177808 \n",
      "\n",
      "net present value -41552.650780105905 \n",
      "\n",
      "Episode:301 Reward:-2.858798436533387 \n",
      "\n",
      "total financial balance: (eur) -67153.3285940539 \n",
      "\n",
      "internal rate of return 562.8294371347531 \n",
      "\n",
      "net present value -45191.86409057737 \n",
      "\n",
      "Episode:302 Reward:-1.9977653494036605 \n",
      "\n",
      "total financial balance: (eur) -39701.10445700903 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -28394.16982132201 \n",
      "\n",
      "Episode:303 Reward:-1.9825608995880675 \n",
      "\n",
      "total financial balance: (eur) -58522.015116293995 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -39102.104171889594 \n",
      "\n",
      "Episode:304 Reward:-1.8511502003616278 \n",
      "\n",
      "total financial balance: (eur) -69173.79717210116 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -43651.56580022588 \n",
      "\n",
      "Episode:305 Reward:-0.9780888985127394 \n",
      "\n",
      "total financial balance: (eur) -44552.7810092801 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -30698.451466988878 \n",
      "\n",
      "Episode:306 Reward:3.705013136270338 \n",
      "\n",
      "total financial balance: (eur) -22964.86489242765 \n",
      "\n",
      "internal rate of return -9.904392359200187 \n",
      "\n",
      "net present value -18223.690400328167 \n",
      "\n",
      "Episode:307 Reward:2.3658557240452573 \n",
      "\n",
      "total financial balance: (eur) -16323.397487944261 \n",
      "\n",
      "internal rate of return -8.171190609951006 \n",
      "\n",
      "net present value -13832.604000683868 \n",
      "\n",
      "Episode:308 Reward:-3.4329578103758984 \n",
      "\n",
      "total financial balance: (eur) -66854.13496731155 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -39719.74006792287 \n",
      "\n",
      "Episode:309 Reward:-3.3712358831071714 \n",
      "\n",
      "total financial balance: (eur) -77606.56702704066 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -49260.89072257692 \n",
      "\n",
      "Episode:310 Reward:-4.119786804677311 \n",
      "\n",
      "total financial balance: (eur) -93767.8926103502 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -59759.834735809876 \n",
      "\n",
      "Episode:311 Reward:-3.5131862124207625 \n",
      "\n",
      "total financial balance: (eur) -71842.06381749325 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -44354.623723134275 \n",
      "\n",
      "Episode:312 Reward:-1.990565495745288 \n",
      "\n",
      "total financial balance: (eur) -50441.28288322921 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -36230.65120404352 \n",
      "\n",
      "Episode:313 Reward:-0.6250074583599926 \n",
      "\n",
      "total financial balance: (eur) -43311.82268891613 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -29260.852773529146 \n",
      "\n",
      "Episode:314 Reward:-1.709933722497466 \n",
      "\n",
      "total financial balance: (eur) -73468.50201444223 \n",
      "\n",
      "internal rate of return 1362.6290898363404 \n",
      "\n",
      "net present value -44618.96833505251 \n",
      "\n",
      "Episode:315 Reward:-1.3887150518748368 \n",
      "\n",
      "total financial balance: (eur) -52789.22953236612 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -36449.739924801914 \n",
      "\n",
      "Episode:316 Reward:-2.028575298309426 \n",
      "\n",
      "total financial balance: (eur) -82179.52516620676 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -52329.076334418314 \n",
      "\n",
      "Episode:317 Reward:-2.6321265512144247 \n",
      "\n",
      "total financial balance: (eur) -85356.95161158693 \n",
      "\n",
      "internal rate of return 332.1557087516946 \n",
      "\n",
      "net present value -51658.135388921604 \n",
      "\n",
      "Episode:318 Reward:0.17329129752084282 \n",
      "\n",
      "total financial balance: (eur) -47517.37157435913 \n",
      "\n",
      "internal rate of return -36.59746044277177 \n",
      "\n",
      "net present value -33163.572206687 \n",
      "\n",
      "Episode:319 Reward:-4.069006990244376 \n",
      "\n",
      "total financial balance: (eur) -69837.05088063343 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -42873.67806931483 \n",
      "\n",
      "Episode:320 Reward:-2.7507600171174618 \n",
      "\n",
      "total financial balance: (eur) -65423.10652710394 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -41064.47140077538 \n",
      "\n",
      "Episode:321 Reward:-3.6705233467890643 \n",
      "\n",
      "total financial balance: (eur) -83717.49420447092 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -49998.30194036755 \n",
      "\n",
      "Episode:322 Reward:-2.735126696452152 \n",
      "\n",
      "total financial balance: (eur) -69166.55222414067 \n",
      "\n",
      "internal rate of return 169.06793557090043 \n",
      "\n",
      "net present value -46323.50199150262 \n",
      "\n",
      "Episode:323 Reward:-0.5949343291328169 \n",
      "\n",
      "total financial balance: (eur) -59960.467575166185 \n",
      "\n",
      "internal rate of return 329.33917365963794 \n",
      "\n",
      "net present value -40367.05856574885 \n",
      "\n",
      "Episode:324 Reward:-2.6345358501751397 \n",
      "\n",
      "total financial balance: (eur) -81935.71465914432 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -49540.46012226224 \n",
      "\n",
      "Episode:325 Reward:-5.000375010643851 \n",
      "\n",
      "total financial balance: (eur) -87611.82083878781 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -56100.149956732814 \n",
      "\n",
      "Episode:326 Reward:-2.2008909915154535 \n",
      "\n",
      "total financial balance: (eur) -55117.33028227677 \n",
      "\n",
      "internal rate of return 110.7997325629881 \n",
      "\n",
      "net present value -32159.041279064382 \n",
      "\n",
      "Episode:327 Reward:-0.5266247743878711 \n",
      "\n",
      "total financial balance: (eur) -57554.49627565402 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -37992.603872599386 \n",
      "\n",
      "Episode:328 Reward:-3.7509758303686054 \n",
      "\n",
      "total financial balance: (eur) -85521.74172557709 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -57575.632388795384 \n",
      "\n",
      "Episode:329 Reward:-4.139248920856229 \n",
      "\n",
      "total financial balance: (eur) -67809.7822807239 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -39129.58836422035 \n",
      "\n",
      "Episode:330 Reward:-5.975489632050682 \n",
      "\n",
      "total financial balance: (eur) -89514.08539447676 \n",
      "\n",
      "internal rate of return 182.61968688240327 \n",
      "\n",
      "net present value -51448.25699169501 \n",
      "\n",
      "Episode:331 Reward:-3.2643776214079225 \n",
      "\n",
      "total financial balance: (eur) -88226.46593469859 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -54056.77321728838 \n",
      "\n",
      "Episode:332 Reward:-2.0011519722704025 \n",
      "\n",
      "total financial balance: (eur) -67263.01585716916 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -43720.191201524525 \n",
      "\n",
      "Episode:333 Reward:-3.5562545550105416 \n",
      "\n",
      "total financial balance: (eur) -78322.03900773988 \n",
      "\n",
      "internal rate of return 117.80327823077839 \n",
      "\n",
      "net present value -46126.92043826337 \n",
      "\n",
      "Episode:334 Reward:-4.0617918383390546 \n",
      "\n",
      "total financial balance: (eur) -79492.11808092798 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -49753.02676630891 \n",
      "\n",
      "Episode:335 Reward:-4.6808759402638005 \n",
      "\n",
      "total financial balance: (eur) -79250.48124885582 \n",
      "\n",
      "internal rate of return 543.5456045735959 \n",
      "\n",
      "net present value -52398.18432334144 \n",
      "\n",
      "Episode:336 Reward:-1.6960491910753335 \n",
      "\n",
      "total financial balance: (eur) -63052.441554044635 \n",
      "\n",
      "internal rate of return 631.7608667601937 \n",
      "\n",
      "net present value -40079.04747466673 \n",
      "\n",
      "Episode:337 Reward:-0.6647249076793532 \n",
      "\n",
      "total financial balance: (eur) -47806.456254672325 \n",
      "\n",
      "internal rate of return 86.51985881831459 \n",
      "\n",
      "net present value -29577.232568422376 \n",
      "\n",
      "Episode:338 Reward:-1.0254852639038445 \n",
      "\n",
      "total financial balance: (eur) -57441.06693219754 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -35734.28657618964 \n",
      "\n",
      "Episode:339 Reward:-0.9113994690706914 \n",
      "\n",
      "total financial balance: (eur) -40272.909547428215 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -28994.184822038897 \n",
      "\n",
      "Episode:340 Reward:0.39618371951957126 \n",
      "\n",
      "total financial balance: (eur) -12436.361041194008 \n",
      "\n",
      "internal rate of return -12.678880069908082 \n",
      "\n",
      "net present value -9915.396940727245 \n",
      "\n",
      "Episode:341 Reward:-2.5808201191936586 \n",
      "\n",
      "total financial balance: (eur) -68670.55787723706 \n",
      "\n",
      "internal rate of return 283.21804260021855 \n",
      "\n",
      "net present value -44536.7068488471 \n",
      "\n",
      "Episode:342 Reward:-3.372146597965186 \n",
      "\n",
      "total financial balance: (eur) -74473.59300474313 \n",
      "\n",
      "internal rate of return 280.3490571599171 \n",
      "\n",
      "net present value -46174.49567631478 \n",
      "\n",
      "Episode:343 Reward:1.077311920189356 \n",
      "\n",
      "total financial balance: (eur) -37855.60080935068 \n",
      "\n",
      "internal rate of return -18.18185543107421 \n",
      "\n",
      "net present value -27588.84621822567 \n",
      "\n",
      "Episode:344 Reward:1.1902515166972454 \n",
      "\n",
      "total financial balance: (eur) -73096.2540352628 \n",
      "\n",
      "internal rate of return -56.34556546878817 \n",
      "\n",
      "net present value -49460.87624897143 \n",
      "\n",
      "Episode:345 Reward:-2.5126201213731476 \n",
      "\n",
      "total financial balance: (eur) -83457.1880202622 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -52124.7256576128 \n",
      "\n",
      "Episode:346 Reward:2.2459406477041166 \n",
      "\n",
      "total financial balance: (eur) -7941.6235945718245 \n",
      "\n",
      "internal rate of return -8.876080533650077 \n",
      "\n",
      "net present value -7366.18985104922 \n",
      "\n",
      "Episode:347 Reward:-3.377077831826 \n",
      "\n",
      "total financial balance: (eur) -46162.14002461598 \n",
      "\n",
      "internal rate of return 214.1679950403071 \n",
      "\n",
      "net present value -31174.240580784604 \n",
      "\n",
      "Episode:348 Reward:2.64107928756253 \n",
      "\n",
      "total financial balance: (eur) -30829.545640450273 \n",
      "\n",
      "internal rate of return -7.542490250373691 \n",
      "\n",
      "net present value -29082.94936007016 \n",
      "\n",
      "Episode:349 Reward:-2.480910446552107 \n",
      "\n",
      "total financial balance: (eur) -58686.578015329396 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -39288.85485044881 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:350 Reward:-2.398143947874342 \n",
      "\n",
      "total financial balance: (eur) -67475.88362527509 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -41805.92748206222 \n",
      "\n",
      "Episode:351 Reward:-1.0456488723681523 \n",
      "\n",
      "total financial balance: (eur) -54090.302911962324 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -36109.27764085526 \n",
      "\n",
      "Episode:352 Reward:-2.144940570574253 \n",
      "\n",
      "total financial balance: (eur) -71565.32264022293 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -48214.427663625895 \n",
      "\n",
      "Episode:353 Reward:-0.9338066281559686 \n",
      "\n",
      "total financial balance: (eur) -57758.74544273044 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -40978.245330140184 \n",
      "\n",
      "Episode:354 Reward:-0.639851404359093 \n",
      "\n",
      "total financial balance: (eur) -77838.08192441892 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -53936.28397424627 \n",
      "\n",
      "Episode:355 Reward:-5.709956212100675 \n",
      "\n",
      "total financial balance: (eur) -104310.63436656402 \n",
      "\n",
      "internal rate of return 385.51103376373845 \n",
      "\n",
      "net present value -65680.37197524375 \n",
      "\n",
      "Episode:356 Reward:-3.267135344592113 \n",
      "\n",
      "total financial balance: (eur) -63710.28877333845 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -41737.30902430235 \n",
      "\n",
      "Episode:357 Reward:-2.4627431057478795 \n",
      "\n",
      "total financial balance: (eur) -92169.53199623259 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -57869.104555852835 \n",
      "\n",
      "Episode:358 Reward:-1.1317100488052492 \n",
      "\n",
      "total financial balance: (eur) -38338.75720376351 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -25950.325544032574 \n",
      "\n",
      "Episode:359 Reward:-3.0824289249000985 \n",
      "\n",
      "total financial balance: (eur) -61719.00419120053 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -43352.32519644013 \n",
      "\n",
      "Episode:360 Reward:0.9306420528427735 \n",
      "\n",
      "total financial balance: (eur) -15391.809424365254 \n",
      "\n",
      "internal rate of return -8.09944217562193 \n",
      "\n",
      "net present value -14587.598749281324 \n",
      "\n",
      "Episode:361 Reward:-2.764983389946243 \n",
      "\n",
      "total financial balance: (eur) -64169.01788767974 \n",
      "\n",
      "internal rate of return 221.6075060343448 \n",
      "\n",
      "net present value -40480.12112339802 \n",
      "\n",
      "Episode:362 Reward:-3.360901674926877 \n",
      "\n",
      "total financial balance: (eur) -69512.1471132525 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -43335.93152914576 \n",
      "\n",
      "Episode:363 Reward:-2.285513127375905 \n",
      "\n",
      "total financial balance: (eur) -60242.88250642263 \n",
      "\n",
      "internal rate of return 51.09213704604307 \n",
      "\n",
      "net present value -35695.6435489567 \n",
      "\n",
      "Episode:364 Reward:0.792710472698277 \n",
      "\n",
      "total financial balance: (eur) -55317.160132271645 \n",
      "\n",
      "internal rate of return -39.133092960746716 \n",
      "\n",
      "net present value -37867.120734538345 \n",
      "\n",
      "Episode:365 Reward:-0.08640007142828654 \n",
      "\n",
      "total financial balance: (eur) -48265.24186542243 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -34928.6347646015 \n",
      "\n",
      "Episode:366 Reward:-3.96360404289831 \n",
      "\n",
      "total financial balance: (eur) -81137.57651083554 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -54001.92328639382 \n",
      "\n",
      "Episode:367 Reward:-2.358772178967745 \n",
      "\n",
      "total financial balance: (eur) -62574.34230951358 \n",
      "\n",
      "internal rate of return 133.7128745193542 \n",
      "\n",
      "net present value -38961.235795436296 \n",
      "\n",
      "Episode:368 Reward:-2.486069956868276 \n",
      "\n",
      "total financial balance: (eur) -50523.19060603588 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -32539.90640684019 \n",
      "\n",
      "Episode:369 Reward:-4.823845029937139 \n",
      "\n",
      "total financial balance: (eur) -70934.62257159367 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -41643.59542039093 \n",
      "\n",
      "Episode:370 Reward:-5.139073786641495 \n",
      "\n",
      "total financial balance: (eur) -76915.30204950093 \n",
      "\n",
      "internal rate of return 107.1291135038805 \n",
      "\n",
      "net present value -44541.952348279185 \n",
      "\n",
      "Episode:371 Reward:-1.926249913006085 \n",
      "\n",
      "total financial balance: (eur) -74315.75434957785 \n",
      "\n",
      "internal rate of return 4385.963435087779 \n",
      "\n",
      "net present value -47238.433750158016 \n",
      "\n",
      "Episode:372 Reward:-4.390461428684821 \n",
      "\n",
      "total financial balance: (eur) -79483.09835320794 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -49871.30132835352 \n",
      "\n",
      "Episode:373 Reward:-3.687690706972363 \n",
      "\n",
      "total financial balance: (eur) -70668.87106556792 \n",
      "\n",
      "internal rate of return 170.83141962542578 \n",
      "\n",
      "net present value -45093.71602321469 \n",
      "\n",
      "Episode:374 Reward:-0.6664721016102058 \n",
      "\n",
      "total financial balance: (eur) -36650.39313956937 \n",
      "\n",
      "internal rate of return 623.2639163113984 \n",
      "\n",
      "net present value -25576.82361317084 \n",
      "\n",
      "Episode:375 Reward:1.9536867579980461 \n",
      "\n",
      "total financial balance: (eur) -47260.840107791846 \n",
      "\n",
      "internal rate of return -14.227463600137646 \n",
      "\n",
      "net present value -37828.543560370395 \n",
      "\n",
      "Episode:376 Reward:-3.1641321820630823 \n",
      "\n",
      "total financial balance: (eur) -92242.15663225626 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -60464.2101732313 \n",
      "\n",
      "Episode:377 Reward:-3.9898985674768457 \n",
      "\n",
      "total financial balance: (eur) -86421.76650855738 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -56710.654627868345 \n",
      "\n",
      "Episode:378 Reward:-0.3668694947343338 \n",
      "\n",
      "total financial balance: (eur) -60110.40329007607 \n",
      "\n",
      "internal rate of return 76.64672021328948 \n",
      "\n",
      "net present value -38159.33314188638 \n",
      "\n",
      "Episode:379 Reward:-0.6993479391113179 \n",
      "\n",
      "total financial balance: (eur) -77255.94527639872 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -49440.18882631409 \n",
      "\n",
      "Episode:380 Reward:-2.8047635076709603 \n",
      "\n",
      "total financial balance: (eur) -62941.28308857538 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -41386.8753725389 \n",
      "\n",
      "Episode:381 Reward:-4.064157480922623 \n",
      "\n",
      "total financial balance: (eur) -94597.86842274269 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -59857.448921055686 \n",
      "\n",
      "Episode:382 Reward:-2.772790011050734 \n",
      "\n",
      "total financial balance: (eur) -57057.51576437945 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -35124.166453810736 \n",
      "\n",
      "Episode:383 Reward:0.009302671447940156 \n",
      "\n",
      "total financial balance: (eur) -28576.924088038584 \n",
      "\n",
      "internal rate of return -98.61530931593542 \n",
      "\n",
      "net present value -20965.913281520978 \n",
      "\n",
      "Episode:384 Reward:-2.078971867553889 \n",
      "\n",
      "total financial balance: (eur) -93236.6344703019 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -60609.39661200378 \n",
      "\n",
      "Episode:385 Reward:-0.7435905170435954 \n",
      "\n",
      "total financial balance: (eur) -54907.22680943763 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -37302.19823131989 \n",
      "\n",
      "Episode:386 Reward:0.8213720766059978 \n",
      "\n",
      "total financial balance: (eur) -59566.29676684951 \n",
      "\n",
      "internal rate of return -33.16295961512493 \n",
      "\n",
      "net present value -39773.24234779289 \n",
      "\n",
      "Episode:387 Reward:-4.412621387036427 \n",
      "\n",
      "total financial balance: (eur) -84841.2080495675 \n",
      "\n",
      "internal rate of return 785.5551567266682 \n",
      "\n",
      "net present value -53433.618187924825 \n",
      "\n",
      "Episode:388 Reward:-3.726537971170698 \n",
      "\n",
      "total financial balance: (eur) -55627.456158553236 \n",
      "\n",
      "internal rate of return 821.7097159009525 \n",
      "\n",
      "net present value -37619.79675080282 \n",
      "\n",
      "Episode:389 Reward:2.187822113959334 \n",
      "\n",
      "total financial balance: (eur) -40111.99921450047 \n",
      "\n",
      "internal rate of return -12.737771706049628 \n",
      "\n",
      "net present value -32238.297502133944 \n",
      "\n",
      "Episode:390 Reward:-4.27627368572698 \n",
      "\n",
      "total financial balance: (eur) -96401.5502830456 \n",
      "\n",
      "internal rate of return 1006.8679755207368 \n",
      "\n",
      "net present value -60812.264147724105 \n",
      "\n",
      "Episode:391 Reward:-1.7231076590784997 \n",
      "\n",
      "total financial balance: (eur) -23268.034563587047 \n",
      "\n",
      "internal rate of return 1576.0836701274318 \n",
      "\n",
      "net present value -17592.866109770788 \n",
      "\n",
      "Episode:392 Reward:-2.8727302922758238 \n",
      "\n",
      "total financial balance: (eur) -61690.27778760865 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -38772.57931747471 \n",
      "\n",
      "Episode:393 Reward:-4.652074009273194 \n",
      "\n",
      "total financial balance: (eur) -72016.16213245993 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -43322.31627393657 \n",
      "\n",
      "Episode:394 Reward:-3.383905131596558 \n",
      "\n",
      "total financial balance: (eur) -82767.98062018126 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -54581.15890528285 \n",
      "\n",
      "Episode:395 Reward:-5.167025946547131 \n",
      "\n",
      "total financial balance: (eur) -73782.36232845427 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -43022.211503344166 \n",
      "\n",
      "Episode:396 Reward:-2.187887203649353 \n",
      "\n",
      "total financial balance: (eur) -66988.73288103656 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -43620.13647275339 \n",
      "\n",
      "Episode:397 Reward:0.41299927676586323 \n",
      "\n",
      "total financial balance: (eur) -49174.24033721424 \n",
      "\n",
      "internal rate of return -16.836556912807087 \n",
      "\n",
      "net present value -38198.27629065885 \n",
      "\n",
      "Episode:398 Reward:-2.332798004791156 \n",
      "\n",
      "total financial balance: (eur) -52788.313230839434 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -33615.14032455916 \n",
      "\n",
      "Episode:399 Reward:1.2629212587204692 \n",
      "\n",
      "total financial balance: (eur) -38414.68315722582 \n",
      "\n",
      "internal rate of return -13.43214329528143 \n",
      "\n",
      "net present value -30382.391758292866 \n",
      "\n",
      "Episode:400 Reward:1.2270428645332514 \n",
      "\n",
      "total financial balance: (eur) -74822.70791434687 \n",
      "\n",
      "internal rate of return -32.20503624328644 \n",
      "\n",
      "net present value -53103.65288514685 \n",
      "\n",
      "Episode:401 Reward:-2.6092983180022995 \n",
      "\n",
      "total financial balance: (eur) -58749.25684702169 \n",
      "\n",
      "internal rate of return 209.78579721078597 \n",
      "\n",
      "net present value -36252.465900502204 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:402 Reward:-2.2880502975656256 \n",
      "\n",
      "total financial balance: (eur) -86275.47165955091 \n",
      "\n",
      "internal rate of return 612.6783718611879 \n",
      "\n",
      "net present value -54688.827258924524 \n",
      "\n",
      "Episode:403 Reward:-1.3791734227795938 \n",
      "\n",
      "total financial balance: (eur) -87545.29685224945 \n",
      "\n",
      "internal rate of return 148.50366362488367 \n",
      "\n",
      "net present value -54354.747421970715 \n",
      "\n",
      "Episode:404 Reward:1.6001788609759005 \n",
      "\n",
      "total financial balance: (eur) -32238.09055142155 \n",
      "\n",
      "internal rate of return -13.378589662822172 \n",
      "\n",
      "net present value -25073.190615262363 \n",
      "\n",
      "Episode:405 Reward:-2.1354112811799904 \n",
      "\n",
      "total financial balance: (eur) -65840.72796279228 \n",
      "\n",
      "internal rate of return 191.14581441718522 \n",
      "\n",
      "net present value -43093.48596827876 \n",
      "\n",
      "Episode:406 Reward:-1.4901265108825892 \n",
      "\n",
      "total financial balance: (eur) -61631.33352441902 \n",
      "\n",
      "internal rate of return 115.98589270742185 \n",
      "\n",
      "net present value -37909.15032454669 \n",
      "\n",
      "Episode:407 Reward:-0.9667679074168327 \n",
      "\n",
      "total financial balance: (eur) -37257.77592168808 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -29279.37777984786 \n",
      "\n",
      "Episode:408 Reward:-1.0279615084702527 \n",
      "\n",
      "total financial balance: (eur) -57072.76229562882 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -38949.63360491579 \n",
      "\n",
      "Episode:409 Reward:-1.367843771577869 \n",
      "\n",
      "total financial balance: (eur) -67140.51711734981 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -43261.69779723099 \n",
      "\n",
      "Episode:410 Reward:-0.23690509175851185 \n",
      "\n",
      "total financial balance: (eur) -19014.15485560954 \n",
      "\n",
      "internal rate of return 72.0550809503549 \n",
      "\n",
      "net present value -13253.69361737355 \n",
      "\n",
      "Episode:411 Reward:3.907383147657898 \n",
      "\n",
      "total financial balance: (eur) 20302.380341324315 \n",
      "\n",
      "internal rate of return 6.495582047631965 \n",
      "\n",
      "net present value 4378.692956553649 \n",
      "\n",
      "Episode:412 Reward:-1.2494885434054814 \n",
      "\n",
      "total financial balance: (eur) -88553.55357298843 \n",
      "\n",
      "internal rate of return 214.38847629750217 \n",
      "\n",
      "net present value -58231.584660124965 \n",
      "\n",
      "Episode:413 Reward:-5.7346888726755285 \n",
      "\n",
      "total financial balance: (eur) -107172.13501531411 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -64577.89950545816 \n",
      "\n",
      "Episode:414 Reward:-0.9133615641137367 \n",
      "\n",
      "total financial balance: (eur) -38503.08997897594 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -26395.324852385587 \n",
      "\n",
      "Episode:415 Reward:-4.657525467886613 \n",
      "\n",
      "total financial balance: (eur) -89732.7996684596 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -56021.499893850014 \n",
      "\n",
      "Episode:416 Reward:-3.2767774660186517 \n",
      "\n",
      "total financial balance: (eur) -83114.84223088516 \n",
      "\n",
      "internal rate of return 154.35875658062645 \n",
      "\n",
      "net present value -50634.582761723585 \n",
      "\n",
      "Episode:417 Reward:-1.2802162532993562 \n",
      "\n",
      "total financial balance: (eur) -55206.99627201949 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -34891.037532105176 \n",
      "\n",
      "Episode:418 Reward:-1.3374871581203307 \n",
      "\n",
      "total financial balance: (eur) -65646.72174787374 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -42323.88514958305 \n",
      "\n",
      "Episode:419 Reward:-1.721304191998549 \n",
      "\n",
      "total financial balance: (eur) -65332.37248532357 \n",
      "\n",
      "internal rate of return 211.21193103111295 \n",
      "\n",
      "net present value -43900.035623396754 \n",
      "\n",
      "Episode:420 Reward:2.856199552920919 \n",
      "\n",
      "total financial balance: (eur) -34213.515692632376 \n",
      "\n",
      "internal rate of return -12.29137325815175 \n",
      "\n",
      "net present value -27019.946509164096 \n",
      "\n",
      "Episode:421 Reward:-3.9217758539255336 \n",
      "\n",
      "total financial balance: (eur) -67638.11106230092 \n",
      "\n",
      "internal rate of return 93.70356149592847 \n",
      "\n",
      "net present value -40326.95041337997 \n",
      "\n",
      "Episode:422 Reward:-2.9415387111802693 \n",
      "\n",
      "total financial balance: (eur) -68532.229082194 \n",
      "\n",
      "internal rate of return 213.8185829205802 \n",
      "\n",
      "net present value -43394.3702977615 \n",
      "\n",
      "Episode:423 Reward:-3.0365881066934315 \n",
      "\n",
      "total financial balance: (eur) -71065.2775362605 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -44850.353154685334 \n",
      "\n",
      "Episode:424 Reward:-1.721957995525835 \n",
      "\n",
      "total financial balance: (eur) -78728.31015331982 \n",
      "\n",
      "internal rate of return 218.15051457414842 \n",
      "\n",
      "net present value -52289.99805610689 \n",
      "\n",
      "Episode:425 Reward:-3.148865652645267 \n",
      "\n",
      "total financial balance: (eur) -69681.46520675476 \n",
      "\n",
      "internal rate of return 396.3367047935286 \n",
      "\n",
      "net present value -45674.693592569645 \n",
      "\n",
      "Episode:426 Reward:0.02859408973730933 \n",
      "\n",
      "total financial balance: (eur) -57524.37681561152 \n",
      "\n",
      "internal rate of return -68.67829916943504 \n",
      "\n",
      "net present value -41616.68287684202 \n",
      "\n",
      "Episode:427 Reward:-2.4824644133674956 \n",
      "\n",
      "total financial balance: (eur) -92018.48955990249 \n",
      "\n",
      "internal rate of return 1697.5046001741368 \n",
      "\n",
      "net present value -59763.66369401016 \n",
      "\n",
      "Episode:428 Reward:-1.8931375433191269 \n",
      "\n",
      "total financial balance: (eur) -33295.150768783395 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -22520.105657512242 \n",
      "\n",
      "Episode:429 Reward:-2.2954133994368675 \n",
      "\n",
      "total financial balance: (eur) -76360.5535630697 \n",
      "\n",
      "internal rate of return 344.8204225880607 \n",
      "\n",
      "net present value -48327.94489598223 \n",
      "\n",
      "Episode:430 Reward:-1.2116501797374144 \n",
      "\n",
      "total financial balance: (eur) -71173.16405869299 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -46124.447980611476 \n",
      "\n",
      "Episode:431 Reward:-0.0385206684573659 \n",
      "\n",
      "total financial balance: (eur) -31136.08929888528 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -23125.85419572298 \n",
      "\n",
      "Episode:432 Reward:-4.029390539888496 \n",
      "\n",
      "total financial balance: (eur) -93233.02540353216 \n",
      "\n",
      "internal rate of return 1048.2239709779933 \n",
      "\n",
      "net present value -57571.81236158982 \n",
      "\n",
      "Episode:433 Reward:-3.9737163143229743 \n",
      "\n",
      "total financial balance: (eur) -85553.0575365043 \n",
      "\n",
      "internal rate of return 338.0997154563673 \n",
      "\n",
      "net present value -52041.11968834606 \n",
      "\n",
      "Episode:434 Reward:-3.603200659405426 \n",
      "\n",
      "total financial balance: (eur) -94793.55061798329 \n",
      "\n",
      "internal rate of return 232.98340181996093 \n",
      "\n",
      "net present value -61153.56482627276 \n",
      "\n",
      "Episode:435 Reward:-0.8553729749698932 \n",
      "\n",
      "total financial balance: (eur) -49495.89914709034 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -33094.34504652933 \n",
      "\n",
      "Episode:436 Reward:-4.004620699541 \n",
      "\n",
      "total financial balance: (eur) -94349.33013987847 \n",
      "\n",
      "internal rate of return 382.52686611182094 \n",
      "\n",
      "net present value -60122.58122954062 \n",
      "\n",
      "Episode:437 Reward:-3.2257712240467318 \n",
      "\n",
      "total financial balance: (eur) -93361.23465691312 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -59273.064097881106 \n",
      "\n",
      "Episode:438 Reward:-1.7514220225513937 \n",
      "\n",
      "total financial balance: (eur) -68051.69100185648 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -44256.88642379476 \n",
      "\n",
      "Episode:439 Reward:-1.699364314283668 \n",
      "\n",
      "total financial balance: (eur) -67376.43193821031 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -43654.67982072423 \n",
      "\n",
      "Episode:440 Reward:-6.360071468909658 \n",
      "\n",
      "total financial balance: (eur) -119474.35679892956 \n",
      "\n",
      "internal rate of return 2351.4518681832674 \n",
      "\n",
      "net present value -74464.30201210245 \n",
      "\n",
      "Episode:441 Reward:-2.7795064105036262 \n",
      "\n",
      "total financial balance: (eur) -78828.11547038257 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -52143.12127489692 \n",
      "\n",
      "Episode:442 Reward:-0.6879755337131929 \n",
      "\n",
      "total financial balance: (eur) -30285.012987695183 \n",
      "\n",
      "internal rate of return -19.538751126399422 \n",
      "\n",
      "net present value -24260.43725869637 \n",
      "\n",
      "Episode:443 Reward:-5.203921530955349 \n",
      "\n",
      "total financial balance: (eur) -101182.4924096928 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -61536.63718442017 \n",
      "\n",
      "Episode:444 Reward:2.2698181791289525 \n",
      "\n",
      "total financial balance: (eur) -35370.43062233219 \n",
      "\n",
      "internal rate of return -13.298968715768178 \n",
      "\n",
      "net present value -27767.715890811527 \n",
      "\n",
      "Episode:445 Reward:-1.8008321539721472 \n",
      "\n",
      "total financial balance: (eur) -52065.6632749213 \n",
      "\n",
      "internal rate of return 635.8812454933707 \n",
      "\n",
      "net present value -33174.05995839659 \n",
      "\n",
      "Episode:446 Reward:0.4120453142526367 \n",
      "\n",
      "total financial balance: (eur) -61566.0012573221 \n",
      "\n",
      "internal rate of return -44.71415412466625 \n",
      "\n",
      "net present value -42864.61968740112 \n",
      "\n",
      "Episode:447 Reward:-2.669135948630248 \n",
      "\n",
      "total financial balance: (eur) -46510.31689322327 \n",
      "\n",
      "internal rate of return 157.95747188815943 \n",
      "\n",
      "net present value -28031.639208735847 \n",
      "\n",
      "Episode:448 Reward:-1.9333461034698067 \n",
      "\n",
      "total financial balance: (eur) -50081.03529217876 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -33258.3106156486 \n",
      "\n",
      "Episode:449 Reward:-2.5486149176786776 \n",
      "\n",
      "total financial balance: (eur) -63457.23682506884 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -38018.9755870854 \n",
      "\n",
      "Episode:450 Reward:-3.0138520658694934 \n",
      "\n",
      "total financial balance: (eur) -56100.1329098058 \n",
      "\n",
      "internal rate of return 498.54687489518534 \n",
      "\n",
      "net present value -37592.860988976274 \n",
      "\n",
      "Episode:451 Reward:-3.9984096250496455 \n",
      "\n",
      "total financial balance: (eur) -93383.87436302917 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -58726.47881227404 \n",
      "\n",
      "Episode:452 Reward:-3.7735762231784293 \n",
      "\n",
      "total financial balance: (eur) -66165.4271445095 \n",
      "\n",
      "internal rate of return 112.13011137057474 \n",
      "\n",
      "net present value -39147.719727405616 \n",
      "\n",
      "Episode:453 Reward:-2.015496967938394 \n",
      "\n",
      "total financial balance: (eur) -49882.3968135309 \n",
      "\n",
      "internal rate of return 116.2108324559917 \n",
      "\n",
      "net present value -32879.122717331134 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:454 Reward:-6.345924573475837 \n",
      "\n",
      "total financial balance: (eur) -95271.28117317104 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -58774.64876616784 \n",
      "\n",
      "Episode:455 Reward:1.6157012535257909 \n",
      "\n",
      "total financial balance: (eur) -68618.99193672725 \n",
      "\n",
      "internal rate of return -56.305579420280026 \n",
      "\n",
      "net present value -45851.78927847188 \n",
      "\n",
      "Episode:456 Reward:-0.5266431547335642 \n",
      "\n",
      "total financial balance: (eur) -85159.9013242488 \n",
      "\n",
      "internal rate of return 163.60969227466123 \n",
      "\n",
      "net present value -52046.81177742957 \n",
      "\n",
      "Episode:457 Reward:1.9818726415652508 \n",
      "\n",
      "total financial balance: (eur) -30704.931852988353 \n",
      "\n",
      "internal rate of return -11.135450275270852 \n",
      "\n",
      "net present value -26305.516043198288 \n",
      "\n",
      "Episode:458 Reward:-0.9824241978708651 \n",
      "\n",
      "total financial balance: (eur) -34761.0294216372 \n",
      "\n",
      "internal rate of return 198.0385849946909 \n",
      "\n",
      "net present value -25388.026354378126 \n",
      "\n",
      "Episode:459 Reward:-0.24449929610342314 \n",
      "\n",
      "total financial balance: (eur) -16196.533245120187 \n",
      "\n",
      "internal rate of return -6.076398073602974 \n",
      "\n",
      "net present value -16842.640731378346 \n",
      "\n",
      "Episode:460 Reward:-1.7381475153404873 \n",
      "\n",
      "total financial balance: (eur) -63695.941228277836 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -40709.40826706355 \n",
      "\n",
      "Episode:461 Reward:-2.7970129483565933 \n",
      "\n",
      "total financial balance: (eur) -65979.655880709 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -40091.146466512015 \n",
      "\n",
      "Episode:462 Reward:-2.898837784369428 \n",
      "\n",
      "total financial balance: (eur) -62096.709549519386 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -39796.41292847821 \n",
      "\n",
      "Episode:463 Reward:-1.47994169015612 \n",
      "\n",
      "total financial balance: (eur) -56033.46103389687 \n",
      "\n",
      "internal rate of return 173.0477604785325 \n",
      "\n",
      "net present value -37161.08347235324 \n",
      "\n",
      "Episode:464 Reward:1.042085800593014 \n",
      "\n",
      "total financial balance: (eur) -17720.92031283829 \n",
      "\n",
      "internal rate of return -6.232337722222569 \n",
      "\n",
      "net present value -17754.671244625875 \n",
      "\n",
      "Episode:465 Reward:-2.626179469210809 \n",
      "\n",
      "total financial balance: (eur) -64094.253017237585 \n",
      "\n",
      "internal rate of return 64.0560942799117 \n",
      "\n",
      "net present value -37828.19773095847 \n",
      "\n",
      "Episode:466 Reward:-1.8702238741847022 \n",
      "\n",
      "total financial balance: (eur) -47210.84208476797 \n",
      "\n",
      "internal rate of return 537.5969602460676 \n",
      "\n",
      "net present value -32972.4393196882 \n",
      "\n",
      "Episode:467 Reward:-0.9492438479354051 \n",
      "\n",
      "total financial balance: (eur) -68894.76967134756 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -44133.66445483165 \n",
      "\n",
      "Episode:468 Reward:-1.7570188506043531 \n",
      "\n",
      "total financial balance: (eur) -40551.27525683142 \n",
      "\n",
      "internal rate of return 556.9695325637597 \n",
      "\n",
      "net present value -26809.479936087788 \n",
      "\n",
      "Episode:469 Reward:-0.5828915846891723 \n",
      "\n",
      "total financial balance: (eur) -61384.12591104201 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -41804.31722272439 \n",
      "\n",
      "Episode:470 Reward:2.846740641348605 \n",
      "\n",
      "total financial balance: (eur) -49319.38457208011 \n",
      "\n",
      "internal rate of return -23.534623659954 \n",
      "\n",
      "net present value -33892.90014874298 \n",
      "\n",
      "Episode:471 Reward:1.746650813670446 \n",
      "\n",
      "total financial balance: (eur) -22514.86674268999 \n",
      "\n",
      "internal rate of return -6.658723816008127 \n",
      "\n",
      "net present value -21649.374000725176 \n",
      "\n",
      "Episode:472 Reward:-2.4440013864615775 \n",
      "\n",
      "total financial balance: (eur) -67436.33745082372 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -43013.886049524706 \n",
      "\n",
      "Episode:473 Reward:-3.5704911672659128 \n",
      "\n",
      "total financial balance: (eur) -75200.27982809996 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -47852.095361670625 \n",
      "\n",
      "Episode:474 Reward:1.024565930123832 \n",
      "\n",
      "total financial balance: (eur) -30825.71713593525 \n",
      "\n",
      "internal rate of return -27.575232336514112 \n",
      "\n",
      "net present value -24246.731581038883 \n",
      "\n",
      "Episode:475 Reward:-4.581207220994318 \n",
      "\n",
      "total financial balance: (eur) -78440.65598503238 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -50885.08377864274 \n",
      "\n",
      "Episode:476 Reward:-2.5697526738491954 \n",
      "\n",
      "total financial balance: (eur) -43432.241978736594 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -26867.306317653532 \n",
      "\n",
      "Episode:477 Reward:-5.937158834798287 \n",
      "\n",
      "total financial balance: (eur) -79092.98349386954 \n",
      "\n",
      "internal rate of return 111.8471540822219 \n",
      "\n",
      "net present value -48194.47701046791 \n",
      "\n",
      "Episode:478 Reward:-1.4993307885075837 \n",
      "\n",
      "total financial balance: (eur) -72119.95297422544 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -48959.77513360816 \n",
      "\n",
      "Episode:479 Reward:-3.284782973230077 \n",
      "\n",
      "total financial balance: (eur) -59959.66669580431 \n",
      "\n",
      "internal rate of return 162.137150240081 \n",
      "\n",
      "net present value -38793.748224753836 \n",
      "\n",
      "Episode:480 Reward:-2.3097242156470013 \n",
      "\n",
      "total financial balance: (eur) -53089.38371573983 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -34950.38552940038 \n",
      "\n",
      "Episode:481 Reward:-2.5834812286610824 \n",
      "\n",
      "total financial balance: (eur) -69684.17191168242 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -47160.56751583076 \n",
      "\n",
      "Episode:482 Reward:-2.0000599741957683 \n",
      "\n",
      "total financial balance: (eur) -66316.69851368114 \n",
      "\n",
      "internal rate of return 1952.3927165977036 \n",
      "\n",
      "net present value -44736.1136166554 \n",
      "\n",
      "Episode:483 Reward:-4.589516265137194 \n",
      "\n",
      "total financial balance: (eur) -79294.34009890833 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -45925.43915233019 \n",
      "\n",
      "Episode:484 Reward:-4.7680266046541115 \n",
      "\n",
      "total financial balance: (eur) -79787.77797442827 \n",
      "\n",
      "internal rate of return 126.48759473387416 \n",
      "\n",
      "net present value -46916.64964480358 \n",
      "\n",
      "Episode:485 Reward:-4.258283159505205 \n",
      "\n",
      "total financial balance: (eur) -67605.48904764405 \n",
      "\n",
      "internal rate of return 387.2525486271388 \n",
      "\n",
      "net present value -40398.118912997306 \n",
      "\n",
      "Episode:486 Reward:0.6941369445999062 \n",
      "\n",
      "total financial balance: (eur) -40941.869719321265 \n",
      "\n",
      "internal rate of return -34.591554427513046 \n",
      "\n",
      "net present value -29655.665132916147 \n",
      "\n",
      "Episode:487 Reward:-1.274573921311231 \n",
      "\n",
      "total financial balance: (eur) -67323.88443793175 \n",
      "\n",
      "internal rate of return 328.66240053173516 \n",
      "\n",
      "net present value -45229.39695101082 \n",
      "\n",
      "Episode:488 Reward:-1.8523591234118648 \n",
      "\n",
      "total financial balance: (eur) -55420.11654060824 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -35519.19295037784 \n",
      "\n",
      "Episode:489 Reward:-1.829705462910184 \n",
      "\n",
      "total financial balance: (eur) -58657.57142460478 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -36024.67077265274 \n",
      "\n",
      "Episode:490 Reward:-1.7190287830968927 \n",
      "\n",
      "total financial balance: (eur) -53923.33852255604 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -37728.80553716728 \n",
      "\n",
      "Episode:491 Reward:-1.7968571575977377 \n",
      "\n",
      "total financial balance: (eur) -72883.40864355006 \n",
      "\n",
      "internal rate of return 156.99216182393968 \n",
      "\n",
      "net present value -44757.03507999017 \n",
      "\n",
      "Episode:492 Reward:-1.2105981385928644 \n",
      "\n",
      "total financial balance: (eur) -42429.23715358351 \n",
      "\n",
      "internal rate of return 2408.814505666776 \n",
      "\n",
      "net present value -30825.807705129086 \n",
      "\n",
      "Episode:493 Reward:-4.141744370181612 \n",
      "\n",
      "total financial balance: (eur) -64868.99128004123 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -40572.23456856759 \n",
      "\n",
      "Episode:494 Reward:-4.285428558337746 \n",
      "\n",
      "total financial balance: (eur) -93032.20228182308 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -59665.286184176715 \n",
      "\n",
      "Episode:495 Reward:-4.532463100802466 \n",
      "\n",
      "total financial balance: (eur) -85079.46794345937 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -51711.23348463886 \n",
      "\n",
      "Episode:496 Reward:-2.1623753514736355 \n",
      "\n",
      "total financial balance: (eur) -27252.453074888825 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -23303.237857418855 \n",
      "\n",
      "Episode:497 Reward:-2.8133586855355652 \n",
      "\n",
      "total financial balance: (eur) -76569.01054943794 \n",
      "\n",
      "internal rate of return 385.00231013421546 \n",
      "\n",
      "net present value -50474.38279943699 \n",
      "\n",
      "Episode:498 Reward:-3.999924260127643 \n",
      "\n",
      "total financial balance: (eur) -66841.13611260956 \n",
      "\n",
      "internal rate of return 553.136688599112 \n",
      "\n",
      "net present value -42032.86802822235 \n",
      "\n",
      "Episode:499 Reward:-1.071292225627114 \n",
      "\n",
      "total financial balance: (eur) -36446.93468575278 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -25440.137587440597 \n",
      "\n",
      "Episode:500 Reward:-3.572366567123285 \n",
      "\n",
      "total financial balance: (eur) -47210.455523810684 \n",
      "\n",
      "internal rate of return 82.3673327794577 \n",
      "\n",
      "net present value -27827.161529378187 \n",
      "\n",
      "Episode:501 Reward:2.3677818068100454 \n",
      "\n",
      "total financial balance: (eur) -46506.926435727946 \n",
      "\n",
      "internal rate of return -14.191328907026868 \n",
      "\n",
      "net present value -35893.79061553346 \n",
      "\n",
      "Episode:502 Reward:-2.423695589150062 \n",
      "\n",
      "total financial balance: (eur) -63668.08589976803 \n",
      "\n",
      "internal rate of return 200.206180011159 \n",
      "\n",
      "net present value -40840.26581109127 \n",
      "\n",
      "Episode:503 Reward:-5.833186050867622 \n",
      "\n",
      "total financial balance: (eur) -94545.84021380078 \n",
      "\n",
      "internal rate of return 189.075606409961 \n",
      "\n",
      "net present value -57277.66847693958 \n",
      "\n",
      "Episode:504 Reward:-0.9794127912904091 \n",
      "\n",
      "total financial balance: (eur) -72205.99035593361 \n",
      "\n",
      "internal rate of return 373.1770120419057 \n",
      "\n",
      "net present value -44919.60472215425 \n",
      "\n",
      "Episode:505 Reward:-3.3617431332920713 \n",
      "\n",
      "total financial balance: (eur) -68985.08645065181 \n",
      "\n",
      "internal rate of return 186.1815458828988 \n",
      "\n",
      "net present value -44420.94539610513 \n",
      "\n",
      "Episode:506 Reward:-1.7502739738387294 \n",
      "\n",
      "total financial balance: (eur) -57776.766171085364 \n",
      "\n",
      "internal rate of return 327.24342468207306 \n",
      "\n",
      "net present value -37592.76760430894 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:507 Reward:1.6579594845200336 \n",
      "\n",
      "total financial balance: (eur) -30286.29543530722 \n",
      "\n",
      "internal rate of return -12.49210830876204 \n",
      "\n",
      "net present value -24456.20272015893 \n",
      "\n",
      "Episode:508 Reward:-1.1181274303437385 \n",
      "\n",
      "total financial balance: (eur) -63913.51514560192 \n",
      "\n",
      "internal rate of return 522.1691630137784 \n",
      "\n",
      "net present value -42646.70234601208 \n",
      "\n",
      "Episode:509 Reward:-3.8682897587518728 \n",
      "\n",
      "total financial balance: (eur) -52312.7915011039 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -32133.583593527936 \n",
      "\n",
      "Episode:510 Reward:-1.3719926668914886 \n",
      "\n",
      "total financial balance: (eur) -30128.838700578537 \n",
      "\n",
      "internal rate of return 4141.909975016781 \n",
      "\n",
      "net present value -23809.345530797716 \n",
      "\n",
      "Episode:511 Reward:-1.9174279410680837 \n",
      "\n",
      "total financial balance: (eur) -51215.91353739592 \n",
      "\n",
      "internal rate of return 940.9799496973372 \n",
      "\n",
      "net present value -32899.48388557967 \n",
      "\n",
      "Episode:512 Reward:-2.85573530548467 \n",
      "\n",
      "total financial balance: (eur) -75947.08929450215 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -48609.62524139177 \n",
      "\n",
      "Episode:513 Reward:-0.32387035018885674 \n",
      "\n",
      "total financial balance: (eur) -69784.76468762677 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -45312.22481630471 \n",
      "\n",
      "Episode:514 Reward:-3.3942627661146605 \n",
      "\n",
      "total financial balance: (eur) -73774.23697630901 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -46135.31333581993 \n",
      "\n",
      "Episode:515 Reward:-0.9996184825692362 \n",
      "\n",
      "total financial balance: (eur) -58501.109854747 \n",
      "\n",
      "internal rate of return 554.1427166715904 \n",
      "\n",
      "net present value -39607.24506699683 \n",
      "\n",
      "Episode:516 Reward:-1.5716802057532886 \n",
      "\n",
      "total financial balance: (eur) -48009.737654645905 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -33412.76312472616 \n",
      "\n",
      "Episode:517 Reward:2.007928465767415 \n",
      "\n",
      "total financial balance: (eur) -22407.006633954374 \n",
      "\n",
      "internal rate of return -5.789756279460034 \n",
      "\n",
      "net present value -23357.697512472267 \n",
      "\n",
      "Episode:518 Reward:-0.7165308744920567 \n",
      "\n",
      "total financial balance: (eur) -26550.38623596888 \n",
      "\n",
      "internal rate of return 87.16691784397048 \n",
      "\n",
      "net present value -17991.300590440056 \n",
      "\n",
      "Episode:519 Reward:-1.0400720430824777 \n",
      "\n",
      "total financial balance: (eur) -75386.38160338943 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -50634.620472984745 \n",
      "\n",
      "Episode:520 Reward:-2.379507525193858 \n",
      "\n",
      "total financial balance: (eur) -81728.76132120083 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -52449.39288342743 \n",
      "\n",
      "Episode:521 Reward:-1.0041921755529748 \n",
      "\n",
      "total financial balance: (eur) -32055.096005487525 \n",
      "\n",
      "internal rate of return 367.2825147915039 \n",
      "\n",
      "net present value -21331.980632997544 \n",
      "\n",
      "Episode:522 Reward:-4.250663522321708 \n",
      "\n",
      "total financial balance: (eur) -103173.21541244739 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -61087.71595639919 \n",
      "\n",
      "Episode:523 Reward:-3.973305564683543 \n",
      "\n",
      "total financial balance: (eur) -100248.85216912799 \n",
      "\n",
      "internal rate of return 239.76095829213722 \n",
      "\n",
      "net present value -61987.07802870356 \n",
      "\n",
      "Episode:524 Reward:-1.540521797250296 \n",
      "\n",
      "total financial balance: (eur) -71064.13755218657 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -46157.66645990005 \n",
      "\n",
      "Episode:525 Reward:-0.5124064397091451 \n",
      "\n",
      "total financial balance: (eur) -36136.098266748806 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -23806.14763055978 \n",
      "\n",
      "Episode:526 Reward:-6.6493875705189005 \n",
      "\n",
      "total financial balance: (eur) -129447.48225545333 \n",
      "\n",
      "internal rate of return 134.99359687259633 \n",
      "\n",
      "net present value -76203.56602101661 \n",
      "\n",
      "Episode:527 Reward:-1.4779047494780453 \n",
      "\n",
      "total financial balance: (eur) -69388.87059555223 \n",
      "\n",
      "internal rate of return 260.81476869368606 \n",
      "\n",
      "net present value -46518.09423799784 \n",
      "\n",
      "Episode:528 Reward:-1.0954687496411406 \n",
      "\n",
      "total financial balance: (eur) -46392.983010319695 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -30880.346104674358 \n",
      "\n",
      "Episode:529 Reward:0.7226578865853444 \n",
      "\n",
      "total financial balance: (eur) -40192.49615755764 \n",
      "\n",
      "internal rate of return -18.394460783603684 \n",
      "\n",
      "net present value -30292.17813542981 \n",
      "\n",
      "Episode:530 Reward:-3.0025901399508856 \n",
      "\n",
      "total financial balance: (eur) -83818.30063398617 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -51254.55523073173 \n",
      "\n",
      "Episode:531 Reward:-1.3631406516827629 \n",
      "\n",
      "total financial balance: (eur) -56800.260024877774 \n",
      "\n",
      "internal rate of return 155.8022455546091 \n",
      "\n",
      "net present value -34752.385812092434 \n",
      "\n",
      "Episode:532 Reward:-3.1347699574397367 \n",
      "\n",
      "total financial balance: (eur) -93429.76045587029 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -60214.84938189535 \n",
      "\n",
      "Episode:533 Reward:-3.8099876397450845 \n",
      "\n",
      "total financial balance: (eur) -72869.22676321842 \n",
      "\n",
      "internal rate of return 322.2361789127085 \n",
      "\n",
      "net present value -46491.27324629049 \n",
      "\n",
      "Episode:534 Reward:-3.546803978996466 \n",
      "\n",
      "total financial balance: (eur) -79469.15286383034 \n",
      "\n",
      "internal rate of return 195.07778049436175 \n",
      "\n",
      "net present value -49487.84585324697 \n",
      "\n",
      "Episode:535 Reward:-1.5008898232804295 \n",
      "\n",
      "total financial balance: (eur) -43330.582469361645 \n",
      "\n",
      "internal rate of return 218.8728117877936 \n",
      "\n",
      "net present value -28676.92542679589 \n",
      "\n",
      "Episode:536 Reward:-0.616045641270618 \n",
      "\n",
      "total financial balance: (eur) -43524.266707567156 \n",
      "\n",
      "internal rate of return 480.5040470270874 \n",
      "\n",
      "net present value -27957.724472025708 \n",
      "\n",
      "Episode:537 Reward:-3.8847071383149325 \n",
      "\n",
      "total financial balance: (eur) -80675.94127883263 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -49593.19588068147 \n",
      "\n",
      "Episode:538 Reward:-3.0051043716252215 \n",
      "\n",
      "total financial balance: (eur) -86852.92290132314 \n",
      "\n",
      "internal rate of return 2267.3687755061037 \n",
      "\n",
      "net present value -55844.53569123238 \n",
      "\n",
      "Episode:539 Reward:-1.581216003671083 \n",
      "\n",
      "total financial balance: (eur) -45577.18721600032 \n",
      "\n",
      "internal rate of return 1474.3821252799878 \n",
      "\n",
      "net present value -31531.773578548513 \n",
      "\n",
      "Episode:540 Reward:-5.2542325690561 \n",
      "\n",
      "total financial balance: (eur) -103050.01336804275 \n",
      "\n",
      "internal rate of return 558.5427586564344 \n",
      "\n",
      "net present value -63503.72730557393 \n",
      "\n",
      "Episode:541 Reward:-4.473167128091317 \n",
      "\n",
      "total financial balance: (eur) -67696.11536640601 \n",
      "\n",
      "internal rate of return 1292.9141382866853 \n",
      "\n",
      "net present value -41446.583168093624 \n",
      "\n",
      "Episode:542 Reward:-2.4099711517836915 \n",
      "\n",
      "total financial balance: (eur) -75766.5025775916 \n",
      "\n",
      "internal rate of return 415.8812935454085 \n",
      "\n",
      "net present value -47968.05019698607 \n",
      "\n",
      "Episode:543 Reward:-1.4112557477749514 \n",
      "\n",
      "total financial balance: (eur) -55526.962088406195 \n",
      "\n",
      "internal rate of return 600.3665461761052 \n",
      "\n",
      "net present value -32664.641089186 \n",
      "\n",
      "Episode:544 Reward:2.913327481813423 \n",
      "\n",
      "total financial balance: (eur) 30439.875965871106 \n",
      "\n",
      "internal rate of return 16.135062014733048 \n",
      "\n",
      "net present value 12820.495012197254 \n",
      "\n",
      "Episode:545 Reward:-2.454372231042565 \n",
      "\n",
      "total financial balance: (eur) -57290.27449731122 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -35573.880922034776 \n",
      "\n",
      "Episode:546 Reward:-4.583154566454791 \n",
      "\n",
      "total financial balance: (eur) -89235.07319235234 \n",
      "\n",
      "internal rate of return 781.1687571603806 \n",
      "\n",
      "net present value -55931.89219621077 \n",
      "\n",
      "Episode:547 Reward:-4.259599827524392 \n",
      "\n",
      "total financial balance: (eur) -112001.91315212562 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -69941.83615259631 \n",
      "\n",
      "Episode:548 Reward:0.9288739183915641 \n",
      "\n",
      "total financial balance: (eur) -65019.74538261285 \n",
      "\n",
      "internal rate of return -47.463160774095236 \n",
      "\n",
      "net present value -43183.52157914443 \n",
      "\n",
      "Episode:549 Reward:-3.4402305860249336 \n",
      "\n",
      "total financial balance: (eur) -78000.68300095228 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -51643.259672678265 \n",
      "\n",
      "Episode:550 Reward:-2.1600803051550166 \n",
      "\n",
      "total financial balance: (eur) -83621.97400779743 \n",
      "\n",
      "internal rate of return 264.392795636959 \n",
      "\n",
      "net present value -54803.508336748164 \n",
      "\n",
      "Episode:551 Reward:1.1083885342807989 \n",
      "\n",
      "total financial balance: (eur) -58694.044636973886 \n",
      "\n",
      "internal rate of return -31.003527462491554 \n",
      "\n",
      "net present value -40970.23491695098 \n",
      "\n",
      "Episode:552 Reward:-4.767812787994193 \n",
      "\n",
      "total financial balance: (eur) -49334.0048878809 \n",
      "\n",
      "internal rate of return 142.64823430080548 \n",
      "\n",
      "net present value -28119.945407523344 \n",
      "\n",
      "Episode:553 Reward:-3.682928330381749 \n",
      "\n",
      "total financial balance: (eur) -64638.03626434977 \n",
      "\n",
      "internal rate of return 114.38275875301089 \n",
      "\n",
      "net present value -40565.01700958412 \n",
      "\n",
      "Episode:554 Reward:-1.6977801153656638 \n",
      "\n",
      "total financial balance: (eur) -50050.15729733117 \n",
      "\n",
      "internal rate of return 1445.1367631339483 \n",
      "\n",
      "net present value -33301.37886012042 \n",
      "\n",
      "Episode:555 Reward:-1.4875284528414667 \n",
      "\n",
      "total financial balance: (eur) -64157.81579825441 \n",
      "\n",
      "internal rate of return 316.8834353992895 \n",
      "\n",
      "net present value -41968.6105584803 \n",
      "\n",
      "Episode:556 Reward:-3.9666494506787555 \n",
      "\n",
      "total financial balance: (eur) -74967.48718518125 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -47784.57110575882 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:557 Reward:0.8905047115741354 \n",
      "\n",
      "total financial balance: (eur) -20906.371763738443 \n",
      "\n",
      "internal rate of return -11.751978643958939 \n",
      "\n",
      "net present value -17849.805684576633 \n",
      "\n",
      "Episode:558 Reward:-2.6244506808452317 \n",
      "\n",
      "total financial balance: (eur) -63484.57685011995 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -40658.12266398597 \n",
      "\n",
      "Episode:559 Reward:-4.646223383625751 \n",
      "\n",
      "total financial balance: (eur) -88850.23104461077 \n",
      "\n",
      "internal rate of return 185.6438663068416 \n",
      "\n",
      "net present value -54618.4157747501 \n",
      "\n",
      "Episode:560 Reward:-3.9206850947667418 \n",
      "\n",
      "total financial balance: (eur) -62506.982268956344 \n",
      "\n",
      "internal rate of return 379.9478905751989 \n",
      "\n",
      "net present value -38892.034416982424 \n",
      "\n",
      "Episode:561 Reward:-1.2500493880116974 \n",
      "\n",
      "total financial balance: (eur) -65772.38559924038 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -42872.261548747476 \n",
      "\n",
      "Episode:562 Reward:-2.644130367116756 \n",
      "\n",
      "total financial balance: (eur) -104941.9989341893 \n",
      "\n",
      "internal rate of return 1148.2260906293845 \n",
      "\n",
      "net present value -66804.55114765592 \n",
      "\n",
      "Episode:563 Reward:-1.8182774663965338 \n",
      "\n",
      "total financial balance: (eur) -30246.09526766384 \n",
      "\n",
      "internal rate of return 96.64437400060162 \n",
      "\n",
      "net present value -20203.948628135604 \n",
      "\n",
      "Episode:564 Reward:-3.9490404089929863 \n",
      "\n",
      "total financial balance: (eur) -87937.65606077707 \n",
      "\n",
      "internal rate of return 175.37162229840905 \n",
      "\n",
      "net present value -53011.574887429924 \n",
      "\n",
      "Episode:565 Reward:1.6852304035285897 \n",
      "\n",
      "total financial balance: (eur) -39249.91015157288 \n",
      "\n",
      "internal rate of return -20.914539942402598 \n",
      "\n",
      "net present value -29267.74685220012 \n",
      "\n",
      "Episode:566 Reward:-1.2672042743985394 \n",
      "\n",
      "total financial balance: (eur) -76771.16257737957 \n",
      "\n",
      "internal rate of return 111.25300633321187 \n",
      "\n",
      "net present value -48614.49093926111 \n",
      "\n",
      "Episode:567 Reward:-1.4809822232342231 \n",
      "\n",
      "total financial balance: (eur) -69202.00676117465 \n",
      "\n",
      "internal rate of return 240.117761363883 \n",
      "\n",
      "net present value -43739.511804074915 \n",
      "\n",
      "Episode:568 Reward:-4.968388609659544 \n",
      "\n",
      "total financial balance: (eur) -104712.38335080817 \n",
      "\n",
      "internal rate of return 441.0619677831722 \n",
      "\n",
      "net present value -66209.92058770967 \n",
      "\n",
      "Episode:569 Reward:-0.14067767202583856 \n",
      "\n",
      "total financial balance: (eur) -29501.944716035632 \n",
      "\n",
      "internal rate of return -24.60241239151656 \n",
      "\n",
      "net present value -21555.387117431077 \n",
      "\n",
      "Episode:570 Reward:-3.191995485801215 \n",
      "\n",
      "total financial balance: (eur) -55688.09247561397 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -34449.46064662408 \n",
      "\n",
      "Episode:571 Reward:-1.6176949620042378 \n",
      "\n",
      "total financial balance: (eur) -65495.26623647607 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -42440.324514854015 \n",
      "\n",
      "Episode:572 Reward:-2.908323479814826 \n",
      "\n",
      "total financial balance: (eur) -41503.843770603424 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -26903.32169668066 \n",
      "\n",
      "Episode:573 Reward:-0.554697749902848 \n",
      "\n",
      "total financial balance: (eur) -78282.6513851371 \n",
      "\n",
      "internal rate of return 179.64203986752872 \n",
      "\n",
      "net present value -51480.44399876635 \n",
      "\n",
      "Episode:574 Reward:-4.443283210041 \n",
      "\n",
      "total financial balance: (eur) -87631.14569045306 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -57512.42274124058 \n",
      "\n",
      "Episode:575 Reward:-0.8276201401567441 \n",
      "\n",
      "total financial balance: (eur) -48314.048927555006 \n",
      "\n",
      "internal rate of return 97.44852806873145 \n",
      "\n",
      "net present value -32354.78092630164 \n",
      "\n",
      "Episode:576 Reward:0.6191341616040099 \n",
      "\n",
      "total financial balance: (eur) -41158.688868330486 \n",
      "\n",
      "internal rate of return -20.343246750827205 \n",
      "\n",
      "net present value -32358.324519667654 \n",
      "\n",
      "Episode:577 Reward:-1.9144966214823025 \n",
      "\n",
      "total financial balance: (eur) -56964.36385192336 \n",
      "\n",
      "internal rate of return 328.4511583277721 \n",
      "\n",
      "net present value -35807.22063808443 \n",
      "\n",
      "Episode:578 Reward:-0.7354219208876485 \n",
      "\n",
      "total financial balance: (eur) -59952.02873010817 \n",
      "\n",
      "internal rate of return 486.2842319100739 \n",
      "\n",
      "net present value -40244.60168654995 \n",
      "\n",
      "Episode:579 Reward:-1.0209759562287346 \n",
      "\n",
      "total financial balance: (eur) -70283.14214835574 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -46048.587579921856 \n",
      "\n",
      "Episode:580 Reward:-0.9736777887924781 \n",
      "\n",
      "total financial balance: (eur) -56741.4451042437 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -35451.30172671572 \n",
      "\n",
      "Episode:581 Reward:-6.604460005636135 \n",
      "\n",
      "total financial balance: (eur) -83537.93047766913 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -51600.32407898623 \n",
      "\n",
      "Episode:582 Reward:-2.488430616969864 \n",
      "\n",
      "total financial balance: (eur) -65681.35253305796 \n",
      "\n",
      "internal rate of return 127.55251728583627 \n",
      "\n",
      "net present value -43635.01648172718 \n",
      "\n",
      "Episode:583 Reward:-3.082787279425059 \n",
      "\n",
      "total financial balance: (eur) -83767.67611741312 \n",
      "\n",
      "internal rate of return 648.1593246976511 \n",
      "\n",
      "net present value -50055.18476159112 \n",
      "\n",
      "Episode:584 Reward:-4.6431904637477635 \n",
      "\n",
      "total financial balance: (eur) -106591.06693052538 \n",
      "\n",
      "internal rate of return 203.01858709346465 \n",
      "\n",
      "net present value -65709.33491158465 \n",
      "\n",
      "Episode:585 Reward:-2.811334832322398 \n",
      "\n",
      "total financial balance: (eur) -65376.521409184 \n",
      "\n",
      "internal rate of return 89.26133991292585 \n",
      "\n",
      "net present value -39616.86144696142 \n",
      "\n",
      "Episode:586 Reward:-1.2861142400754388 \n",
      "\n",
      "total financial balance: (eur) -52013.122265084436 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -35040.93618619938 \n",
      "\n",
      "Episode:587 Reward:-2.510574992772333 \n",
      "\n",
      "total financial balance: (eur) -108381.21843921556 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -69102.14705897588 \n",
      "\n",
      "Episode:588 Reward:-1.244397148375805 \n",
      "\n",
      "total financial balance: (eur) -66017.84470100442 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -45646.23691246431 \n",
      "\n",
      "Episode:589 Reward:0.48436946498052114 \n",
      "\n",
      "total financial balance: (eur) -51764.268572363115 \n",
      "\n",
      "internal rate of return -75.87212183957229 \n",
      "\n",
      "net present value -34236.23122882998 \n",
      "\n",
      "Episode:590 Reward:-1.671142883099954 \n",
      "\n",
      "total financial balance: (eur) -73613.34996610269 \n",
      "\n",
      "internal rate of return 233.0518572779244 \n",
      "\n",
      "net present value -48915.75243023158 \n",
      "\n",
      "Episode:591 Reward:1.1240435574456251 \n",
      "\n",
      "total financial balance: (eur) -5243.331138608743 \n",
      "\n",
      "internal rate of return -4.1299674724219475 \n",
      "\n",
      "net present value -5398.554843383598 \n",
      "\n",
      "Episode:592 Reward:-0.9639452060091935 \n",
      "\n",
      "total financial balance: (eur) -46927.809926901624 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -32929.69706536224 \n",
      "\n",
      "Episode:593 Reward:-1.3639849895004226 \n",
      "\n",
      "total financial balance: (eur) -66813.15269345755 \n",
      "\n",
      "internal rate of return 180.02157491792167 \n",
      "\n",
      "net present value -43157.54808306901 \n",
      "\n",
      "Episode:594 Reward:-0.0929670095807378 \n",
      "\n",
      "total financial balance: (eur) -40966.94079079643 \n",
      "\n",
      "internal rate of return -20.398136869887583 \n",
      "\n",
      "net present value -30738.876235500233 \n",
      "\n",
      "Episode:595 Reward:-2.1710585785456713 \n",
      "\n",
      "total financial balance: (eur) -54290.90939647797 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -36430.49302480926 \n",
      "\n",
      "Episode:596 Reward:-0.3976852328564164 \n",
      "\n",
      "total financial balance: (eur) -51165.952627286184 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -37290.10621957531 \n",
      "\n",
      "Episode:597 Reward:-2.955091662857877 \n",
      "\n",
      "total financial balance: (eur) -64983.32517992995 \n",
      "\n",
      "internal rate of return 263.281811949613 \n",
      "\n",
      "net present value -42586.04120305926 \n",
      "\n",
      "Episode:598 Reward:0.016038924675597626 \n",
      "\n",
      "total financial balance: (eur) -66480.47699969621 \n",
      "\n",
      "internal rate of return -99.12026209978403 \n",
      "\n",
      "net present value -45274.25523093727 \n",
      "\n",
      "Episode:599 Reward:-2.7741284534757877 \n",
      "\n",
      "total financial balance: (eur) -75279.3127129441 \n",
      "\n",
      "internal rate of return 81.87702480636841 \n",
      "\n",
      "net present value -46151.155535114114 \n",
      "\n",
      "Episode:600 Reward:-0.8138356827521438 \n",
      "\n",
      "total financial balance: (eur) -53025.874103650516 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -37141.663529131 \n",
      "\n",
      "Episode:601 Reward:-1.6540059283236015 \n",
      "\n",
      "total financial balance: (eur) -60504.56569960885 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -38741.41935751739 \n",
      "\n",
      "Episode:602 Reward:-3.0868170287067715 \n",
      "\n",
      "total financial balance: (eur) -66222.69787266814 \n",
      "\n",
      "internal rate of return 259.97951523937485 \n",
      "\n",
      "net present value -40760.75425362642 \n",
      "\n",
      "Episode:603 Reward:-2.783863115370579 \n",
      "\n",
      "total financial balance: (eur) -87204.03869494073 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -52088.22755553694 \n",
      "\n",
      "Episode:604 Reward:-2.0830886822450676 \n",
      "\n",
      "total financial balance: (eur) -87569.21605717897 \n",
      "\n",
      "internal rate of return 285.87579411794974 \n",
      "\n",
      "net present value -57800.02214888876 \n",
      "\n",
      "Episode:605 Reward:-1.3016462509890152 \n",
      "\n",
      "total financial balance: (eur) -67345.65752625462 \n",
      "\n",
      "internal rate of return 82151.27894917471 \n",
      "\n",
      "net present value -45318.617104412886 \n",
      "\n",
      "Episode:606 Reward:-1.4826434062607996 \n",
      "\n",
      "total financial balance: (eur) -61691.83854654973 \n",
      "\n",
      "internal rate of return 291.88950918838333 \n",
      "\n",
      "net present value -40806.75044172419 \n",
      "\n",
      "Episode:607 Reward:-2.310511512530862 \n",
      "\n",
      "total financial balance: (eur) -54620.17455496121 \n",
      "\n",
      "internal rate of return 1054.4243563646824 \n",
      "\n",
      "net present value -36676.26068150946 \n",
      "\n",
      "Episode:608 Reward:0.39555942720084747 \n",
      "\n",
      "total financial balance: (eur) -65196.111295045295 \n",
      "\n",
      "internal rate of return -86.54183348952002 \n",
      "\n",
      "net present value -44912.66488832278 \n",
      "\n",
      "Episode:609 Reward:-1.3694398753286687 \n",
      "\n",
      "total financial balance: (eur) -62416.07151895638 \n",
      "\n",
      "internal rate of return 94.1032538895933 \n",
      "\n",
      "net present value -38404.866941337496 \n",
      "\n",
      "Episode:610 Reward:0.26840557495494066 \n",
      "\n",
      "total financial balance: (eur) -58487.26899480795 \n",
      "\n",
      "internal rate of return -78.98810067159322 \n",
      "\n",
      "net present value -37940.799856592144 \n",
      "\n",
      "Episode:611 Reward:-2.6525642380164807 \n",
      "\n",
      "total financial balance: (eur) -63569.303670382484 \n",
      "\n",
      "internal rate of return 445.33830667050654 \n",
      "\n",
      "net present value -40166.21671105038 \n",
      "\n",
      "Episode:612 Reward:-2.09182975325407 \n",
      "\n",
      "total financial balance: (eur) -75519.1092642946 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -46237.9531396127 \n",
      "\n",
      "Episode:613 Reward:-1.6968618432191434 \n",
      "\n",
      "total financial balance: (eur) -54694.283680719716 \n",
      "\n",
      "internal rate of return 360.7484002844346 \n",
      "\n",
      "net present value -37783.54883478301 \n",
      "\n",
      "Episode:614 Reward:-3.2259799098826822 \n",
      "\n",
      "total financial balance: (eur) -80886.08309533053 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -49077.96599440442 \n",
      "\n",
      "Episode:615 Reward:-2.692174597520476 \n",
      "\n",
      "total financial balance: (eur) -65463.196048090605 \n",
      "\n",
      "internal rate of return 389.6736113856196 \n",
      "\n",
      "net present value -43694.85472937652 \n",
      "\n",
      "Episode:616 Reward:1.7378701161731196 \n",
      "\n",
      "total financial balance: (eur) -51343.84737568891 \n",
      "\n",
      "internal rate of return -42.69391226207293 \n",
      "\n",
      "net present value -34860.15348767991 \n",
      "\n",
      "Episode:617 Reward:-2.096066756188404 \n",
      "\n",
      "total financial balance: (eur) -59732.640421809534 \n",
      "\n",
      "internal rate of return 585.6849985529199 \n",
      "\n",
      "net present value -38413.43498630838 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:618 Reward:-2.3039372643243943 \n",
      "\n",
      "total financial balance: (eur) -48920.80888759994 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -33700.341079123944 \n",
      "\n",
      "Episode:619 Reward:-2.551104627333383 \n",
      "\n",
      "total financial balance: (eur) -63876.6565471564 \n",
      "\n",
      "internal rate of return 368.2302397174008 \n",
      "\n",
      "net present value -42431.90424641134 \n",
      "\n",
      "Episode:620 Reward:-3.6180141387026015 \n",
      "\n",
      "total financial balance: (eur) -84318.56967394231 \n",
      "\n",
      "internal rate of return 1090.1935003986591 \n",
      "\n",
      "net present value -55366.040248475954 \n",
      "\n",
      "Episode:621 Reward:-0.3879278673697572 \n",
      "\n",
      "total financial balance: (eur) -33094.16412186809 \n",
      "\n",
      "internal rate of return -28.486471689100146 \n",
      "\n",
      "net present value -26024.024051368357 \n",
      "\n",
      "Episode:622 Reward:0.783553384818536 \n",
      "\n",
      "total financial balance: (eur) -44576.990328371365 \n",
      "\n",
      "internal rate of return -34.997950772712784 \n",
      "\n",
      "net present value -31464.775065826685 \n",
      "\n",
      "Episode:623 Reward:0.5140967328121405 \n",
      "\n",
      "total financial balance: (eur) -14919.825401565777 \n",
      "\n",
      "internal rate of return -9.125202569050295 \n",
      "\n",
      "net present value -13730.948235014654 \n",
      "\n",
      "Episode:624 Reward:-0.6432681068629672 \n",
      "\n",
      "total financial balance: (eur) -55168.964254523766 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -37301.22058503103 \n",
      "\n",
      "Episode:625 Reward:-5.0584347251001525 \n",
      "\n",
      "total financial balance: (eur) -92627.02168581777 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -55689.64249870559 \n",
      "\n",
      "Episode:626 Reward:-3.013346465622145 \n",
      "\n",
      "total financial balance: (eur) -66890.58298899797 \n",
      "\n",
      "internal rate of return 132.80800069216895 \n",
      "\n",
      "net present value -40245.91984961949 \n",
      "\n",
      "Episode:627 Reward:-0.5644122402269323 \n",
      "\n",
      "total financial balance: (eur) -50896.05190542 \n",
      "\n",
      "internal rate of return 1433.4740356039938 \n",
      "\n",
      "net present value -33885.69927338828 \n",
      "\n",
      "Episode:628 Reward:-2.961060154844666 \n",
      "\n",
      "total financial balance: (eur) -69688.20121105267 \n",
      "\n",
      "internal rate of return 148.47417618433906 \n",
      "\n",
      "net present value -43989.08024191775 \n",
      "\n",
      "Episode:629 Reward:-5.108811205570305 \n",
      "\n",
      "total financial balance: (eur) -85105.84029881269 \n",
      "\n",
      "internal rate of return 362.08391135962745 \n",
      "\n",
      "net present value -51547.408659123765 \n",
      "\n",
      "Episode:630 Reward:-1.460557899550866 \n",
      "\n",
      "total financial balance: (eur) -69339.97480684362 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -42819.29332349939 \n",
      "\n",
      "Episode:631 Reward:-2.9060654443048826 \n",
      "\n",
      "total financial balance: (eur) -75703.72791441107 \n",
      "\n",
      "internal rate of return 206.9560992490649 \n",
      "\n",
      "net present value -48545.54923003689 \n",
      "\n",
      "Episode:632 Reward:-2.5564028286604734 \n",
      "\n",
      "total financial balance: (eur) -67303.4048900741 \n",
      "\n",
      "internal rate of return 103.78135513835578 \n",
      "\n",
      "net present value -41093.663480182375 \n",
      "\n",
      "Episode:633 Reward:-3.7471161981280248 \n",
      "\n",
      "total financial balance: (eur) -63458.99133137663 \n",
      "\n",
      "internal rate of return 109.43072292358221 \n",
      "\n",
      "net present value -37786.3945606167 \n",
      "\n",
      "Episode:634 Reward:-4.043968449071534 \n",
      "\n",
      "total financial balance: (eur) -83607.57058856614 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -49786.96225866442 \n",
      "\n",
      "Episode:635 Reward:0.8960600505353141 \n",
      "\n",
      "total financial balance: (eur) -44943.96376829598 \n",
      "\n",
      "internal rate of return -16.476012788999217 \n",
      "\n",
      "net present value -35295.791701021044 \n",
      "\n",
      "Episode:636 Reward:-3.5831092027600064 \n",
      "\n",
      "total financial balance: (eur) -68588.15271914419 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -41509.740137246656 \n",
      "\n",
      "Episode:637 Reward:-4.561813036980715 \n",
      "\n",
      "total financial balance: (eur) -86650.21993670776 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -55694.185782863984 \n",
      "\n",
      "Episode:638 Reward:-3.340553558586294 \n",
      "\n",
      "total financial balance: (eur) -77459.70687524058 \n",
      "\n",
      "internal rate of return 1254.4857758405194 \n",
      "\n",
      "net present value -51547.71169229376 \n",
      "\n",
      "Episode:639 Reward:-2.280521497926974 \n",
      "\n",
      "total financial balance: (eur) -75487.83109285173 \n",
      "\n",
      "internal rate of return 606.7619683549381 \n",
      "\n",
      "net present value -49183.61169037499 \n",
      "\n",
      "Episode:640 Reward:-1.947593020318669 \n",
      "\n",
      "total financial balance: (eur) -55719.71876307399 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -34986.477786985 \n",
      "\n",
      "Episode:641 Reward:-2.7855921109150286 \n",
      "\n",
      "total financial balance: (eur) -66809.94456190772 \n",
      "\n",
      "internal rate of return 474.5252383148479 \n",
      "\n",
      "net present value -42290.521660947175 \n",
      "\n",
      "Episode:642 Reward:-2.036725758263815 \n",
      "\n",
      "total financial balance: (eur) -68633.68508902483 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -46844.12169670455 \n",
      "\n",
      "Episode:643 Reward:-2.690280290935838 \n",
      "\n",
      "total financial balance: (eur) -81592.4580090527 \n",
      "\n",
      "internal rate of return 153.96878505304764 \n",
      "\n",
      "net present value -50580.71469532855 \n",
      "\n",
      "Episode:644 Reward:0.7493201550143777 \n",
      "\n",
      "total financial balance: (eur) -30789.67280994731 \n",
      "\n",
      "internal rate of return -35.554805003628175 \n",
      "\n",
      "net present value -22385.575063464457 \n",
      "\n",
      "Episode:645 Reward:-1.5095450396988634 \n",
      "\n",
      "total financial balance: (eur) -35206.60253166944 \n",
      "\n",
      "internal rate of return 66.14738860036971 \n",
      "\n",
      "net present value -20312.732040314193 \n",
      "\n",
      "Episode:646 Reward:0.2914777163441486 \n",
      "\n",
      "total financial balance: (eur) -51505.10290354372 \n",
      "\n",
      "internal rate of return -86.0998094389121 \n",
      "\n",
      "net present value -35786.76039231067 \n",
      "\n",
      "Episode:647 Reward:-2.053515637945985 \n",
      "\n",
      "total financial balance: (eur) -59947.66027345642 \n",
      "\n",
      "internal rate of return 288.59238565067164 \n",
      "\n",
      "net present value -40486.81680257816 \n",
      "\n",
      "Episode:648 Reward:-1.775064480186314 \n",
      "\n",
      "total financial balance: (eur) -79893.8457973037 \n",
      "\n",
      "internal rate of return 729.6999958141232 \n",
      "\n",
      "net present value -55430.176431299835 \n",
      "\n",
      "Episode:649 Reward:0.3711467512064837 \n",
      "\n",
      "total financial balance: (eur) -61119.56155709211 \n",
      "\n",
      "internal rate of return -87.22162824854982 \n",
      "\n",
      "net present value -39801.04890585359 \n",
      "\n",
      "Episode:650 Reward:-3.763415378413368 \n",
      "\n",
      "total financial balance: (eur) -108059.68572055548 \n",
      "\n",
      "internal rate of return 797.9864066125913 \n",
      "\n",
      "net present value -66216.87275108906 \n",
      "\n",
      "Episode:651 Reward:0.3960244335191492 \n",
      "\n",
      "total financial balance: (eur) -60787.2301104607 \n",
      "\n",
      "internal rate of return -79.55678641862777 \n",
      "\n",
      "net present value -43679.520693053644 \n",
      "\n",
      "Episode:652 Reward:-2.725045777459396 \n",
      "\n",
      "total financial balance: (eur) -88679.88841592877 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -57547.45038982583 \n",
      "\n",
      "Episode:653 Reward:-3.1736781172720567 \n",
      "\n",
      "total financial balance: (eur) -68276.31758872219 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -44248.28223973143 \n",
      "\n",
      "Episode:654 Reward:-3.0824896384102978 \n",
      "\n",
      "total financial balance: (eur) -69543.74067827739 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -45767.68883835802 \n",
      "\n",
      "Episode:655 Reward:-3.826054235220491 \n",
      "\n",
      "total financial balance: (eur) -64078.94635445757 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -41694.64131389904 \n",
      "\n",
      "Episode:656 Reward:-1.6354590545440932 \n",
      "\n",
      "total financial balance: (eur) -40578.24600385424 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -25908.11586632124 \n",
      "\n",
      "Episode:657 Reward:-2.5712284547925592 \n",
      "\n",
      "total financial balance: (eur) -76011.87383715887 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -49342.18520031577 \n",
      "\n",
      "Episode:658 Reward:-3.669728241738786 \n",
      "\n",
      "total financial balance: (eur) -52079.597301560694 \n",
      "\n",
      "internal rate of return 423.1250725597417 \n",
      "\n",
      "net present value -32229.36947006429 \n",
      "\n",
      "Episode:659 Reward:-5.383848098036801 \n",
      "\n",
      "total financial balance: (eur) -104405.85026918966 \n",
      "\n",
      "internal rate of return 321.54189282038857 \n",
      "\n",
      "net present value -63712.36342419202 \n",
      "\n",
      "Episode:660 Reward:-1.7896135837508864 \n",
      "\n",
      "total financial balance: (eur) -59040.21252691677 \n",
      "\n",
      "internal rate of return 497.9534047392436 \n",
      "\n",
      "net present value -37932.62200046066 \n",
      "\n",
      "Episode:661 Reward:1.032062019455423 \n",
      "\n",
      "total financial balance: (eur) -61385.49051217876 \n",
      "\n",
      "internal rate of return -64.85788999847328 \n",
      "\n",
      "net present value -40178.970394037264 \n",
      "\n",
      "Episode:662 Reward:-1.5880408756586895 \n",
      "\n",
      "total financial balance: (eur) -74854.79896164616 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -47242.885243911216 \n",
      "\n",
      "Episode:663 Reward:-0.9076667185150536 \n",
      "\n",
      "total financial balance: (eur) -41161.547142625255 \n",
      "\n",
      "internal rate of return 356.1784840507813 \n",
      "\n",
      "net present value -26807.62140525685 \n",
      "\n",
      "Episode:664 Reward:-3.4314235315763706 \n",
      "\n",
      "total financial balance: (eur) -89283.1850757884 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -55174.66820032845 \n",
      "\n",
      "Episode:665 Reward:-2.140404786411639 \n",
      "\n",
      "total financial balance: (eur) -78406.73956089554 \n",
      "\n",
      "internal rate of return 1071.0549172133224 \n",
      "\n",
      "net present value -51047.59912042896 \n",
      "\n",
      "Episode:666 Reward:-1.769582311445385 \n",
      "\n",
      "total financial balance: (eur) -73060.7247336309 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -48218.103659744054 \n",
      "\n",
      "Episode:667 Reward:-2.999648957476163 \n",
      "\n",
      "total financial balance: (eur) -73344.54507974918 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -46004.76556253744 \n",
      "\n",
      "Episode:668 Reward:-2.8916971893255177 \n",
      "\n",
      "total financial balance: (eur) -59621.500762193886 \n",
      "\n",
      "internal rate of return 259.7184860755785 \n",
      "\n",
      "net present value -34909.86705838193 \n",
      "\n",
      "Episode:669 Reward:-4.002316778041274 \n",
      "\n",
      "total financial balance: (eur) -106326.79604593203 \n",
      "\n",
      "internal rate of return 220.24336946207052 \n",
      "\n",
      "net present value -64896.145058528666 \n",
      "\n",
      "Episode:670 Reward:4.191761494246865 \n",
      "\n",
      "total financial balance: (eur) -23264.160735215675 \n",
      "\n",
      "internal rate of return -8.561443210189578 \n",
      "\n",
      "net present value -20120.169263769734 \n",
      "\n",
      "Episode:671 Reward:-3.6046901121962898 \n",
      "\n",
      "total financial balance: (eur) -80060.95263098639 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -50540.3819253796 \n",
      "\n",
      "Episode:672 Reward:-1.946648942122377 \n",
      "\n",
      "total financial balance: (eur) -45522.71919618073 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -29835.27508950918 \n",
      "\n",
      "Episode:673 Reward:-3.602399435295118 \n",
      "\n",
      "total financial balance: (eur) -105445.57573553821 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -67463.50735358238 \n",
      "\n",
      "Episode:674 Reward:-1.251737102382136 \n",
      "\n",
      "total financial balance: (eur) -54790.67007490636 \n",
      "\n",
      "internal rate of return 122.90718098085986 \n",
      "\n",
      "net present value -33055.9582179559 \n",
      "\n",
      "Episode:675 Reward:-1.0860279177788044 \n",
      "\n",
      "total financial balance: (eur) -84896.41059554988 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -54934.872692711215 \n",
      "\n",
      "Episode:676 Reward:3.1144710957764845 \n",
      "\n",
      "total financial balance: (eur) -25972.804070309932 \n",
      "\n",
      "internal rate of return -13.856020948882819 \n",
      "\n",
      "net present value -19592.95455308141 \n",
      "\n",
      "Episode:677 Reward:-2.968498068863038 \n",
      "\n",
      "total financial balance: (eur) -88931.389859327 \n",
      "\n",
      "internal rate of return 252.6253549059592 \n",
      "\n",
      "net present value -53921.52863367931 \n",
      "\n",
      "Episode:678 Reward:0.4465594311323202 \n",
      "\n",
      "total financial balance: (eur) -30131.830593364168 \n",
      "\n",
      "internal rate of return -11.989796130542206 \n",
      "\n",
      "net present value -24587.16651586849 \n",
      "\n",
      "Episode:679 Reward:-0.1814446601504096 \n",
      "\n",
      "total financial balance: (eur) -52686.946934464686 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -36683.80491115835 \n",
      "\n",
      "Episode:680 Reward:-4.34705427670469 \n",
      "\n",
      "total financial balance: (eur) -84316.10162414995 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -53789.00194703284 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:681 Reward:-2.823242668212647 \n",
      "\n",
      "total financial balance: (eur) -68883.07574173775 \n",
      "\n",
      "internal rate of return 410.79404321639777 \n",
      "\n",
      "net present value -44005.08802919526 \n",
      "\n",
      "Episode:682 Reward:-3.0936849236483086 \n",
      "\n",
      "total financial balance: (eur) -63432.52146988335 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -40511.38379510402 \n",
      "\n",
      "Episode:683 Reward:-3.235665418854551 \n",
      "\n",
      "total financial balance: (eur) -83466.78262179917 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -52931.90007027454 \n",
      "\n",
      "Episode:684 Reward:-2.7758542782503475 \n",
      "\n",
      "total financial balance: (eur) -64419.9732504692 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -42152.66294893468 \n",
      "\n",
      "Episode:685 Reward:-1.7908426296537372 \n",
      "\n",
      "total financial balance: (eur) -70008.95814650707 \n",
      "\n",
      "internal rate of return 486.6640071247666 \n",
      "\n",
      "net present value -46428.20844799044 \n",
      "\n",
      "Episode:686 Reward:-1.3684758566191995 \n",
      "\n",
      "total financial balance: (eur) -51986.23064313058 \n",
      "\n",
      "internal rate of return 1735.993139432695 \n",
      "\n",
      "net present value -34392.571393223545 \n",
      "\n",
      "Episode:687 Reward:-2.632810840259484 \n",
      "\n",
      "total financial balance: (eur) -79196.41478199304 \n",
      "\n",
      "internal rate of return 214.94485684375599 \n",
      "\n",
      "net present value -48614.772057619804 \n",
      "\n",
      "Episode:688 Reward:-2.882725400660377 \n",
      "\n",
      "total financial balance: (eur) -46410.41962321904 \n",
      "\n",
      "internal rate of return 91.4754622632131 \n",
      "\n",
      "net present value -27119.224389131046 \n",
      "\n",
      "Episode:689 Reward:-2.3768169071621235 \n",
      "\n",
      "total financial balance: (eur) -52628.92163141656 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -32555.3601394652 \n",
      "\n",
      "Episode:690 Reward:0.044287363702275345 \n",
      "\n",
      "total financial balance: (eur) -79020.62383544125 \n",
      "\n",
      "internal rate of return -98.76866856452904 \n",
      "\n",
      "net present value -51456.33834655651 \n",
      "\n",
      "Episode:691 Reward:-0.37382208534166966 \n",
      "\n",
      "total financial balance: (eur) -46519.08660723947 \n",
      "\n",
      "internal rate of return 203.68711789341307 \n",
      "\n",
      "net present value -30481.435065640693 \n",
      "\n",
      "Episode:692 Reward:-1.7285591964464047 \n",
      "\n",
      "total financial balance: (eur) -66255.50301112642 \n",
      "\n",
      "internal rate of return 344.43450418130385 \n",
      "\n",
      "net present value -44833.64004822864 \n",
      "\n",
      "Episode:693 Reward:3.942145895307538 \n",
      "\n",
      "total financial balance: (eur) 24709.22319628129 \n",
      "\n",
      "internal rate of return 9.493729193519652 \n",
      "\n",
      "net present value 8416.148027667008 \n",
      "\n",
      "Episode:694 Reward:-1.9286014188081817 \n",
      "\n",
      "total financial balance: (eur) -74401.73801964415 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -46961.8667953208 \n",
      "\n",
      "Episode:695 Reward:0.38135632905475175 \n",
      "\n",
      "total financial balance: (eur) -49192.923753571304 \n",
      "\n",
      "internal rate of return -36.9899465260317 \n",
      "\n",
      "net present value -32637.125125002898 \n",
      "\n",
      "Episode:696 Reward:-2.313528075693278 \n",
      "\n",
      "total financial balance: (eur) -65168.147209212475 \n",
      "\n",
      "internal rate of return 258.76674821838037 \n",
      "\n",
      "net present value -42284.0552849197 \n",
      "\n",
      "Episode:697 Reward:-3.4275396783914376 \n",
      "\n",
      "total financial balance: (eur) -79882.81924904237 \n",
      "\n",
      "internal rate of return 329.80979761721915 \n",
      "\n",
      "net present value -50701.08560526469 \n",
      "\n",
      "Episode:698 Reward:-2.5165674072478867 \n",
      "\n",
      "total financial balance: (eur) -58856.77667455891 \n",
      "\n",
      "internal rate of return 335.8705986656708 \n",
      "\n",
      "net present value -35751.46501772713 \n",
      "\n",
      "Episode:699 Reward:1.1203837639168555 \n",
      "\n",
      "total financial balance: (eur) -64830.23905955017 \n",
      "\n",
      "internal rate of return -50.790654646440245 \n",
      "\n",
      "net present value -44131.34471349239 \n",
      "\n",
      "Episode:700 Reward:-2.7283508986899543 \n",
      "\n",
      "total financial balance: (eur) -57946.16271976006 \n",
      "\n",
      "internal rate of return 326.54965660298984 \n",
      "\n",
      "net present value -38581.94513714174 \n",
      "\n",
      "Episode:701 Reward:-4.535666002783473 \n",
      "\n",
      "total financial balance: (eur) -96606.22136960574 \n",
      "\n",
      "internal rate of return 2206.788643994788 \n",
      "\n",
      "net present value -62435.24706900085 \n",
      "\n",
      "Episode:702 Reward:-3.3291228852886943 \n",
      "\n",
      "total financial balance: (eur) -85467.14994043649 \n",
      "\n",
      "internal rate of return 248.14088185401334 \n",
      "\n",
      "net present value -52959.721711884864 \n",
      "\n",
      "Episode:703 Reward:-0.7888437906178105 \n",
      "\n",
      "total financial balance: (eur) -64394.53571518076 \n",
      "\n",
      "internal rate of return 725.2369764489275 \n",
      "\n",
      "net present value -41958.690095822305 \n",
      "\n",
      "Episode:704 Reward:-2.141971452007396 \n",
      "\n",
      "total financial balance: (eur) -62090.855314220906 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -39629.03391735018 \n",
      "\n",
      "Episode:705 Reward:5.659620562580416 \n",
      "\n",
      "total financial balance: (eur) -34777.52483796577 \n",
      "\n",
      "internal rate of return -8.139431560211197 \n",
      "\n",
      "net present value -30646.796154388518 \n",
      "\n",
      "Episode:706 Reward:3.2719692749787717 \n",
      "\n",
      "total financial balance: (eur) -12747.060487532226 \n",
      "\n",
      "internal rate of return -4.976498518660044 \n",
      "\n",
      "net present value -13097.161867162386 \n",
      "\n",
      "Episode:707 Reward:-3.7940999705108305 \n",
      "\n",
      "total financial balance: (eur) -82639.81760513784 \n",
      "\n",
      "internal rate of return 213.86251460081274 \n",
      "\n",
      "net present value -54011.390059451835 \n",
      "\n",
      "Episode:708 Reward:-3.0676377466695617 \n",
      "\n",
      "total financial balance: (eur) -67899.2116283594 \n",
      "\n",
      "internal rate of return 127.20517453262113 \n",
      "\n",
      "net present value -41682.03377783853 \n",
      "\n",
      "Episode:709 Reward:0.7828068076370482 \n",
      "\n",
      "total financial balance: (eur) -32979.650784548954 \n",
      "\n",
      "internal rate of return -22.97785742005174 \n",
      "\n",
      "net present value -24649.60056267637 \n",
      "\n",
      "Episode:710 Reward:-4.276790029289216 \n",
      "\n",
      "total financial balance: (eur) -67258.16653342711 \n",
      "\n",
      "internal rate of return 197.33148955932919 \n",
      "\n",
      "net present value -41945.923506179985 \n",
      "\n",
      "Episode:711 Reward:0.26568185144430756 \n",
      "\n",
      "total financial balance: (eur) -32039.797370392578 \n",
      "\n",
      "internal rate of return -68.0189492790384 \n",
      "\n",
      "net present value -21364.071104622304 \n",
      "\n",
      "Episode:712 Reward:-4.375650206250431 \n",
      "\n",
      "total financial balance: (eur) -81333.53539880329 \n",
      "\n",
      "internal rate of return 388.8162537907723 \n",
      "\n",
      "net present value -49943.208105228696 \n",
      "\n",
      "Episode:713 Reward:-0.8921486395499278 \n",
      "\n",
      "total financial balance: (eur) -51090.97954092383 \n",
      "\n",
      "internal rate of return 790.6490753105184 \n",
      "\n",
      "net present value -36307.292381366584 \n",
      "\n",
      "Episode:714 Reward:2.281144062839315 \n",
      "\n",
      "total financial balance: (eur) -18240.503477723036 \n",
      "\n",
      "internal rate of return -7.030443626639904 \n",
      "\n",
      "net present value -17659.85236131178 \n",
      "\n",
      "Episode:715 Reward:-3.0533330928989 \n",
      "\n",
      "total financial balance: (eur) -89448.46224734095 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -56055.17747147095 \n",
      "\n",
      "Episode:716 Reward:-2.6626035452766663 \n",
      "\n",
      "total financial balance: (eur) -64333.33598897041 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -41460.7383992418 \n",
      "\n",
      "Episode:717 Reward:-0.598310801882606 \n",
      "\n",
      "total financial balance: (eur) -77050.7138609353 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -51319.7360943124 \n",
      "\n",
      "Episode:718 Reward:-1.8131198900796008 \n",
      "\n",
      "total financial balance: (eur) -54959.729897547804 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -34843.2827826309 \n",
      "\n",
      "Episode:719 Reward:-3.974508966592494 \n",
      "\n",
      "total financial balance: (eur) -84806.19058298599 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -51840.82147108534 \n",
      "\n",
      "Episode:720 Reward:-2.590339864710191 \n",
      "\n",
      "total financial balance: (eur) -75467.10422434064 \n",
      "\n",
      "internal rate of return 373.03538245567324 \n",
      "\n",
      "net present value -46291.97382645243 \n",
      "\n",
      "Episode:721 Reward:-3.654844913487915 \n",
      "\n",
      "total financial balance: (eur) -91432.77440528263 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -57084.5271843766 \n",
      "\n",
      "Episode:722 Reward:5.171390105152332 \n",
      "\n",
      "total financial balance: (eur) -15786.828667102662 \n",
      "\n",
      "internal rate of return -5.390340952388062 \n",
      "\n",
      "net present value -15888.268967769021 \n",
      "\n",
      "Episode:723 Reward:-1.4130596746008242 \n",
      "\n",
      "total financial balance: (eur) -60849.74272547615 \n",
      "\n",
      "internal rate of return 47188.806803521795 \n",
      "\n",
      "net present value -42087.236665767305 \n",
      "\n",
      "Episode:724 Reward:-0.14752201876716664 \n",
      "\n",
      "total financial balance: (eur) -55213.72147193925 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -37444.2244280283 \n",
      "\n",
      "Episode:725 Reward:1.0285513372559554 \n",
      "\n",
      "total financial balance: (eur) -26348.32180456735 \n",
      "\n",
      "internal rate of return -52.242181661961794 \n",
      "\n",
      "net present value -17443.221942014123 \n",
      "\n",
      "Episode:726 Reward:-1.8019742073697134 \n",
      "\n",
      "total financial balance: (eur) -70854.61563497937 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -48094.50494271341 \n",
      "\n",
      "Episode:727 Reward:-0.2685232717158533 \n",
      "\n",
      "total financial balance: (eur) -74936.90286998646 \n",
      "\n",
      "internal rate of return 321.06879619043616 \n",
      "\n",
      "net present value -49225.46980796331 \n",
      "\n",
      "Episode:728 Reward:-3.894901234541946 \n",
      "\n",
      "total financial balance: (eur) -106268.2079478471 \n",
      "\n",
      "internal rate of return 467.20137117368836 \n",
      "\n",
      "net present value -68048.34926735803 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:729 Reward:-1.3536237983113961 \n",
      "\n",
      "total financial balance: (eur) -75020.5439487486 \n",
      "\n",
      "internal rate of return 1409.433905189709 \n",
      "\n",
      "net present value -48423.78606385318 \n",
      "\n",
      "Episode:730 Reward:-0.7027672013114743 \n",
      "\n",
      "total financial balance: (eur) -66767.92340678237 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -44406.47737018821 \n",
      "\n",
      "Episode:731 Reward:-0.42186891328656384 \n",
      "\n",
      "total financial balance: (eur) -78062.9033947984 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -53492.2373859505 \n",
      "\n",
      "Episode:732 Reward:0.7878879809921328 \n",
      "\n",
      "total financial balance: (eur) -36450.24728877865 \n",
      "\n",
      "internal rate of return -15.93251676723474 \n",
      "\n",
      "net present value -27022.20694530585 \n",
      "\n",
      "Episode:733 Reward:-1.8142180066029223 \n",
      "\n",
      "total financial balance: (eur) -54769.239480070064 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -36615.8889155285 \n",
      "\n",
      "Episode:734 Reward:1.2685771098410696 \n",
      "\n",
      "total financial balance: (eur) -34733.694625004864 \n",
      "\n",
      "internal rate of return -38.99419717315293 \n",
      "\n",
      "net present value -25345.089813082745 \n",
      "\n",
      "Episode:735 Reward:-3.7479401699048522 \n",
      "\n",
      "total financial balance: (eur) -110605.88165057106 \n",
      "\n",
      "internal rate of return 326.52016705303026 \n",
      "\n",
      "net present value -69742.27938992318 \n",
      "\n",
      "Episode:736 Reward:-4.047225956463 \n",
      "\n",
      "total financial balance: (eur) -92907.0506252276 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -57309.92689152161 \n",
      "\n",
      "Episode:737 Reward:0.03635366371366945 \n",
      "\n",
      "total financial balance: (eur) -16245.119932139749 \n",
      "\n",
      "internal rate of return -5.57223297276892 \n",
      "\n",
      "net present value -17657.08720909967 \n",
      "\n",
      "Episode:738 Reward:-2.107717381302404 \n",
      "\n",
      "total financial balance: (eur) -61112.26125871684 \n",
      "\n",
      "internal rate of return 88.65696922313164 \n",
      "\n",
      "net present value -39820.05769886426 \n",
      "\n",
      "Episode:739 Reward:-0.4004971075011372 \n",
      "\n",
      "total financial balance: (eur) -75057.96525012117 \n",
      "\n",
      "internal rate of return 1566.8363647910926 \n",
      "\n",
      "net present value -51343.48764791264 \n",
      "\n",
      "Episode:740 Reward:-2.809824812248382 \n",
      "\n",
      "total financial balance: (eur) -71564.29114007657 \n",
      "\n",
      "internal rate of return 1825.5037143634027 \n",
      "\n",
      "net present value -46259.94365952611 \n",
      "\n",
      "Episode:741 Reward:-1.265563792127079 \n",
      "\n",
      "total financial balance: (eur) -66409.21065440579 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -45987.35531178258 \n",
      "\n",
      "Episode:742 Reward:-3.2825739612947573 \n",
      "\n",
      "total financial balance: (eur) -67733.47395360413 \n",
      "\n",
      "internal rate of return 352.67299958089825 \n",
      "\n",
      "net present value -44132.43374377094 \n",
      "\n",
      "Episode:743 Reward:-2.9609217475113208 \n",
      "\n",
      "total financial balance: (eur) -67785.9758754192 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -43625.106303800625 \n",
      "\n",
      "Episode:744 Reward:-3.2294622426232475 \n",
      "\n",
      "total financial balance: (eur) -22442.718330223695 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -10116.780916994372 \n",
      "\n",
      "Episode:745 Reward:-4.377751687223623 \n",
      "\n",
      "total financial balance: (eur) -69353.63619403436 \n",
      "\n",
      "internal rate of return 426.84109967243114 \n",
      "\n",
      "net present value -42602.41970895025 \n",
      "\n",
      "Episode:746 Reward:-0.13684480013645317 \n",
      "\n",
      "total financial balance: (eur) -83009.91592925992 \n",
      "\n",
      "internal rate of return 782.1254444400839 \n",
      "\n",
      "net present value -53945.6891115857 \n",
      "\n",
      "Episode:747 Reward:-0.4730211504549197 \n",
      "\n",
      "total financial balance: (eur) -37622.08226416969 \n",
      "\n",
      "internal rate of return 122.55497821100118 \n",
      "\n",
      "net present value -26310.578699345366 \n",
      "\n",
      "Episode:748 Reward:-0.7809753514246904 \n",
      "\n",
      "total financial balance: (eur) -37407.47285184921 \n",
      "\n",
      "internal rate of return 2670.842440830889 \n",
      "\n",
      "net present value -26570.81442825352 \n",
      "\n",
      "Episode:749 Reward:-4.093888770409107 \n",
      "\n",
      "total financial balance: (eur) -66775.05945143179 \n",
      "\n",
      "internal rate of return 123.33918354019117 \n",
      "\n",
      "net present value -39239.25419493408 \n",
      "\n",
      "Episode:750 Reward:4.238521233887748 \n",
      "\n",
      "total financial balance: (eur) -26716.166105119984 \n",
      "\n",
      "internal rate of return -9.808528563707043 \n",
      "\n",
      "net present value -21362.599164290234 \n",
      "\n",
      "Episode:751 Reward:2.3587761425222333 \n",
      "\n",
      "total financial balance: (eur) -2541.3274258925903 \n",
      "\n",
      "internal rate of return -0.7400571829202951 \n",
      "\n",
      "net present value -10210.298257475235 \n",
      "\n",
      "Episode:752 Reward:3.6322808311519648 \n",
      "\n",
      "total financial balance: (eur) -11619.620511895162 \n",
      "\n",
      "internal rate of return -3.5830075986176713 \n",
      "\n",
      "net present value -15214.149632571165 \n",
      "\n",
      "Episode:753 Reward:-1.0857780506777635 \n",
      "\n",
      "total financial balance: (eur) -43784.24710540379 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -33563.080479729455 \n",
      "\n",
      "Episode:754 Reward:-2.4290086077646325 \n",
      "\n",
      "total financial balance: (eur) -69775.59856635003 \n",
      "\n",
      "internal rate of return 220.89774976741072 \n",
      "\n",
      "net present value -43068.185566505745 \n",
      "\n",
      "Episode:755 Reward:-1.431838356957278 \n",
      "\n",
      "total financial balance: (eur) -71429.25167516788 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -45662.783972387486 \n",
      "\n",
      "Episode:756 Reward:-2.139502946045105 \n",
      "\n",
      "total financial balance: (eur) -61505.53653979961 \n",
      "\n",
      "internal rate of return 496.8692817720823 \n",
      "\n",
      "net present value -40437.50567625337 \n",
      "\n",
      "Episode:757 Reward:0.9417313713368695 \n",
      "\n",
      "total financial balance: (eur) -27635.283609181024 \n",
      "\n",
      "internal rate of return -20.561640243380452 \n",
      "\n",
      "net present value -19908.063192929156 \n",
      "\n",
      "Episode:758 Reward:-2.740345125639592 \n",
      "\n",
      "total financial balance: (eur) -80993.89205497134 \n",
      "\n",
      "internal rate of return 559.307800291322 \n",
      "\n",
      "net present value -52093.442003957716 \n",
      "\n",
      "Episode:759 Reward:-3.074862089981522 \n",
      "\n",
      "total financial balance: (eur) -67838.83933885948 \n",
      "\n",
      "internal rate of return 126.21269352602708 \n",
      "\n",
      "net present value -39898.597129829366 \n",
      "\n",
      "Episode:760 Reward:2.2497744273071696 \n",
      "\n",
      "total financial balance: (eur) -6682.005011190544 \n",
      "\n",
      "internal rate of return -2.514789612020507 \n",
      "\n",
      "net present value -10364.65770134125 \n",
      "\n",
      "Episode:761 Reward:0.888191479781166 \n",
      "\n",
      "total financial balance: (eur) -30298.766476570952 \n",
      "\n",
      "internal rate of return -29.077139120698792 \n",
      "\n",
      "net present value -21910.28061333692 \n",
      "\n",
      "Episode:762 Reward:-1.5871981392455965 \n",
      "\n",
      "total financial balance: (eur) -61130.08074026507 \n",
      "\n",
      "internal rate of return 110.40799525063835 \n",
      "\n",
      "net present value -36986.34065621183 \n",
      "\n",
      "Episode:763 Reward:-4.810678309013927 \n",
      "\n",
      "total financial balance: (eur) -65633.49302960608 \n",
      "\n",
      "internal rate of return 205.66882008335563 \n",
      "\n",
      "net present value -37746.93792963291 \n",
      "\n",
      "Episode:764 Reward:-0.7202225250826341 \n",
      "\n",
      "total financial balance: (eur) -44065.91229153631 \n",
      "\n",
      "internal rate of return 82.9396012779197 \n",
      "\n",
      "net present value -27984.442430505344 \n",
      "\n",
      "Episode:765 Reward:-2.8533125579145797 \n",
      "\n",
      "total financial balance: (eur) -66558.2772184622 \n",
      "\n",
      "internal rate of return 135.6390531791269 \n",
      "\n",
      "net present value -42525.09684765356 \n",
      "\n",
      "Episode:766 Reward:-0.43936455772542743 \n",
      "\n",
      "total financial balance: (eur) -67391.78815068242 \n",
      "\n",
      "internal rate of return 198.39921918245346 \n",
      "\n",
      "net present value -43155.53062569172 \n",
      "\n",
      "Episode:767 Reward:-1.975525184163399 \n",
      "\n",
      "total financial balance: (eur) -47070.68692770194 \n",
      "\n",
      "internal rate of return 337.53871120412066 \n",
      "\n",
      "net present value -28969.805058639362 \n",
      "\n",
      "Episode:768 Reward:-2.144028466973872 \n",
      "\n",
      "total financial balance: (eur) -47901.76309637228 \n",
      "\n",
      "internal rate of return 81.01927458961381 \n",
      "\n",
      "net present value -30546.707075118953 \n",
      "\n",
      "Episode:769 Reward:-1.953479675795018 \n",
      "\n",
      "total financial balance: (eur) -60440.71681627344 \n",
      "\n",
      "internal rate of return 337.88872289841345 \n",
      "\n",
      "net present value -39362.601313415544 \n",
      "\n",
      "Episode:770 Reward:0.054742652570268543 \n",
      "\n",
      "total financial balance: (eur) -25077.139762414008 \n",
      "\n",
      "internal rate of return -93.67929909359832 \n",
      "\n",
      "net present value -18488.782326447727 \n",
      "\n",
      "Episode:771 Reward:-1.7834296131352347 \n",
      "\n",
      "total financial balance: (eur) -77404.98377383496 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -52137.27698897648 \n",
      "\n",
      "Episode:772 Reward:-0.9213560091684694 \n",
      "\n",
      "total financial balance: (eur) -77271.55525679197 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -49549.18129452559 \n",
      "\n",
      "Episode:773 Reward:-0.19216318292644427 \n",
      "\n",
      "total financial balance: (eur) -26080.31180452135 \n",
      "\n",
      "internal rate of return 230.7169537248315 \n",
      "\n",
      "net present value -21260.25086606135 \n",
      "\n",
      "Episode:774 Reward:1.810236541774686 \n",
      "\n",
      "total financial balance: (eur) -31358.906115757876 \n",
      "\n",
      "internal rate of return -16.000291493256146 \n",
      "\n",
      "net present value -24436.50758298845 \n",
      "\n",
      "Episode:775 Reward:-2.620046126117947 \n",
      "\n",
      "total financial balance: (eur) -68889.4130967664 \n",
      "\n",
      "internal rate of return 332.3444454035616 \n",
      "\n",
      "net present value -45395.664267973676 \n",
      "\n",
      "Episode:776 Reward:-2.218611585101572 \n",
      "\n",
      "total financial balance: (eur) -63060.46182062312 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -43737.69393354967 \n",
      "\n",
      "Episode:777 Reward:-0.5557791445273924 \n",
      "\n",
      "total financial balance: (eur) -86034.05715711405 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -57007.41932952156 \n",
      "\n",
      "Episode:778 Reward:-3.619588286696194 \n",
      "\n",
      "total financial balance: (eur) -78639.43837611817 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -46617.80201458998 \n",
      "\n",
      "Episode:779 Reward:1.390584723429116 \n",
      "\n",
      "total financial balance: (eur) -29852.934054778918 \n",
      "\n",
      "internal rate of return -9.677282616851347 \n",
      "\n",
      "net present value -26929.545511154072 \n",
      "\n",
      "Episode:780 Reward:-1.6538216255447478 \n",
      "\n",
      "total financial balance: (eur) -85501.77950728641 \n",
      "\n",
      "internal rate of return 2110.5230514748855 \n",
      "\n",
      "net present value -56113.34817619112 \n",
      "\n",
      "Episode:781 Reward:1.1626482607355948 \n",
      "\n",
      "total financial balance: (eur) -32763.013832323602 \n",
      "\n",
      "internal rate of return -35.33808363682037 \n",
      "\n",
      "net present value -23678.366309878707 \n",
      "\n",
      "Episode:782 Reward:-4.212186658125462 \n",
      "\n",
      "total financial balance: (eur) -91647.27089379862 \n",
      "\n",
      "internal rate of return 256.64763757136535 \n",
      "\n",
      "net present value -55364.320014535726 \n",
      "\n",
      "Episode:783 Reward:-2.8520245189512368 \n",
      "\n",
      "total financial balance: (eur) -85228.67041026967 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -57357.12759109446 \n",
      "\n",
      "Episode:784 Reward:-5.8559242440391825 \n",
      "\n",
      "total financial balance: (eur) -79713.28315515917 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -47243.05446904035 \n",
      "\n",
      "Episode:785 Reward:-5.479529885674549 \n",
      "\n",
      "total financial balance: (eur) -105192.83449504348 \n",
      "\n",
      "internal rate of return 360.8194491918883 \n",
      "\n",
      "net present value -65845.47918807724 \n",
      "\n",
      "Episode:786 Reward:-2.497145004790965 \n",
      "\n",
      "total financial balance: (eur) -80243.68659042889 \n",
      "\n",
      "internal rate of return 301.34617410050157 \n",
      "\n",
      "net present value -52851.23440641068 \n",
      "\n",
      "Episode:787 Reward:-4.631360052894764 \n",
      "\n",
      "total financial balance: (eur) -99676.55020277556 \n",
      "\n",
      "internal rate of return 288.9647077107634 \n",
      "\n",
      "net present value -63265.6686861402 \n",
      "\n",
      "Episode:788 Reward:-2.634638827929928 \n",
      "\n",
      "total financial balance: (eur) -69849.21536174013 \n",
      "\n",
      "internal rate of return 338.6953266418086 \n",
      "\n",
      "net present value -44068.05960897529 \n",
      "\n",
      "Episode:789 Reward:-1.7373353457047416 \n",
      "\n",
      "total financial balance: (eur) -55147.69588408113 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -36951.25041578272 \n",
      "\n",
      "Episode:790 Reward:-2.5179179594459655 \n",
      "\n",
      "total financial balance: (eur) -75338.83095155015 \n",
      "\n",
      "internal rate of return 261.65627267812374 \n",
      "\n",
      "net present value -47694.304205826134 \n",
      "\n",
      "Episode:791 Reward:-2.1058909903233864 \n",
      "\n",
      "total financial balance: (eur) -84874.86202050932 \n",
      "\n",
      "internal rate of return 461.2511025921781 \n",
      "\n",
      "net present value -52386.29680300063 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:792 Reward:-4.154257095272989 \n",
      "\n",
      "total financial balance: (eur) -61199.3048824905 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -35742.04483351731 \n",
      "\n",
      "Episode:793 Reward:-2.4519036068096582 \n",
      "\n",
      "total financial balance: (eur) -62472.45683836631 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -39548.56178125037 \n",
      "\n",
      "Episode:794 Reward:-2.0334004601847426 \n",
      "\n",
      "total financial balance: (eur) -57247.46562210876 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -36847.60280538247 \n",
      "\n",
      "Episode:795 Reward:-0.8984470062947348 \n",
      "\n",
      "total financial balance: (eur) -44330.24487713377 \n",
      "\n",
      "internal rate of return 356.27516435264255 \n",
      "\n",
      "net present value -34362.073594987836 \n",
      "\n",
      "Episode:796 Reward:-2.4864149707213272 \n",
      "\n",
      "total financial balance: (eur) -83715.05352952692 \n",
      "\n",
      "internal rate of return 119.55702804748012 \n",
      "\n",
      "net present value -53278.073632429216 \n",
      "\n",
      "Episode:797 Reward:-2.0989112667634107 \n",
      "\n",
      "total financial balance: (eur) -73590.42249867614 \n",
      "\n",
      "internal rate of return 114.2451774062387 \n",
      "\n",
      "net present value -46172.74112825408 \n",
      "\n",
      "Episode:798 Reward:-1.827346013330448 \n",
      "\n",
      "total financial balance: (eur) -67602.74480445399 \n",
      "\n",
      "internal rate of return 160.08187190210114 \n",
      "\n",
      "net present value -43822.9558277085 \n",
      "\n",
      "Episode:799 Reward:-3.042116615743038 \n",
      "\n",
      "total financial balance: (eur) -73280.84190878629 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -48250.453713480216 \n",
      "\n",
      "Episode:800 Reward:-3.411735653858531 \n",
      "\n",
      "total financial balance: (eur) -70348.67181376359 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -43961.33108663411 \n",
      "\n",
      "Episode:801 Reward:-1.1880871198189442 \n",
      "\n",
      "total financial balance: (eur) -51970.157717868686 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -35728.9532816385 \n",
      "\n",
      "Episode:802 Reward:-2.9452217382328563 \n",
      "\n",
      "total financial balance: (eur) -81450.1627399122 \n",
      "\n",
      "internal rate of return 550.9131569897968 \n",
      "\n",
      "net present value -49361.006527596735 \n",
      "\n",
      "Episode:803 Reward:-2.6805416929526875 \n",
      "\n",
      "total financial balance: (eur) -75131.14178923075 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -49350.41443146975 \n",
      "\n",
      "Episode:804 Reward:-1.6336262324106956 \n",
      "\n",
      "total financial balance: (eur) -57548.792578051485 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -41302.19650425627 \n",
      "\n",
      "Episode:805 Reward:-3.518099668070395 \n",
      "\n",
      "total financial balance: (eur) -92653.81633214996 \n",
      "\n",
      "internal rate of return 5559.922892904124 \n",
      "\n",
      "net present value -57192.30099139394 \n",
      "\n",
      "Episode:806 Reward:3.441324945101722 \n",
      "\n",
      "total financial balance: (eur) -20105.06730179029 \n",
      "\n",
      "internal rate of return -6.304488594514335 \n",
      "\n",
      "net present value -19723.97755385554 \n",
      "\n",
      "Episode:807 Reward:1.2073068457037253 \n",
      "\n",
      "total financial balance: (eur) -58983.435795583966 \n",
      "\n",
      "internal rate of return -34.21808001781075 \n",
      "\n",
      "net present value -41125.63647841425 \n",
      "\n",
      "Episode:808 Reward:-5.537640385438944 \n",
      "\n",
      "total financial balance: (eur) -66960.4744706935 \n",
      "\n",
      "internal rate of return 177.6361483497785 \n",
      "\n",
      "net present value -39375.4776360616 \n",
      "\n",
      "Episode:809 Reward:-2.8416335950396223 \n",
      "\n",
      "total financial balance: (eur) -74786.75789614304 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -45822.83398992718 \n",
      "\n",
      "Episode:810 Reward:1.2789478273959949 \n",
      "\n",
      "total financial balance: (eur) -30142.23819111699 \n",
      "\n",
      "internal rate of return -16.591115589408535 \n",
      "\n",
      "net present value -23017.507355879676 \n",
      "\n",
      "Episode:811 Reward:-0.7851024946646076 \n",
      "\n",
      "total financial balance: (eur) -68133.70501616843 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -47249.83860102684 \n",
      "\n",
      "Episode:812 Reward:-4.0990239224344736 \n",
      "\n",
      "total financial balance: (eur) -50207.50104471159 \n",
      "\n",
      "internal rate of return 140.98021850407233 \n",
      "\n",
      "net present value -29804.161319427876 \n",
      "\n",
      "Episode:813 Reward:-4.364694551518582 \n",
      "\n",
      "total financial balance: (eur) -118654.50321581573 \n",
      "\n",
      "internal rate of return 699.463887712629 \n",
      "\n",
      "net present value -76593.86719455756 \n",
      "\n",
      "Episode:814 Reward:-2.59245267484302 \n",
      "\n",
      "total financial balance: (eur) -42473.99773353656 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -28093.307086821427 \n",
      "\n",
      "Episode:815 Reward:-2.939832417252129 \n",
      "\n",
      "total financial balance: (eur) -47977.77265078638 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -33333.09829225342 \n",
      "\n",
      "Episode:816 Reward:-3.885590589933365 \n",
      "\n",
      "total financial balance: (eur) -90696.56507157849 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -59534.105880343035 \n",
      "\n",
      "Episode:817 Reward:-1.2021742782377587 \n",
      "\n",
      "total financial balance: (eur) -69055.95007275126 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -46966.96462948995 \n",
      "\n",
      "Episode:818 Reward:-3.834605933722298 \n",
      "\n",
      "total financial balance: (eur) -79390.24673585163 \n",
      "\n",
      "internal rate of return 188.64069566185404 \n",
      "\n",
      "net present value -49485.646059928906 \n",
      "\n",
      "Episode:819 Reward:0.07927018087380656 \n",
      "\n",
      "total financial balance: (eur) -63605.789238084035 \n",
      "\n",
      "internal rate of return -94.17242113854634 \n",
      "\n",
      "net present value -44692.28215138683 \n",
      "\n",
      "Episode:820 Reward:1.6861493577574274 \n",
      "\n",
      "total financial balance: (eur) -38291.189350718174 \n",
      "\n",
      "internal rate of return -21.63507892298545 \n",
      "\n",
      "net present value -27586.288370044604 \n",
      "\n",
      "Episode:821 Reward:-3.3921861966644435 \n",
      "\n",
      "total financial balance: (eur) -65059.63422161834 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -40936.84452042526 \n",
      "\n",
      "Episode:822 Reward:-3.1987347782310027 \n",
      "\n",
      "total financial balance: (eur) -63709.855479294434 \n",
      "\n",
      "internal rate of return 151.97822527011314 \n",
      "\n",
      "net present value -41468.777860519345 \n",
      "\n",
      "Episode:823 Reward:-2.059896488469154 \n",
      "\n",
      "total financial balance: (eur) -71180.6734127917 \n",
      "\n",
      "internal rate of return 371.33800547781834 \n",
      "\n",
      "net present value -45295.526826625646 \n",
      "\n",
      "Episode:824 Reward:0.47802090966562993 \n",
      "\n",
      "total financial balance: (eur) -24310.037522070517 \n",
      "\n",
      "internal rate of return -26.89591308664171 \n",
      "\n",
      "net present value -18930.88169370209 \n",
      "\n",
      "Episode:825 Reward:-1.2142716935579856 \n",
      "\n",
      "total financial balance: (eur) -83861.38020197085 \n",
      "\n",
      "internal rate of return 668.1986263240092 \n",
      "\n",
      "net present value -55665.7690616106 \n",
      "\n",
      "Episode:826 Reward:0.04742296257097587 \n",
      "\n",
      "total financial balance: (eur) -74544.85809281474 \n",
      "\n",
      "internal rate of return -94.07053916409765 \n",
      "\n",
      "net present value -51532.90380686424 \n",
      "\n",
      "Episode:827 Reward:-3.0376955900563853 \n",
      "\n",
      "total financial balance: (eur) -68834.25276614155 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -42563.06134333572 \n",
      "\n",
      "Episode:828 Reward:-0.8426741467761826 \n",
      "\n",
      "total financial balance: (eur) -58569.346450048906 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -35874.31464640516 \n",
      "\n",
      "Episode:829 Reward:-3.7574662038843725 \n",
      "\n",
      "total financial balance: (eur) -66920.89145947558 \n",
      "\n",
      "internal rate of return 177.8581472144408 \n",
      "\n",
      "net present value -42562.56640062377 \n",
      "\n",
      "Episode:830 Reward:3.091718483508934 \n",
      "\n",
      "total financial balance: (eur) 3111.860458376318 \n",
      "\n",
      "internal rate of return 1.3596821839477524 \n",
      "\n",
      "net present value -3518.0923529694173 \n",
      "\n",
      "Episode:831 Reward:0.214720151578902 \n",
      "\n",
      "total financial balance: (eur) -11520.686909146374 \n",
      "\n",
      "internal rate of return -82.52737760721884 \n",
      "\n",
      "net present value -9681.575589187685 \n",
      "\n",
      "Episode:832 Reward:-4.556099832365174 \n",
      "\n",
      "total financial balance: (eur) -78563.86623335366 \n",
      "\n",
      "internal rate of return 123.19568651815706 \n",
      "\n",
      "net present value -46536.36416305936 \n",
      "\n",
      "Episode:833 Reward:-1.2732074154261181 \n",
      "\n",
      "total financial balance: (eur) -45913.57557797154 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -30329.08909953665 \n",
      "\n",
      "Episode:834 Reward:-4.435618597076762 \n",
      "\n",
      "total financial balance: (eur) -97331.07172678539 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -60089.93464097404 \n",
      "\n",
      "Episode:835 Reward:1.116638247757979 \n",
      "\n",
      "total financial balance: (eur) -39593.018462951164 \n",
      "\n",
      "internal rate of return -51.590945078288854 \n",
      "\n",
      "net present value -26248.722073414403 \n",
      "\n",
      "Episode:836 Reward:0.7218212558146534 \n",
      "\n",
      "total financial balance: (eur) -32592.638512425954 \n",
      "\n",
      "internal rate of return -11.637376999225257 \n",
      "\n",
      "net present value -27451.01345798261 \n",
      "\n",
      "Episode:837 Reward:-0.17479955325628363 \n",
      "\n",
      "total financial balance: (eur) -30354.621955665854 \n",
      "\n",
      "internal rate of return 714.1429745305496 \n",
      "\n",
      "net present value -22679.597694028893 \n",
      "\n",
      "Episode:838 Reward:-2.5441518984002234 \n",
      "\n",
      "total financial balance: (eur) -71998.25894352356 \n",
      "\n",
      "internal rate of return 119.88874142204176 \n",
      "\n",
      "net present value -47323.38282890594 \n",
      "\n",
      "Episode:839 Reward:-2.5757655817716043 \n",
      "\n",
      "total financial balance: (eur) -84510.82710391111 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -51550.69958925976 \n",
      "\n",
      "Episode:840 Reward:-4.4569205969939505 \n",
      "\n",
      "total financial balance: (eur) -84860.95122301529 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -52625.98934853885 \n",
      "\n",
      "Episode:841 Reward:-2.1437805443777735 \n",
      "\n",
      "total financial balance: (eur) -69866.97637761488 \n",
      "\n",
      "internal rate of return 204.57813378140997 \n",
      "\n",
      "net present value -45183.16069535943 \n",
      "\n",
      "Episode:842 Reward:-4.431774360322041 \n",
      "\n",
      "total financial balance: (eur) -82411.61022088167 \n",
      "\n",
      "internal rate of return 326.42941242940725 \n",
      "\n",
      "net present value -51463.17920844314 \n",
      "\n",
      "Episode:843 Reward:2.600382839889653 \n",
      "\n",
      "total financial balance: (eur) -18926.683866855914 \n",
      "\n",
      "internal rate of return -9.393265061044554 \n",
      "\n",
      "net present value -15747.620981980834 \n",
      "\n",
      "Episode:844 Reward:-4.582155522483725 \n",
      "\n",
      "total financial balance: (eur) -88719.71373949757 \n",
      "\n",
      "internal rate of return 456.7401703981054 \n",
      "\n",
      "net present value -52583.24117417112 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:845 Reward:-2.140392354033483 \n",
      "\n",
      "total financial balance: (eur) -59519.25490136764 \n",
      "\n",
      "internal rate of return 32824.91096369484 \n",
      "\n",
      "net present value -37865.36586312628 \n",
      "\n",
      "Episode:846 Reward:-0.6842233059808296 \n",
      "\n",
      "total financial balance: (eur) -29957.240557275945 \n",
      "\n",
      "internal rate of return 146.15283309751655 \n",
      "\n",
      "net present value -20549.720599204255 \n",
      "\n",
      "Episode:847 Reward:-1.4966438629110816 \n",
      "\n",
      "total financial balance: (eur) -43391.93557520717 \n",
      "\n",
      "internal rate of return 202.9718505895508 \n",
      "\n",
      "net present value -28094.16117360619 \n",
      "\n",
      "Episode:848 Reward:-2.3158198052778225 \n",
      "\n",
      "total financial balance: (eur) -70786.47654127983 \n",
      "\n",
      "internal rate of return 2324.0177206095454 \n",
      "\n",
      "net present value -44559.01382429191 \n",
      "\n",
      "Episode:849 Reward:-2.184666851242859 \n",
      "\n",
      "total financial balance: (eur) -80327.90664644762 \n",
      "\n",
      "internal rate of return 260.60133816744 \n",
      "\n",
      "net present value -50648.59923872256 \n",
      "\n",
      "Episode:850 Reward:-2.759081569142785 \n",
      "\n",
      "total financial balance: (eur) -78143.89901197034 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -50466.31308832958 \n",
      "\n",
      "Episode:851 Reward:-1.5253203941154274 \n",
      "\n",
      "total financial balance: (eur) -87051.91179279612 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -56974.86046104355 \n",
      "\n",
      "Episode:852 Reward:-1.3905571644672619 \n",
      "\n",
      "total financial balance: (eur) -88597.64766921235 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -57406.25672929445 \n",
      "\n",
      "Episode:853 Reward:-2.2315522688589073 \n",
      "\n",
      "total financial balance: (eur) -55018.42594747413 \n",
      "\n",
      "internal rate of return 147.58852188653435 \n",
      "\n",
      "net present value -33812.09397302144 \n",
      "\n",
      "Episode:854 Reward:1.0039626756910256 \n",
      "\n",
      "total financial balance: (eur) -29828.355246141207 \n",
      "\n",
      "internal rate of return -16.200723652240455 \n",
      "\n",
      "net present value -22534.877745268983 \n",
      "\n",
      "Episode:855 Reward:0.5481155672918103 \n",
      "\n",
      "total financial balance: (eur) -48752.77381958871 \n",
      "\n",
      "internal rate of return -31.717267726595978 \n",
      "\n",
      "net present value -35173.70330299339 \n",
      "\n",
      "Episode:856 Reward:-3.7160635662189967 \n",
      "\n",
      "total financial balance: (eur) -77660.98998336316 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -46600.33687308967 \n",
      "\n",
      "Episode:857 Reward:-4.23073232286584 \n",
      "\n",
      "total financial balance: (eur) -81792.75417752331 \n",
      "\n",
      "internal rate of return 343.15692248689294 \n",
      "\n",
      "net present value -50132.119188322045 \n",
      "\n",
      "Episode:858 Reward:-0.6523664205240312 \n",
      "\n",
      "total financial balance: (eur) -72022.29701688804 \n",
      "\n",
      "internal rate of return 235.90350189803792 \n",
      "\n",
      "net present value -49460.86707973122 \n",
      "\n",
      "Episode:859 Reward:-1.8273872599039478 \n",
      "\n",
      "total financial balance: (eur) -90356.52076665476 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -58440.342459994135 \n",
      "\n",
      "Episode:860 Reward:-2.0774143040529607 \n",
      "\n",
      "total financial balance: (eur) -72054.13033101683 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -46009.84474351749 \n",
      "\n",
      "Episode:861 Reward:-3.396018544651985 \n",
      "\n",
      "total financial balance: (eur) -63399.80299728768 \n",
      "\n",
      "internal rate of return 367.5394608234238 \n",
      "\n",
      "net present value -39928.25567884104 \n",
      "\n",
      "Episode:862 Reward:1.5548412318360043 \n",
      "\n",
      "total financial balance: (eur) -41146.41705032538 \n",
      "\n",
      "internal rate of return -29.914921254355363 \n",
      "\n",
      "net present value -29789.17796418636 \n",
      "\n",
      "Episode:863 Reward:-3.0517143203237866 \n",
      "\n",
      "total financial balance: (eur) -85374.2962799606 \n",
      "\n",
      "internal rate of return 422.37581293735974 \n",
      "\n",
      "net present value -54052.79916671821 \n",
      "\n",
      "Episode:864 Reward:-5.152585544034849 \n",
      "\n",
      "total financial balance: (eur) -96349.61970953365 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -59214.84328489538 \n",
      "\n",
      "Episode:865 Reward:-0.3077228628208577 \n",
      "\n",
      "total financial balance: (eur) -31495.330034228566 \n",
      "\n",
      "internal rate of return 99.91360867616923 \n",
      "\n",
      "net present value -20376.83054028682 \n",
      "\n",
      "Episode:866 Reward:-2.363749420525419 \n",
      "\n",
      "total financial balance: (eur) -58409.29822483497 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -37256.31539925077 \n",
      "\n",
      "Episode:867 Reward:-0.9981254634494817 \n",
      "\n",
      "total financial balance: (eur) -68114.87550131985 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -43424.97089440765 \n",
      "\n",
      "Episode:868 Reward:-0.2879580070607317 \n",
      "\n",
      "total financial balance: (eur) -34193.60710930939 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -24282.2650939373 \n",
      "\n",
      "Episode:869 Reward:-2.3442244148098306 \n",
      "\n",
      "total financial balance: (eur) -64436.02203467195 \n",
      "\n",
      "internal rate of return 855.5433211576766 \n",
      "\n",
      "net present value -41825.026112755244 \n",
      "\n",
      "Episode:870 Reward:-3.315953182291866 \n",
      "\n",
      "total financial balance: (eur) -70210.85927954424 \n",
      "\n",
      "internal rate of return 423.35919113742426 \n",
      "\n",
      "net present value -46031.426703222416 \n",
      "\n",
      "Episode:871 Reward:0.5401707304483607 \n",
      "\n",
      "total financial balance: (eur) -53766.8062361714 \n",
      "\n",
      "internal rate of return 68.99506535150925 \n",
      "\n",
      "net present value -33516.265249630065 \n",
      "\n",
      "Episode:872 Reward:1.6229162145313576 \n",
      "\n",
      "total financial balance: (eur) -30061.66575086417 \n",
      "\n",
      "internal rate of return -14.372261633457061 \n",
      "\n",
      "net present value -23697.872935399948 \n",
      "\n",
      "Episode:873 Reward:-2.6898142365202946 \n",
      "\n",
      "total financial balance: (eur) -72344.3996465542 \n",
      "\n",
      "internal rate of return 455.7119885929909 \n",
      "\n",
      "net present value -47373.410909897146 \n",
      "\n",
      "Episode:874 Reward:-0.7109096816343663 \n",
      "\n",
      "total financial balance: (eur) -57027.18392755668 \n",
      "\n",
      "internal rate of return 8569.975867439354 \n",
      "\n",
      "net present value -39886.97052418749 \n",
      "\n",
      "Episode:875 Reward:-1.4852795249731607 \n",
      "\n",
      "total financial balance: (eur) -44060.45878281299 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -31565.783226813088 \n",
      "\n",
      "Episode:876 Reward:-1.3966350311810438 \n",
      "\n",
      "total financial balance: (eur) -60466.842978744084 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -40176.220074353005 \n",
      "\n",
      "Episode:877 Reward:0.41216385658730814 \n",
      "\n",
      "total financial balance: (eur) -53426.569706419585 \n",
      "\n",
      "internal rate of return -76.67896836540773 \n",
      "\n",
      "net present value -37881.66831984365 \n",
      "\n",
      "Episode:878 Reward:-1.0335756756666452 \n",
      "\n",
      "total financial balance: (eur) -42856.402604358635 \n",
      "\n",
      "internal rate of return 243.3645197666936 \n",
      "\n",
      "net present value -29336.971621673627 \n",
      "\n",
      "Episode:879 Reward:-1.1259732656999268 \n",
      "\n",
      "total financial balance: (eur) -46810.77682255357 \n",
      "\n",
      "internal rate of return 329.35657594327114 \n",
      "\n",
      "net present value -30332.47933601306 \n",
      "\n",
      "Episode:880 Reward:-1.1019727759602664 \n",
      "\n",
      "total financial balance: (eur) -69235.11795256549 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -45426.43881704935 \n",
      "\n",
      "Episode:881 Reward:-3.71204753492932 \n",
      "\n",
      "total financial balance: (eur) -93253.74414438361 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -58538.085855875564 \n",
      "\n",
      "Episode:882 Reward:-3.0908078554129417 \n",
      "\n",
      "total financial balance: (eur) -81992.56082201227 \n",
      "\n",
      "internal rate of return 136.9969543832967 \n",
      "\n",
      "net present value -51508.00030268991 \n",
      "\n",
      "Episode:883 Reward:1.7777010727799316 \n",
      "\n",
      "total financial balance: (eur) -43996.81105636319 \n",
      "\n",
      "internal rate of return -24.339093579933657 \n",
      "\n",
      "net present value -32176.163181295793 \n",
      "\n",
      "Episode:884 Reward:-2.2736530505726615 \n",
      "\n",
      "total financial balance: (eur) -62160.05372601565 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -44265.68899576491 \n",
      "\n",
      "Episode:885 Reward:-0.975573007369142 \n",
      "\n",
      "total financial balance: (eur) -49070.90683911072 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -36682.04828768911 \n",
      "\n",
      "Episode:886 Reward:-0.47271529364608067 \n",
      "\n",
      "total financial balance: (eur) -48266.38291179149 \n",
      "\n",
      "internal rate of return 435.09560293256914 \n",
      "\n",
      "net present value -33590.93059539835 \n",
      "\n",
      "Episode:887 Reward:-4.225298941958493 \n",
      "\n",
      "total financial balance: (eur) -97326.63150360099 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -59857.08073451426 \n",
      "\n",
      "Episode:888 Reward:-1.7749104450485937 \n",
      "\n",
      "total financial balance: (eur) -89856.26569476012 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -54852.37811022357 \n",
      "\n",
      "Episode:889 Reward:-4.209110168251146 \n",
      "\n",
      "total financial balance: (eur) -74296.01723592068 \n",
      "\n",
      "internal rate of return 200.1608953382401 \n",
      "\n",
      "net present value -46264.932341743595 \n",
      "\n",
      "Episode:890 Reward:-1.2248333916977536 \n",
      "\n",
      "total financial balance: (eur) -75197.76894770519 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -48071.49171212162 \n",
      "\n",
      "Episode:891 Reward:-1.2506235403369927 \n",
      "\n",
      "total financial balance: (eur) -44785.83552860975 \n",
      "\n",
      "internal rate of return 230.86192928319383 \n",
      "\n",
      "net present value -29408.958312445393 \n",
      "\n",
      "Episode:892 Reward:-3.1766516085578886 \n",
      "\n",
      "total financial balance: (eur) -55551.45606905529 \n",
      "\n",
      "internal rate of return 740.5992442732236 \n",
      "\n",
      "net present value -33358.17193133251 \n",
      "\n",
      "Episode:893 Reward:-3.93438440666139 \n",
      "\n",
      "total financial balance: (eur) -93792.38273616518 \n",
      "\n",
      "internal rate of return 3873.3579217420756 \n",
      "\n",
      "net present value -61421.0323711863 \n",
      "\n",
      "Episode:894 Reward:-3.08724467532537 \n",
      "\n",
      "total financial balance: (eur) -86185.11065293879 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -52649.200000122175 \n",
      "\n",
      "Episode:895 Reward:-2.6877077382528625 \n",
      "\n",
      "total financial balance: (eur) -78222.08563061857 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -52742.495243045094 \n",
      "\n",
      "Episode:896 Reward:-1.4812538249107448 \n",
      "\n",
      "total financial balance: (eur) -35027.43093007312 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -23093.173735488675 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:897 Reward:1.6095881245056316 \n",
      "\n",
      "total financial balance: (eur) -920.451104659548 \n",
      "\n",
      "internal rate of return -0.31780782673335173 \n",
      "\n",
      "net present value -7475.784471464971 \n",
      "\n",
      "Episode:898 Reward:-1.9534323328469028 \n",
      "\n",
      "total financial balance: (eur) -63405.030327173125 \n",
      "\n",
      "internal rate of return 518.4603437467065 \n",
      "\n",
      "net present value -39923.27490322901 \n",
      "\n",
      "Episode:899 Reward:1.9938271771510399 \n",
      "\n",
      "total financial balance: (eur) -24170.654213657996 \n",
      "\n",
      "internal rate of return -10.717135114341147 \n",
      "\n",
      "net present value -19706.65963665913 \n",
      "\n",
      "Episode:900 Reward:-0.12838631048476146 \n",
      "\n",
      "total financial balance: (eur) -59965.872170566225 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -37746.15523803428 \n",
      "\n",
      "Episode:901 Reward:-5.0658897072098625 \n",
      "\n",
      "total financial balance: (eur) -94484.8179057492 \n",
      "\n",
      "internal rate of return 348.6209007583028 \n",
      "\n",
      "net present value -59071.27891619065 \n",
      "\n",
      "Episode:902 Reward:-1.2497698746857477 \n",
      "\n",
      "total financial balance: (eur) -46881.78381033691 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -30852.89303031798 \n",
      "\n",
      "Episode:903 Reward:-1.4776457697201821 \n",
      "\n",
      "total financial balance: (eur) -40735.63157102243 \n",
      "\n",
      "internal rate of return 102.91953548391963 \n",
      "\n",
      "net present value -27085.063851366685 \n",
      "\n",
      "Episode:904 Reward:-3.8822529126003262 \n",
      "\n",
      "total financial balance: (eur) -74317.52923391972 \n",
      "\n",
      "internal rate of return 931.3088810427056 \n",
      "\n",
      "net present value -49923.12130070955 \n",
      "\n",
      "Episode:905 Reward:-4.587659620701097 \n",
      "\n",
      "total financial balance: (eur) -100572.90588800705 \n",
      "\n",
      "internal rate of return 257.67660886146837 \n",
      "\n",
      "net present value -63100.24504109048 \n",
      "\n",
      "Episode:906 Reward:-3.8090035270771496 \n",
      "\n",
      "total financial balance: (eur) -51219.7753187197 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -31241.018318898048 \n",
      "\n",
      "Episode:907 Reward:1.8389784581823743 \n",
      "\n",
      "total financial balance: (eur) -39812.63688629072 \n",
      "\n",
      "internal rate of return -24.2805756276794 \n",
      "\n",
      "net present value -30100.307864380084 \n",
      "\n",
      "Episode:908 Reward:-3.1761576650149275 \n",
      "\n",
      "total financial balance: (eur) -79899.51559742176 \n",
      "\n",
      "internal rate of return 457.9913328476324 \n",
      "\n",
      "net present value -49470.866217906114 \n",
      "\n",
      "Episode:909 Reward:-1.3137408225043845 \n",
      "\n",
      "total financial balance: (eur) -49567.16541665254 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -34752.121453606254 \n",
      "\n",
      "Episode:910 Reward:-2.6671684061380727 \n",
      "\n",
      "total financial balance: (eur) -73166.76363026875 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -44143.98770060787 \n",
      "\n",
      "Episode:911 Reward:0.7060414946266901 \n",
      "\n",
      "total financial balance: (eur) -17273.695122125602 \n",
      "\n",
      "internal rate of return -14.846214907483501 \n",
      "\n",
      "net present value -13772.61888662855 \n",
      "\n",
      "Episode:912 Reward:-3.729037734206879 \n",
      "\n",
      "total financial balance: (eur) -77408.64115979605 \n",
      "\n",
      "internal rate of return 219.3262777825789 \n",
      "\n",
      "net present value -46324.48594608271 \n",
      "\n",
      "Episode:913 Reward:2.6334915822646088 \n",
      "\n",
      "total financial balance: (eur) -44137.46878029763 \n",
      "\n",
      "internal rate of return -17.57271380073686 \n",
      "\n",
      "net present value -34135.08078612987 \n",
      "\n",
      "Episode:914 Reward:1.028441149143443 \n",
      "\n",
      "total financial balance: (eur) -34325.28850448222 \n",
      "\n",
      "internal rate of return -41.888041859117074 \n",
      "\n",
      "net present value -25601.112832403687 \n",
      "\n",
      "Episode:915 Reward:-1.9892217216081398 \n",
      "\n",
      "total financial balance: (eur) -71084.36394437838 \n",
      "\n",
      "internal rate of return 189.31532388319695 \n",
      "\n",
      "net present value -43712.15737061212 \n",
      "\n",
      "Episode:916 Reward:2.452416476182925 \n",
      "\n",
      "total financial balance: (eur) -27761.430907652517 \n",
      "\n",
      "internal rate of return -13.751668327002363 \n",
      "\n",
      "net present value -22440.1395643881 \n",
      "\n",
      "Episode:917 Reward:-3.960137812208747 \n",
      "\n",
      "total financial balance: (eur) -82783.07709386926 \n",
      "\n",
      "internal rate of return 702.1732383761777 \n",
      "\n",
      "net present value -50928.385207490974 \n",
      "\n",
      "Episode:918 Reward:-1.4799383922406077 \n",
      "\n",
      "total financial balance: (eur) -76408.53406488935 \n",
      "\n",
      "internal rate of return 170.51107783014513 \n",
      "\n",
      "net present value -47393.176041502804 \n",
      "\n",
      "Episode:919 Reward:1.0033555685472548 \n",
      "\n",
      "total financial balance: (eur) -16372.694924092515 \n",
      "\n",
      "internal rate of return -4.160876691050275 \n",
      "\n",
      "net present value -20707.431851469293 \n",
      "\n",
      "Episode:920 Reward:-2.397782598421754 \n",
      "\n",
      "total financial balance: (eur) -62181.801603366606 \n",
      "\n",
      "internal rate of return 225.42836135611816 \n",
      "\n",
      "net present value -37914.06598836172 \n",
      "\n",
      "Episode:921 Reward:-3.4848452285515528 \n",
      "\n",
      "total financial balance: (eur) -69154.48288749014 \n",
      "\n",
      "internal rate of return 536.7376785563982 \n",
      "\n",
      "net present value -43680.176344457046 \n",
      "\n",
      "Episode:922 Reward:-3.0970360031835815 \n",
      "\n",
      "total financial balance: (eur) -84597.1167521706 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -52415.628770037714 \n",
      "\n",
      "Episode:923 Reward:0.36855170908341645 \n",
      "\n",
      "total financial balance: (eur) -50109.95527927084 \n",
      "\n",
      "internal rate of return -62.457696481418346 \n",
      "\n",
      "net present value -36317.644800651426 \n",
      "\n",
      "Episode:924 Reward:-2.99674963048905 \n",
      "\n",
      "total financial balance: (eur) -63917.4610529171 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -38604.16781174479 \n",
      "\n",
      "Episode:925 Reward:-1.7194490154874866 \n",
      "\n",
      "total financial balance: (eur) -65348.189976055466 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -39451.237647646725 \n",
      "\n",
      "Episode:926 Reward:-0.05520829789506206 \n",
      "\n",
      "total financial balance: (eur) -66881.12393957557 \n",
      "\n",
      "internal rate of return 167.04359552125925 \n",
      "\n",
      "net present value -43839.0114007175 \n",
      "\n",
      "Episode:927 Reward:-2.476351926471444 \n",
      "\n",
      "total financial balance: (eur) -69267.74729189774 \n",
      "\n",
      "internal rate of return 135.75757569873153 \n",
      "\n",
      "net present value -43304.3056832069 \n",
      "\n",
      "Episode:928 Reward:-2.211932346435704 \n",
      "\n",
      "total financial balance: (eur) -68591.33195514338 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -44291.526906136474 \n",
      "\n",
      "Episode:929 Reward:-1.189580122203026 \n",
      "\n",
      "total financial balance: (eur) -27404.76452288541 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -19542.113357976672 \n",
      "\n",
      "Episode:930 Reward:-0.42411329527840097 \n",
      "\n",
      "total financial balance: (eur) -24273.403086541402 \n",
      "\n",
      "internal rate of return 709.6214557993679 \n",
      "\n",
      "net present value -17338.883619017426 \n",
      "\n",
      "Episode:931 Reward:-1.6610936632946214 \n",
      "\n",
      "total financial balance: (eur) -56547.105350654354 \n",
      "\n",
      "internal rate of return 143.37760300513415 \n",
      "\n",
      "net present value -36566.457997528014 \n",
      "\n",
      "Episode:932 Reward:-1.9092090963409192 \n",
      "\n",
      "total financial balance: (eur) -63520.20806614262 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -40709.45225352048 \n",
      "\n",
      "Episode:933 Reward:-0.6656285363903999 \n",
      "\n",
      "total financial balance: (eur) -45807.422188733195 \n",
      "\n",
      "internal rate of return 560.1215150006135 \n",
      "\n",
      "net present value -29415.824302734018 \n",
      "\n",
      "Episode:934 Reward:-2.598415542726627 \n",
      "\n",
      "total financial balance: (eur) -74241.07350987232 \n",
      "\n",
      "internal rate of return 1305.5272731151956 \n",
      "\n",
      "net present value -49577.697814388615 \n",
      "\n",
      "Episode:935 Reward:-5.097248329715236 \n",
      "\n",
      "total financial balance: (eur) -92085.14030277851 \n",
      "\n",
      "internal rate of return 80.3443601924414 \n",
      "\n",
      "net present value -53719.320497263296 \n",
      "\n",
      "Episode:936 Reward:-4.189304409185571 \n",
      "\n",
      "total financial balance: (eur) -84924.73972137648 \n",
      "\n",
      "internal rate of return 856.0607028352017 \n",
      "\n",
      "net present value -55306.97616028642 \n",
      "\n",
      "Episode:937 Reward:-2.411098708262348 \n",
      "\n",
      "total financial balance: (eur) -73951.57886344561 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -50423.299271330055 \n",
      "\n",
      "Episode:938 Reward:1.7352996742191027 \n",
      "\n",
      "total financial balance: (eur) -1224.704651318213 \n",
      "\n",
      "internal rate of return -0.43484366828874244 \n",
      "\n",
      "net present value -7624.655337222641 \n",
      "\n",
      "Episode:939 Reward:-4.5421562310993675 \n",
      "\n",
      "total financial balance: (eur) -85113.31587367339 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -57136.36352231841 \n",
      "\n",
      "Episode:940 Reward:-4.059291906415981 \n",
      "\n",
      "total financial balance: (eur) -90996.29533761172 \n",
      "\n",
      "internal rate of return 592.4233796956127 \n",
      "\n",
      "net present value -55025.10741611352 \n",
      "\n",
      "Episode:941 Reward:-1.8092235426773295 \n",
      "\n",
      "total financial balance: (eur) -45738.50010163724 \n",
      "\n",
      "internal rate of return 159.2397801267176 \n",
      "\n",
      "net present value -32863.936472313675 \n",
      "\n",
      "Episode:942 Reward:-0.22115151649810832 \n",
      "\n",
      "total financial balance: (eur) -65773.91135823741 \n",
      "\n",
      "internal rate of return 144.881576949773 \n",
      "\n",
      "net present value -44639.68625930116 \n",
      "\n",
      "Episode:943 Reward:-2.32058988258365 \n",
      "\n",
      "total financial balance: (eur) -60595.20965381012 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -39655.301073330156 \n",
      "\n",
      "Episode:944 Reward:-2.29794103651364 \n",
      "\n",
      "total financial balance: (eur) -94040.37797673621 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -61123.48149183278 \n",
      "\n",
      "Episode:945 Reward:-0.07522059664527388 \n",
      "\n",
      "total financial balance: (eur) -52365.94690249729 \n",
      "\n",
      "internal rate of return 103.77587952764817 \n",
      "\n",
      "net present value -33846.906614228574 \n",
      "\n",
      "Episode:946 Reward:-2.076911844474425 \n",
      "\n",
      "total financial balance: (eur) -77455.82383671962 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -49331.9922571039 \n",
      "\n",
      "Episode:947 Reward:0.9027236746203126 \n",
      "\n",
      "total financial balance: (eur) -42678.80958146981 \n",
      "\n",
      "internal rate of return -43.10631599568816 \n",
      "\n",
      "net present value -28654.76726224732 \n",
      "\n",
      "Episode:948 Reward:-2.4416195598730854 \n",
      "\n",
      "total financial balance: (eur) -83086.76363479735 \n",
      "\n",
      "internal rate of return 278.25894924453866 \n",
      "\n",
      "net present value -51889.50648047093 \n",
      "\n",
      "Episode:949 Reward:-3.5591984530024403 \n",
      "\n",
      "total financial balance: (eur) -75769.45400278743 \n",
      "\n",
      "internal rate of return 115.80246368298121 \n",
      "\n",
      "net present value -45279.167488006424 \n",
      "\n",
      "Episode:950 Reward:-1.3118238641854714 \n",
      "\n",
      "total financial balance: (eur) -57010.61774797621 \n",
      "\n",
      "internal rate of return 332.5120715928749 \n",
      "\n",
      "net present value -37814.60759426814 \n",
      "\n",
      "Episode:951 Reward:-2.7883070117760815 \n",
      "\n",
      "total financial balance: (eur) -75137.6271656501 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -49250.40631378321 \n",
      "\n",
      "Episode:952 Reward:0.10959766209716963 \n",
      "\n",
      "total financial balance: (eur) -26429.42819720616 \n",
      "\n",
      "internal rate of return -21.481036661407536 \n",
      "\n",
      "net present value -18440.53722938298 \n",
      "\n",
      "Episode:953 Reward:-3.2028338692755316 \n",
      "\n",
      "total financial balance: (eur) -62622.4883397112 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -38372.692506412255 \n",
      "\n",
      "Episode:954 Reward:-0.5598459350409039 \n",
      "\n",
      "total financial balance: (eur) -63809.76056722326 \n",
      "\n",
      "internal rate of return 612.22641242123 \n",
      "\n",
      "net present value -44268.35168160707 \n",
      "\n",
      "Episode:955 Reward:-1.8208735733639734 \n",
      "\n",
      "total financial balance: (eur) -62277.575481516236 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -41625.951454294576 \n",
      "\n",
      "Episode:956 Reward:-2.5323973886321585 \n",
      "\n",
      "total financial balance: (eur) -76613.96123202759 \n",
      "\n",
      "internal rate of return 570.9182430667476 \n",
      "\n",
      "net present value -48076.57410914893 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:957 Reward:0.846833240781385 \n",
      "\n",
      "total financial balance: (eur) -48055.3935491933 \n",
      "\n",
      "internal rate of return -48.119057087354264 \n",
      "\n",
      "net present value -32765.67260678938 \n",
      "\n",
      "Episode:958 Reward:0.06067759982820644 \n",
      "\n",
      "total financial balance: (eur) -39861.289644076736 \n",
      "\n",
      "internal rate of return -32.18855506091326 \n",
      "\n",
      "net present value -29723.31061241027 \n",
      "\n",
      "Episode:959 Reward:-4.0161628008725225 \n",
      "\n",
      "total financial balance: (eur) -90186.45026934672 \n",
      "\n",
      "internal rate of return 265.46407774110105 \n",
      "\n",
      "net present value -56958.559439324614 \n",
      "\n",
      "Episode:960 Reward:-0.8867928124926411 \n",
      "\n",
      "total financial balance: (eur) -47670.814484703886 \n",
      "\n",
      "internal rate of return 123.84005240176363 \n",
      "\n",
      "net present value -32505.220832454947 \n",
      "\n",
      "Episode:961 Reward:-0.4439818024012593 \n",
      "\n",
      "total financial balance: (eur) -58166.87829903938 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -39546.39159331078 \n",
      "\n",
      "Episode:962 Reward:-2.87434084650354 \n",
      "\n",
      "total financial balance: (eur) -82746.03230893017 \n",
      "\n",
      "internal rate of return 132.8497500228913 \n",
      "\n",
      "net present value -50744.879786187565 \n",
      "\n",
      "Episode:963 Reward:-1.3525983025525965 \n",
      "\n",
      "total financial balance: (eur) -43801.53496446117 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -29373.933960447328 \n",
      "\n",
      "Episode:964 Reward:-2.4178124511586137 \n",
      "\n",
      "total financial balance: (eur) -70303.06100326512 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -44687.93329406812 \n",
      "\n",
      "Episode:965 Reward:-1.1562722046132066 \n",
      "\n",
      "total financial balance: (eur) -45848.556676624816 \n",
      "\n",
      "internal rate of return 214.44733670410355 \n",
      "\n",
      "net present value -29147.09755613518 \n",
      "\n",
      "Episode:966 Reward:-3.713163760057436 \n",
      "\n",
      "total financial balance: (eur) -87352.54925682268 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -55946.17421261365 \n",
      "\n",
      "Episode:967 Reward:-2.5900878968536163 \n",
      "\n",
      "total financial balance: (eur) -57657.012919699 \n",
      "\n",
      "internal rate of return 139.9005806725073 \n",
      "\n",
      "net present value -36231.07787702127 \n",
      "\n",
      "Episode:968 Reward:-2.4082525416706497 \n",
      "\n",
      "total financial balance: (eur) -88923.39553769487 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -56098.59060777462 \n",
      "\n",
      "Episode:969 Reward:-0.34278740224215015 \n",
      "\n",
      "total financial balance: (eur) -49185.99151616765 \n",
      "\n",
      "internal rate of return 88.20195167105953 \n",
      "\n",
      "net present value -30270.814706612804 \n",
      "\n",
      "Episode:970 Reward:-2.1884437392009777 \n",
      "\n",
      "total financial balance: (eur) -71481.62046414985 \n",
      "\n",
      "internal rate of return 122.15236015713185 \n",
      "\n",
      "net present value -43895.1840662374 \n",
      "\n",
      "Episode:971 Reward:-2.4896679634645817 \n",
      "\n",
      "total financial balance: (eur) -68086.12737281837 \n",
      "\n",
      "internal rate of return 267.66554713688237 \n",
      "\n",
      "net present value -45607.815461008046 \n",
      "\n",
      "Episode:972 Reward:-1.786457869865826 \n",
      "\n",
      "total financial balance: (eur) -53362.45583588962 \n",
      "\n",
      "internal rate of return 2619.3512950943477 \n",
      "\n",
      "net present value -34629.308151406156 \n",
      "\n",
      "Episode:973 Reward:-1.3824692045011662 \n",
      "\n",
      "total financial balance: (eur) -84261.70288496975 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -55640.889047756355 \n",
      "\n",
      "Episode:974 Reward:-1.8422474881840007 \n",
      "\n",
      "total financial balance: (eur) -53550.64607639045 \n",
      "\n",
      "internal rate of return 344.1491375302582 \n",
      "\n",
      "net present value -34412.56746332021 \n",
      "\n",
      "Episode:975 Reward:4.1981465106972164 \n",
      "\n",
      "total financial balance: (eur) 16470.449550110432 \n",
      "\n",
      "internal rate of return 7.402681678408851 \n",
      "\n",
      "net present value 4463.100279416278 \n",
      "\n",
      "Episode:976 Reward:-2.900453132445161 \n",
      "\n",
      "total financial balance: (eur) -64799.81411164831 \n",
      "\n",
      "internal rate of return 153.87611139804972 \n",
      "\n",
      "net present value -40753.169491183544 \n",
      "\n",
      "Episode:977 Reward:-2.891985889107279 \n",
      "\n",
      "total financial balance: (eur) -66605.93690510145 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -43949.31619318258 \n",
      "\n",
      "Episode:978 Reward:-3.1721152292010464 \n",
      "\n",
      "total financial balance: (eur) -63206.246273418976 \n",
      "\n",
      "internal rate of return 101.60413881266983 \n",
      "\n",
      "net present value -38857.062615549075 \n",
      "\n",
      "Episode:979 Reward:-0.6471243963269134 \n",
      "\n",
      "total financial balance: (eur) -57556.358854227314 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -36359.12857916778 \n",
      "\n",
      "Episode:980 Reward:-2.007895856519289 \n",
      "\n",
      "total financial balance: (eur) -47960.12890038421 \n",
      "\n",
      "internal rate of return 150.785833866413 \n",
      "\n",
      "net present value -31871.972196497787 \n",
      "\n",
      "Episode:981 Reward:-4.440585479443414 \n",
      "\n",
      "total financial balance: (eur) -83210.46005406699 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -52181.91962609706 \n",
      "\n",
      "Episode:982 Reward:-2.763445622209638 \n",
      "\n",
      "total financial balance: (eur) -41833.35963230139 \n",
      "\n",
      "internal rate of return 210.9752106861888 \n",
      "\n",
      "net present value -28546.39223627473 \n",
      "\n",
      "Episode:983 Reward:-0.2247790832749597 \n",
      "\n",
      "total financial balance: (eur) -35643.925194491174 \n",
      "\n",
      "internal rate of return 282.1658501155918 \n",
      "\n",
      "net present value -25819.99543143803 \n",
      "\n",
      "Episode:984 Reward:-1.4731080559525034 \n",
      "\n",
      "total financial balance: (eur) -67044.40157179932 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -45086.45449686968 \n",
      "\n",
      "Episode:985 Reward:-3.5160779400236377 \n",
      "\n",
      "total financial balance: (eur) -65779.2223879133 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -41844.74164922569 \n",
      "\n",
      "Episode:986 Reward:-3.121875239234454 \n",
      "\n",
      "total financial balance: (eur) -102720.39070223019 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -65095.93308821358 \n",
      "\n",
      "Episode:987 Reward:-4.477703339137974 \n",
      "\n",
      "total financial balance: (eur) -83039.10866399095 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -50385.00148767486 \n",
      "\n",
      "Episode:988 Reward:-1.1866312541018216 \n",
      "\n",
      "total financial balance: (eur) -50941.62457979578 \n",
      "\n",
      "internal rate of return 105.5724490124156 \n",
      "\n",
      "net present value -32263.351377217376 \n",
      "\n",
      "Episode:989 Reward:-0.750667689140234 \n",
      "\n",
      "total financial balance: (eur) -63786.74697072765 \n",
      "\n",
      "internal rate of return 620.5408246866036 \n",
      "\n",
      "net present value -43401.534109803084 \n",
      "\n",
      "Episode:990 Reward:-1.61542541896464 \n",
      "\n",
      "total financial balance: (eur) -53838.780739503876 \n",
      "\n",
      "internal rate of return 245.2382904800918 \n",
      "\n",
      "net present value -34017.111175684506 \n",
      "\n",
      "Episode:991 Reward:4.7370618934281925 \n",
      "\n",
      "total financial balance: (eur) -1766.151015414649 \n",
      "\n",
      "internal rate of return -0.4227970161523431 \n",
      "\n",
      "net present value -10852.76350749879 \n",
      "\n",
      "Episode:992 Reward:0.5960606221484995 \n",
      "\n",
      "total financial balance: (eur) -30295.55068890236 \n",
      "\n",
      "internal rate of return -58.81713607932972 \n",
      "\n",
      "net present value -23835.67427954798 \n",
      "\n",
      "Episode:993 Reward:-3.7491198078186074 \n",
      "\n",
      "total financial balance: (eur) -60566.24142226276 \n",
      "\n",
      "internal rate of return 573.6531448879354 \n",
      "\n",
      "net present value -39061.93189590718 \n",
      "\n",
      "Episode:994 Reward:-2.1515413839477087 \n",
      "\n",
      "total financial balance: (eur) -56056.41135158144 \n",
      "\n",
      "internal rate of return 173.60053252566908 \n",
      "\n",
      "net present value -34624.94700973912 \n",
      "\n",
      "Episode:995 Reward:0.6682041252234003 \n",
      "\n",
      "total financial balance: (eur) -35544.223855612836 \n",
      "\n",
      "internal rate of return -26.644800714968 \n",
      "\n",
      "net present value -25483.436938984312 \n",
      "\n",
      "Episode:996 Reward:-4.389332723652494 \n",
      "\n",
      "total financial balance: (eur) -79673.86253183588 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -44538.273372618845 \n",
      "\n",
      "Episode:997 Reward:-2.715720621741103 \n",
      "\n",
      "total financial balance: (eur) -37325.14458730601 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -24650.116948271418 \n",
      "\n",
      "Episode:998 Reward:-2.050963852358178 \n",
      "\n",
      "total financial balance: (eur) -49326.034925068016 \n",
      "\n",
      "internal rate of return nan \n",
      "\n",
      "net present value -32790.27885427701 \n",
      "\n",
      "Episode:999 Reward:-2.996261869212762 \n",
      "\n",
      "total financial balance: (eur) -61044.644367717745 \n",
      "\n",
      "internal rate of return 249.24799868079663 \n",
      "\n",
      "net present value -41436.09377349582 \n",
      "\n",
      "Episode:1000 Reward:-2.52423374803362 \n",
      "\n",
      "total financial balance: (eur) -53282.23485270162 \n",
      "\n",
      "internal rate of return 1191.8703402776755 \n",
      "\n",
      "net present value -34609.74051037491 \n",
      "\n",
      "Execution time: 13.525114059448242 seconds\n"
     ]
    }
   ],
   "source": [
    "test1(1000, env_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c1e45550",
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def make_env(rank: int, seed: int = 0) -> Callable:\n",
    "    def _init() -> gym.Env:\n",
    "        random.seed(seed + rank)\n",
    "        np.random.seed(seed + rank) \n",
    "        env = TrainEnvironment(JA_60_arr, JA_240_arr, elec_consum_arr, import_price_rate, import_price_train_arr, Eff_train_arr, CAPEX_JA_train_arr)\n",
    "        env.reset(seed=seed + rank)\n",
    "        return env\n",
    "\n",
    "    return _init\n",
    "# Number of environments to run in parallel\n",
    "num_cpu = 16\n",
    "env = SubprocVecEnv([make_env(i) for i in range(num_cpu)])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "36af5784",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "log_path = \"./logs/\"\n",
    "eval_callback = EvalCallback(env_test, best_model_save_path = \"C:/Users/kubaw/Desktop/DELFT/THESIS/CODE/TEST_MODELS/32_ja_low_4/\",\n",
    "                             log_path = log_path, n_eval_episodes = 750, eval_freq=10000,\n",
    "                             deterministic=True, render=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "41010d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_kwargs = dict(net_arch=dict(pi=[1536, 1536], vf=[1536, 1536]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3408195a",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def linear_schedule(initial_value, final_value=0.00001):\n",
    "    \"\"\"\n",
    "    Returns a function that computes a linearly decreasing value from initial_value to final_value.\n",
    "    \"\"\"\n",
    "    def func(progress_remaining):\n",
    "        # Calculate the decrease based on the remaining progress\n",
    "        return final_value + (initial_value - final_value) * progress_remaining\n",
    "    return func\n",
    "\n",
    "# Define the learning rate using the linear schedule\n",
    "learning_rate = linear_schedule(0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "678979b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to C:/Users/kubaw/Desktop/DELFT/THESIS\\CODE/TEST_MODELS/LOGS/logs\\PPO_464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kubaw\\miniforge3\\envs\\pytorch-env\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kubaw\\AppData\\Local\\Temp\\ipykernel_4840\\3085370352.py:225: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  value = annual_expense / self.current_budget_constraint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=28928, episode_reward=26.80 +/- 14.67\n",
      "Episode length: 25.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 25       |\n",
      "|    mean_reward     | 26.8     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 28928    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 873   |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 37    |\n",
      "|    total_timesteps | 32768 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011024598 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.53       |\n",
      "|    explained_variance   | -0.00168    |\n",
      "|    learning_rate        | 0.000199    |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 24          |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 445         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014889834 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.5        |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.000199    |\n",
      "|    loss                 | 38.8        |\n",
      "|    n_updates            | 48          |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    value_loss           | 84.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 414         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016386073 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.44       |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.000198    |\n",
      "|    loss                 | 41          |\n",
      "|    n_updates            | 72          |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    value_loss           | 82.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 395         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 414         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012186385 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.36       |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.000198    |\n",
      "|    loss                 | 41.5        |\n",
      "|    n_updates            | 96          |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    value_loss           | 84          |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=188928, episode_reward=27.60 +/- 12.00\n",
      "Episode length: 25.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 25         |\n",
      "|    mean_reward          | 27.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 188928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01068517 |\n",
      "|    clip_fraction        | 0.213      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.27      |\n",
      "|    explained_variance   | 0.718      |\n",
      "|    learning_rate        | 0.000197   |\n",
      "|    loss                 | 42.2       |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0206    |\n",
      "|    value_loss           | 83.7       |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 358    |\n",
      "|    iterations      | 6      |\n",
      "|    time_elapsed    | 548    |\n",
      "|    total_timesteps | 196608 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 352         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 650         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012401865 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.19       |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.000196    |\n",
      "|    loss                 | 41.1        |\n",
      "|    n_updates            | 144         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    value_loss           | 80.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 349         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 751         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017961804 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.06       |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.000196    |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 168         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    value_loss           | 75.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 346         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 851         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012702815 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.000195    |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 192         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 72.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 344         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 951         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013287064 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.79       |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.000194    |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 216         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    value_loss           | 68.6        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=348928, episode_reward=27.75 +/- 11.84\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 27.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 348928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014664973 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.65       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.000194    |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 70.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 333    |\n",
      "|    iterations      | 11     |\n",
      "|    time_elapsed    | 1081   |\n",
      "|    total_timesteps | 360448 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1179        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013723619 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.5        |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.000193    |\n",
      "|    loss                 | 36.3        |\n",
      "|    n_updates            | 264         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 67.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 332         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 1280        |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010925898 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.33       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.000193    |\n",
      "|    loss                 | 30.9        |\n",
      "|    n_updates            | 288         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 63.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 332         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1378        |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011478219 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.21       |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.000192    |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 312         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 67.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 332         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 1477        |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013076825 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.06       |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.000191    |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 336         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 66.2        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=508928, episode_reward=28.10 +/- 10.96\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 28.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 508928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012987326 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.9        |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.000191    |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 71.8        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 325    |\n",
      "|    iterations      | 16     |\n",
      "|    time_elapsed    | 1609   |\n",
      "|    total_timesteps | 524288 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 1705        |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012020088 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.74       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00019     |\n",
      "|    loss                 | 37.1        |\n",
      "|    n_updates            | 384         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 70.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 1806        |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011217252 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.65       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.000189    |\n",
      "|    loss                 | 35.4        |\n",
      "|    n_updates            | 408         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 69.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 326         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 1905        |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009140475 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.57       |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.000189    |\n",
      "|    loss                 | 36.7        |\n",
      "|    n_updates            | 432         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 68.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 327         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 2001        |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009674294 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.41       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.000188    |\n",
      "|    loss                 | 33.8        |\n",
      "|    n_updates            | 456         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 68.2        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=668928, episode_reward=31.19 +/- 13.00\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 31.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 668928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010410023 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.27       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.000188    |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 66.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 322    |\n",
      "|    iterations      | 21     |\n",
      "|    time_elapsed    | 2131   |\n",
      "|    total_timesteps | 688128 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 2230        |\n",
      "|    total_timesteps      | 720896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009245668 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.18       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.000187    |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 504         |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 64.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 2328        |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009037159 |\n",
      "|    clip_fraction        | 0.0977      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.09       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.000186    |\n",
      "|    loss                 | 36.6        |\n",
      "|    n_updates            | 528         |\n",
      "|    policy_gradient_loss | -0.00867    |\n",
      "|    value_loss           | 72.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 2427        |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011988582 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.01       |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.000186    |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 552         |\n",
      "|    policy_gradient_loss | -0.00917    |\n",
      "|    value_loss           | 60.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 2529        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008386951 |\n",
      "|    clip_fraction        | 0.0751      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.000185    |\n",
      "|    loss                 | 32.2        |\n",
      "|    n_updates            | 576         |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    value_loss           | 60.8        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=828928, episode_reward=32.32 +/- 12.04\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 32.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 828928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010345852 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.000184    |\n",
      "|    loss                 | 27.9        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    value_loss           | 58.7        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 319    |\n",
      "|    iterations      | 26     |\n",
      "|    time_elapsed    | 2669   |\n",
      "|    total_timesteps | 851968 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 2788        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012935221 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.000184    |\n",
      "|    loss                 | 33.5        |\n",
      "|    n_updates            | 624         |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    value_loss           | 65.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 315          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 2911         |\n",
      "|    total_timesteps      | 917504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068993415 |\n",
      "|    clip_fraction        | 0.0628       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.36        |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.000183     |\n",
      "|    loss                 | 31.9         |\n",
      "|    n_updates            | 648          |\n",
      "|    policy_gradient_loss | -0.00675     |\n",
      "|    value_loss           | 60.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 3042        |\n",
      "|    total_timesteps      | 950272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005962134 |\n",
      "|    clip_fraction        | 0.0747      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.34       |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.000183    |\n",
      "|    loss                 | 31.5        |\n",
      "|    n_updates            | 672         |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    value_loss           | 62.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 310          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 3164         |\n",
      "|    total_timesteps      | 983040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067492677 |\n",
      "|    clip_fraction        | 0.0697       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.26        |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.000182     |\n",
      "|    loss                 | 31.9         |\n",
      "|    n_updates            | 696          |\n",
      "|    policy_gradient_loss | -0.00483     |\n",
      "|    value_loss           | 62.3         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=988928, episode_reward=33.74 +/- 12.66\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 33.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 988928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043141088 |\n",
      "|    clip_fraction        | 0.0368       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.23        |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.000181     |\n",
      "|    loss                 | 30.2         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.00527     |\n",
      "|    value_loss           | 61.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 305     |\n",
      "|    iterations      | 31      |\n",
      "|    time_elapsed    | 3319    |\n",
      "|    total_timesteps | 1015808 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 303          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 3453         |\n",
      "|    total_timesteps      | 1048576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055917623 |\n",
      "|    clip_fraction        | 0.0444       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.18        |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.000181     |\n",
      "|    loss                 | 26.9         |\n",
      "|    n_updates            | 744          |\n",
      "|    policy_gradient_loss | -0.00487     |\n",
      "|    value_loss           | 56.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 300          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 3598         |\n",
      "|    total_timesteps      | 1081344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067636864 |\n",
      "|    clip_fraction        | 0.0594       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.1         |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.00018      |\n",
      "|    loss                 | 27.4         |\n",
      "|    n_updates            | 768          |\n",
      "|    policy_gradient_loss | -0.00488     |\n",
      "|    value_loss           | 54.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 298          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 3734         |\n",
      "|    total_timesteps      | 1114112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035617019 |\n",
      "|    clip_fraction        | 0.0602       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.05        |\n",
      "|    explained_variance   | 0.619        |\n",
      "|    learning_rate        | 0.000179     |\n",
      "|    loss                 | 27.6         |\n",
      "|    n_updates            | 792          |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 54.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 297          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 3856         |\n",
      "|    total_timesteps      | 1146880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049668597 |\n",
      "|    clip_fraction        | 0.0404       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.01        |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.000179     |\n",
      "|    loss                 | 27.1         |\n",
      "|    n_updates            | 816          |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    value_loss           | 55.1         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1148928, episode_reward=34.71 +/- 13.20\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 34.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1148928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057433555 |\n",
      "|    clip_fraction        | 0.0512       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.000178     |\n",
      "|    loss                 | 29.5         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    value_loss           | 56.5         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 293     |\n",
      "|    iterations      | 36      |\n",
      "|    time_elapsed    | 4020    |\n",
      "|    total_timesteps | 1179648 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 292          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 4149         |\n",
      "|    total_timesteps      | 1212416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036633892 |\n",
      "|    clip_fraction        | 0.0629       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.000178     |\n",
      "|    loss                 | 30.2         |\n",
      "|    n_updates            | 864          |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    value_loss           | 58.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 291          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 4278         |\n",
      "|    total_timesteps      | 1245184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039411243 |\n",
      "|    clip_fraction        | 0.0564       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 0.000177     |\n",
      "|    loss                 | 25.7         |\n",
      "|    n_updates            | 888          |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    value_loss           | 53.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 4417         |\n",
      "|    total_timesteps      | 1277952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048273155 |\n",
      "|    clip_fraction        | 0.0442       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.87        |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.000176     |\n",
      "|    loss                 | 30.7         |\n",
      "|    n_updates            | 912          |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    value_loss           | 60.2         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1308928, episode_reward=36.39 +/- 14.62\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 36.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1308928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005070462 |\n",
      "|    clip_fraction        | 0.0419      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.000176    |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 936         |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    value_loss           | 56.2        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 285     |\n",
      "|    iterations      | 40      |\n",
      "|    time_elapsed    | 4593    |\n",
      "|    total_timesteps | 1310720 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 4717       |\n",
      "|    total_timesteps      | 1343488    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00332409 |\n",
      "|    clip_fraction        | 0.0441     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.78      |\n",
      "|    explained_variance   | 0.662      |\n",
      "|    learning_rate        | 0.000175   |\n",
      "|    loss                 | 28.4       |\n",
      "|    n_updates            | 960        |\n",
      "|    policy_gradient_loss | -0.00453   |\n",
      "|    value_loss           | 58.3       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 284          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 4833         |\n",
      "|    total_timesteps      | 1376256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044818865 |\n",
      "|    clip_fraction        | 0.0434       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.77        |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.000174     |\n",
      "|    loss                 | 26.7         |\n",
      "|    n_updates            | 984          |\n",
      "|    policy_gradient_loss | -0.00495     |\n",
      "|    value_loss           | 53.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 283          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 4973         |\n",
      "|    total_timesteps      | 1409024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032498895 |\n",
      "|    clip_fraction        | 0.0417       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.68        |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.000174     |\n",
      "|    loss                 | 26.3         |\n",
      "|    n_updates            | 1008         |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    value_loss           | 54.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 5118        |\n",
      "|    total_timesteps      | 1441792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004537713 |\n",
      "|    clip_fraction        | 0.0488      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.000173    |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 1032        |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1468928, episode_reward=35.95 +/- 13.49\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 35.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1468928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049984264 |\n",
      "|    clip_fraction        | 0.0436       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.65        |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.000173     |\n",
      "|    loss                 | 23.7         |\n",
      "|    n_updates            | 1056         |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    value_loss           | 48.4         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 277     |\n",
      "|    iterations      | 45      |\n",
      "|    time_elapsed    | 5312    |\n",
      "|    total_timesteps | 1474560 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 5454        |\n",
      "|    total_timesteps      | 1507328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012651048 |\n",
      "|    clip_fraction        | 0.0579      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.000172    |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    value_loss           | 47.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 275          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 5598         |\n",
      "|    total_timesteps      | 1540096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056973547 |\n",
      "|    clip_fraction        | 0.0403       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.000171     |\n",
      "|    loss                 | 27           |\n",
      "|    n_updates            | 1104         |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    value_loss           | 51.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 5740        |\n",
      "|    total_timesteps      | 1572864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004449802 |\n",
      "|    clip_fraction        | 0.0602      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.67        |\n",
      "|    learning_rate        | 0.000171    |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 1128        |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 272        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 5881       |\n",
      "|    total_timesteps      | 1605632    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00725956 |\n",
      "|    clip_fraction        | 0.0446     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.64      |\n",
      "|    explained_variance   | 0.689      |\n",
      "|    learning_rate        | 0.00017    |\n",
      "|    loss                 | 23.4       |\n",
      "|    n_updates            | 1152       |\n",
      "|    policy_gradient_loss | -0.00427   |\n",
      "|    value_loss           | 49.4       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1628928, episode_reward=35.89 +/- 14.20\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 35.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1628928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036373006 |\n",
      "|    clip_fraction        | 0.0535       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.74        |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.000169     |\n",
      "|    loss                 | 25.2         |\n",
      "|    n_updates            | 1176         |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 52.1         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 270     |\n",
      "|    iterations      | 50      |\n",
      "|    time_elapsed    | 6063    |\n",
      "|    total_timesteps | 1638400 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 6209        |\n",
      "|    total_timesteps      | 1671168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012430383 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.000169    |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    value_loss           | 51          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 6352        |\n",
      "|    total_timesteps      | 1703936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006083116 |\n",
      "|    clip_fraction        | 0.0477      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.000168    |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 1224        |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 268          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 6476         |\n",
      "|    total_timesteps      | 1736704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038545388 |\n",
      "|    clip_fraction        | 0.0535       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.71        |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.000168     |\n",
      "|    loss                 | 26           |\n",
      "|    n_updates            | 1248         |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    value_loss           | 51.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 6609        |\n",
      "|    total_timesteps      | 1769472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004316732 |\n",
      "|    clip_fraction        | 0.0543      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.000167    |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 1272        |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    value_loss           | 50.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1788928, episode_reward=35.59 +/- 14.38\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 35.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1788928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042458326 |\n",
      "|    clip_fraction        | 0.0449       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.64        |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.000166     |\n",
      "|    loss                 | 28.4         |\n",
      "|    n_updates            | 1296         |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    value_loss           | 54.4         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 265     |\n",
      "|    iterations      | 55      |\n",
      "|    time_elapsed    | 6791    |\n",
      "|    total_timesteps | 1802240 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 263        |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 6951       |\n",
      "|    total_timesteps      | 1835008    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00914922 |\n",
      "|    clip_fraction        | 0.0668     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.66      |\n",
      "|    explained_variance   | 0.681      |\n",
      "|    learning_rate        | 0.000166   |\n",
      "|    loss                 | 27.3       |\n",
      "|    n_updates            | 1320       |\n",
      "|    policy_gradient_loss | -0.00255   |\n",
      "|    value_loss           | 53.9       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 262          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 7106         |\n",
      "|    total_timesteps      | 1867776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072615603 |\n",
      "|    clip_fraction        | 0.0477       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.7         |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.000165     |\n",
      "|    loss                 | 28.9         |\n",
      "|    n_updates            | 1344         |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    value_loss           | 55.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 7235        |\n",
      "|    total_timesteps      | 1900544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003947835 |\n",
      "|    clip_fraction        | 0.0514      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.000165    |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 1368        |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    value_loss           | 49.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 262          |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 7359         |\n",
      "|    total_timesteps      | 1933312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040259073 |\n",
      "|    clip_fraction        | 0.0478       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.57        |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.000164     |\n",
      "|    loss                 | 25.6         |\n",
      "|    n_updates            | 1392         |\n",
      "|    policy_gradient_loss | -0.00442     |\n",
      "|    value_loss           | 50.2         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1948928, episode_reward=35.30 +/- 13.25\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 35.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1948928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004311217 |\n",
      "|    clip_fraction        | 0.0581      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.000163    |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 1416        |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    value_loss           | 51.6        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 261     |\n",
      "|    iterations      | 60      |\n",
      "|    time_elapsed    | 7504    |\n",
      "|    total_timesteps | 1966080 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 7609        |\n",
      "|    total_timesteps      | 1998848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004077835 |\n",
      "|    clip_fraction        | 0.0378      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.000163    |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    value_loss           | 50.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 7717        |\n",
      "|    total_timesteps      | 2031616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004345891 |\n",
      "|    clip_fraction        | 0.0652      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.000162    |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 1464        |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    value_loss           | 53.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 7825        |\n",
      "|    total_timesteps      | 2064384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007697723 |\n",
      "|    clip_fraction        | 0.045       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.000161    |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 1488        |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    value_loss           | 52.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 264          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 7936         |\n",
      "|    total_timesteps      | 2097152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034178616 |\n",
      "|    clip_fraction        | 0.0441       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.46        |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.000161     |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 1512         |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    value_loss           | 50.2         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2108928, episode_reward=36.11 +/- 14.10\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 36.1         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2108928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052862996 |\n",
      "|    clip_fraction        | 0.0647       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.47        |\n",
      "|    explained_variance   | 0.691        |\n",
      "|    learning_rate        | 0.00016      |\n",
      "|    loss                 | 24.6         |\n",
      "|    n_updates            | 1536         |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    value_loss           | 50.5         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 263     |\n",
      "|    iterations      | 65      |\n",
      "|    time_elapsed    | 8085    |\n",
      "|    total_timesteps | 2129920 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 263          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 8197         |\n",
      "|    total_timesteps      | 2162688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038785134 |\n",
      "|    clip_fraction        | 0.0629       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.5         |\n",
      "|    explained_variance   | 0.703        |\n",
      "|    learning_rate        | 0.00016      |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 1560         |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 46.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 8303        |\n",
      "|    total_timesteps      | 2195456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006211302 |\n",
      "|    clip_fraction        | 0.0502      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.000159    |\n",
      "|    loss                 | 25.6        |\n",
      "|    n_updates            | 1584        |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    value_loss           | 51.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 264          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 8412         |\n",
      "|    total_timesteps      | 2228224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056639863 |\n",
      "|    clip_fraction        | 0.0575       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.691        |\n",
      "|    learning_rate        | 0.000158     |\n",
      "|    loss                 | 24.7         |\n",
      "|    n_updates            | 1608         |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 51           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 265          |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 8523         |\n",
      "|    total_timesteps      | 2260992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060574193 |\n",
      "|    clip_fraction        | 0.0452       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | 0.705        |\n",
      "|    learning_rate        | 0.000158     |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 1632         |\n",
      "|    policy_gradient_loss | -0.0049      |\n",
      "|    value_loss           | 48.2         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2268928, episode_reward=35.79 +/- 13.47\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 35.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2268928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004528823 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.000157    |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 1656        |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    value_loss           | 49          |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 264     |\n",
      "|    iterations      | 70      |\n",
      "|    time_elapsed    | 8661    |\n",
      "|    total_timesteps | 2293760 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 265          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 8769         |\n",
      "|    total_timesteps      | 2326528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040954864 |\n",
      "|    clip_fraction        | 0.0784       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0.686        |\n",
      "|    learning_rate        | 0.000156     |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 1680         |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    value_loss           | 49.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 265          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 8875         |\n",
      "|    total_timesteps      | 2359296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054598404 |\n",
      "|    clip_fraction        | 0.0464       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.000156     |\n",
      "|    loss                 | 24.2         |\n",
      "|    n_updates            | 1704         |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    value_loss           | 49.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 8981        |\n",
      "|    total_timesteps      | 2392064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003931553 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.000155    |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 1728        |\n",
      "|    policy_gradient_loss | -0.0036     |\n",
      "|    value_loss           | 47.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 9089        |\n",
      "|    total_timesteps      | 2424832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008547257 |\n",
      "|    clip_fraction        | 0.0743      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.000155    |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 1752        |\n",
      "|    policy_gradient_loss | -0.00228    |\n",
      "|    value_loss           | 49.6        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2428928, episode_reward=35.74 +/- 13.99\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 35.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2428928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003851152 |\n",
      "|    clip_fraction        | 0.0427      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.000154    |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 1776        |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    value_loss           | 50.2        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 265     |\n",
      "|    iterations      | 75      |\n",
      "|    time_elapsed    | 9243    |\n",
      "|    total_timesteps | 2457600 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 265          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 9369         |\n",
      "|    total_timesteps      | 2490368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053428477 |\n",
      "|    clip_fraction        | 0.051        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.000153     |\n",
      "|    loss                 | 25.4         |\n",
      "|    n_updates            | 1800         |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    value_loss           | 48           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 9496        |\n",
      "|    total_timesteps      | 2523136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004940006 |\n",
      "|    clip_fraction        | 0.0488      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 0.000153    |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 1824        |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    value_loss           | 45.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 265          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 9613         |\n",
      "|    total_timesteps      | 2555904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074815946 |\n",
      "|    clip_fraction        | 0.0427       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.707        |\n",
      "|    learning_rate        | 0.000152     |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 1848         |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    value_loss           | 49.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 265          |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 9735         |\n",
      "|    total_timesteps      | 2588672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039408994 |\n",
      "|    clip_fraction        | 0.0512       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.52        |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.000151     |\n",
      "|    loss                 | 22.6         |\n",
      "|    n_updates            | 1872         |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 48.3         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2588928, episode_reward=36.25 +/- 14.49\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 36.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2588928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007187328 |\n",
      "|    clip_fraction        | 0.0581      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.000151    |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 1896        |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    value_loss           | 51.8        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 265     |\n",
      "|    iterations      | 80      |\n",
      "|    time_elapsed    | 9885    |\n",
      "|    total_timesteps | 2621440 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 10003       |\n",
      "|    total_timesteps      | 2654208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004695989 |\n",
      "|    clip_fraction        | 0.0894      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.00015     |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.00115    |\n",
      "|    value_loss           | 50.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 265          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 10105        |\n",
      "|    total_timesteps      | 2686976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039524613 |\n",
      "|    clip_fraction        | 0.0549       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.48        |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.00015      |\n",
      "|    loss                 | 25.8         |\n",
      "|    n_updates            | 1944         |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 50.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 266          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 10196        |\n",
      "|    total_timesteps      | 2719744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044523682 |\n",
      "|    clip_fraction        | 0.0399       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.000149     |\n",
      "|    loss                 | 25.5         |\n",
      "|    n_updates            | 1968         |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    value_loss           | 48.4         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2748928, episode_reward=36.09 +/- 14.39\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 36.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2748928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010774331 |\n",
      "|    clip_fraction        | 0.0736      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.000148    |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 1992        |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    value_loss           | 47.6        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 267     |\n",
      "|    iterations      | 84      |\n",
      "|    time_elapsed    | 10302   |\n",
      "|    total_timesteps | 2752512 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 268          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 10380        |\n",
      "|    total_timesteps      | 2785280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041031134 |\n",
      "|    clip_fraction        | 0.0422       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.49        |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.000148     |\n",
      "|    loss                 | 28.1         |\n",
      "|    n_updates            | 2016         |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    value_loss           | 50.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 269          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 10459        |\n",
      "|    total_timesteps      | 2818048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036157412 |\n",
      "|    clip_fraction        | 0.0555       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.5         |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.000147     |\n",
      "|    loss                 | 27.8         |\n",
      "|    n_updates            | 2040         |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    value_loss           | 54.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 10536       |\n",
      "|    total_timesteps      | 2850816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005819248 |\n",
      "|    clip_fraction        | 0.0503      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.000146    |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 2064        |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    value_loss           | 56.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 271          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 10614        |\n",
      "|    total_timesteps      | 2883584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041007325 |\n",
      "|    clip_fraction        | 0.0656       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 0.686        |\n",
      "|    learning_rate        | 0.000146     |\n",
      "|    loss                 | 25.7         |\n",
      "|    n_updates            | 2088         |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    value_loss           | 51           |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2908928, episode_reward=36.76 +/- 15.11\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 36.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2908928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011985939 |\n",
      "|    clip_fraction        | 0.0636      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.000145    |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 2112        |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    value_loss           | 54.9        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 272     |\n",
      "|    iterations      | 89      |\n",
      "|    time_elapsed    | 10719   |\n",
      "|    total_timesteps | 2916352 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 273          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 10795        |\n",
      "|    total_timesteps      | 2949120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073999576 |\n",
      "|    clip_fraction        | 0.0571       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.000145     |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 2136         |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    value_loss           | 48.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 274          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 10873        |\n",
      "|    total_timesteps      | 2981888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034797834 |\n",
      "|    clip_fraction        | 0.0958       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.46        |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.000144     |\n",
      "|    loss                 | 26.5         |\n",
      "|    n_updates            | 2160         |\n",
      "|    policy_gradient_loss | 0.00168      |\n",
      "|    value_loss           | 53.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 10952       |\n",
      "|    total_timesteps      | 3014656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022930501 |\n",
      "|    clip_fraction        | 0.085       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.000143    |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 2184        |\n",
      "|    policy_gradient_loss | -0.000643   |\n",
      "|    value_loss           | 52.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 276          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 11028        |\n",
      "|    total_timesteps      | 3047424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044218395 |\n",
      "|    clip_fraction        | 0.0446       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.686        |\n",
      "|    learning_rate        | 0.000143     |\n",
      "|    loss                 | 26           |\n",
      "|    n_updates            | 2208         |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    value_loss           | 52.9         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3068928, episode_reward=37.82 +/- 15.56\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 37.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3068928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005874337 |\n",
      "|    clip_fraction        | 0.0517      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.000142    |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 2232        |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    value_loss           | 50.5        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 276     |\n",
      "|    iterations      | 94      |\n",
      "|    time_elapsed    | 11130   |\n",
      "|    total_timesteps | 3080192 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 11209       |\n",
      "|    total_timesteps      | 3112960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004869765 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.000141    |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 2256        |\n",
      "|    policy_gradient_loss | 0.00524     |\n",
      "|    value_loss           | 48.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 11287       |\n",
      "|    total_timesteps      | 3145728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003462045 |\n",
      "|    clip_fraction        | 0.0366      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.000141    |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 2280        |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    value_loss           | 52          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 279          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 11361        |\n",
      "|    total_timesteps      | 3178496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039389683 |\n",
      "|    clip_fraction        | 0.0503       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.00014      |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 2304         |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    value_loss           | 48           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 280          |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 11438        |\n",
      "|    total_timesteps      | 3211264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038000322 |\n",
      "|    clip_fraction        | 0.0455       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.691        |\n",
      "|    learning_rate        | 0.00014      |\n",
      "|    loss                 | 27.4         |\n",
      "|    n_updates            | 2328         |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    value_loss           | 53.2         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3228928, episode_reward=36.32 +/- 15.55\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 36.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3228928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043341974 |\n",
      "|    clip_fraction        | 0.0582       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.000139     |\n",
      "|    loss                 | 25.5         |\n",
      "|    n_updates            | 2352         |\n",
      "|    policy_gradient_loss | -0.0015      |\n",
      "|    value_loss           | 48.4         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 281     |\n",
      "|    iterations      | 99      |\n",
      "|    time_elapsed    | 11544   |\n",
      "|    total_timesteps | 3244032 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 282          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 11619        |\n",
      "|    total_timesteps      | 3276800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035066835 |\n",
      "|    clip_fraction        | 0.0351       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0.705        |\n",
      "|    learning_rate        | 0.000138     |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 2376         |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    value_loss           | 49.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 11696       |\n",
      "|    total_timesteps      | 3309568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008794218 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.000138    |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 2400        |\n",
      "|    policy_gradient_loss | -0.00199    |\n",
      "|    value_loss           | 53.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 283          |\n",
      "|    iterations           | 102          |\n",
      "|    time_elapsed         | 11773        |\n",
      "|    total_timesteps      | 3342336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068847323 |\n",
      "|    clip_fraction        | 0.0615       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.000137     |\n",
      "|    loss                 | 25.1         |\n",
      "|    n_updates            | 2424         |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    value_loss           | 49.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 284          |\n",
      "|    iterations           | 103          |\n",
      "|    time_elapsed         | 11851        |\n",
      "|    total_timesteps      | 3375104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038118446 |\n",
      "|    clip_fraction        | 0.0449       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.000136     |\n",
      "|    loss                 | 27.7         |\n",
      "|    n_updates            | 2448         |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 52.3         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3388928, episode_reward=37.11 +/- 15.60\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 37.1         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3388928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040188623 |\n",
      "|    clip_fraction        | 0.0458       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.000136     |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 2472         |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    value_loss           | 48.9         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 285     |\n",
      "|    iterations      | 104     |\n",
      "|    time_elapsed    | 11953   |\n",
      "|    total_timesteps | 3407872 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 12031       |\n",
      "|    total_timesteps      | 3440640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008653719 |\n",
      "|    clip_fraction        | 0.054       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.000135    |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 2496        |\n",
      "|    policy_gradient_loss | -0.00266    |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 12112       |\n",
      "|    total_timesteps      | 3473408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005985812 |\n",
      "|    clip_fraction        | 0.0801      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.000135    |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | -0.00197    |\n",
      "|    value_loss           | 47.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 12194       |\n",
      "|    total_timesteps      | 3506176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008109845 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.721       |\n",
      "|    learning_rate        | 0.000134    |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 2544        |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    value_loss           | 45.3        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 288       |\n",
      "|    iterations           | 108       |\n",
      "|    time_elapsed         | 12271     |\n",
      "|    total_timesteps      | 3538944   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0049676 |\n",
      "|    clip_fraction        | 0.0505    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.1      |\n",
      "|    explained_variance   | 0.704     |\n",
      "|    learning_rate        | 0.000133  |\n",
      "|    loss                 | 24.2      |\n",
      "|    n_updates            | 2568      |\n",
      "|    policy_gradient_loss | -0.00345  |\n",
      "|    value_loss           | 49.4      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=3548928, episode_reward=37.28 +/- 14.83\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 37.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3548928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055885683 |\n",
      "|    clip_fraction        | 0.0472       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | 0.705        |\n",
      "|    learning_rate        | 0.000133     |\n",
      "|    loss                 | 24           |\n",
      "|    n_updates            | 2592         |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    value_loss           | 49.2         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 288     |\n",
      "|    iterations      | 109     |\n",
      "|    time_elapsed    | 12377   |\n",
      "|    total_timesteps | 3571712 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 110          |\n",
      "|    time_elapsed         | 12454        |\n",
      "|    total_timesteps      | 3604480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048334785 |\n",
      "|    clip_fraction        | 0.045        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.11        |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.000132     |\n",
      "|    loss                 | 24.6         |\n",
      "|    n_updates            | 2616         |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    value_loss           | 51.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 12532       |\n",
      "|    total_timesteps      | 3637248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003109596 |\n",
      "|    clip_fraction        | 0.054       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.000132    |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 2640        |\n",
      "|    policy_gradient_loss | -0.00131    |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 291          |\n",
      "|    iterations           | 112          |\n",
      "|    time_elapsed         | 12608        |\n",
      "|    total_timesteps      | 3670016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034949621 |\n",
      "|    clip_fraction        | 0.0431       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.000131     |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 2664         |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    value_loss           | 46.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 291          |\n",
      "|    iterations           | 113          |\n",
      "|    time_elapsed         | 12684        |\n",
      "|    total_timesteps      | 3702784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043558436 |\n",
      "|    clip_fraction        | 0.0902       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 0.00013      |\n",
      "|    loss                 | 23.7         |\n",
      "|    n_updates            | 2688         |\n",
      "|    policy_gradient_loss | 0.00077      |\n",
      "|    value_loss           | 46.7         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3708928, episode_reward=36.63 +/- 13.65\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 36.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3708928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005619486 |\n",
      "|    clip_fraction        | 0.0431      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.00013     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 2712        |\n",
      "|    policy_gradient_loss | -0.00397    |\n",
      "|    value_loss           | 46.4        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 292     |\n",
      "|    iterations      | 114     |\n",
      "|    time_elapsed    | 12787   |\n",
      "|    total_timesteps | 3735552 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 292          |\n",
      "|    iterations           | 115          |\n",
      "|    time_elapsed         | 12862        |\n",
      "|    total_timesteps      | 3768320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027149827 |\n",
      "|    clip_fraction        | 0.0686       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.977       |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.000129     |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 2736         |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    value_loss           | 47.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 293          |\n",
      "|    iterations           | 116          |\n",
      "|    time_elapsed         | 12939        |\n",
      "|    total_timesteps      | 3801088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037982685 |\n",
      "|    clip_fraction        | 0.0507       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.952       |\n",
      "|    explained_variance   | 0.718        |\n",
      "|    learning_rate        | 0.000128     |\n",
      "|    loss                 | 23.2         |\n",
      "|    n_updates            | 2760         |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    value_loss           | 48.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 294          |\n",
      "|    iterations           | 117          |\n",
      "|    time_elapsed         | 13016        |\n",
      "|    total_timesteps      | 3833856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037625958 |\n",
      "|    clip_fraction        | 0.0449       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.942       |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.000128     |\n",
      "|    loss                 | 21.8         |\n",
      "|    n_updates            | 2784         |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 44.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 295         |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 13092       |\n",
      "|    total_timesteps      | 3866624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006052357 |\n",
      "|    clip_fraction        | 0.0564      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.92       |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.000127    |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 2808        |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    value_loss           | 43.7        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3868928, episode_reward=36.56 +/- 15.13\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 36.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3868928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042093387 |\n",
      "|    clip_fraction        | 0.0404       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.913       |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.000127     |\n",
      "|    loss                 | 21.8         |\n",
      "|    n_updates            | 2832         |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    value_loss           | 48.2         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 295     |\n",
      "|    iterations      | 119     |\n",
      "|    time_elapsed    | 13196   |\n",
      "|    total_timesteps | 3899392 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 296          |\n",
      "|    iterations           | 120          |\n",
      "|    time_elapsed         | 13272        |\n",
      "|    total_timesteps      | 3932160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059287935 |\n",
      "|    clip_fraction        | 0.0442       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.885       |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.000126     |\n",
      "|    loss                 | 23.2         |\n",
      "|    n_updates            | 2856         |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 45.9         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 297        |\n",
      "|    iterations           | 121        |\n",
      "|    time_elapsed         | 13349      |\n",
      "|    total_timesteps      | 3964928    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00563284 |\n",
      "|    clip_fraction        | 0.0474     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.865     |\n",
      "|    explained_variance   | 0.728      |\n",
      "|    learning_rate        | 0.000125   |\n",
      "|    loss                 | 23.2       |\n",
      "|    n_updates            | 2880       |\n",
      "|    policy_gradient_loss | -0.00306   |\n",
      "|    value_loss           | 48.2       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 297          |\n",
      "|    iterations           | 122          |\n",
      "|    time_elapsed         | 13425        |\n",
      "|    total_timesteps      | 3997696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065157674 |\n",
      "|    clip_fraction        | 0.0382       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.867       |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.000125     |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 2904         |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 48.5         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4028928, episode_reward=36.91 +/- 14.57\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 36.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4028928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043064957 |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.811       |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.000124     |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 2928         |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 42.8         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 297     |\n",
      "|    iterations      | 123     |\n",
      "|    time_elapsed    | 13537   |\n",
      "|    total_timesteps | 4030464 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 298        |\n",
      "|    iterations           | 124        |\n",
      "|    time_elapsed         | 13617      |\n",
      "|    total_timesteps      | 4063232    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00505353 |\n",
      "|    clip_fraction        | 0.054      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.793     |\n",
      "|    explained_variance   | 0.73       |\n",
      "|    learning_rate        | 0.000123   |\n",
      "|    loss                 | 22.6       |\n",
      "|    n_updates            | 2952       |\n",
      "|    policy_gradient_loss | -0.00243   |\n",
      "|    value_loss           | 44.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 298          |\n",
      "|    iterations           | 125          |\n",
      "|    time_elapsed         | 13700        |\n",
      "|    total_timesteps      | 4096000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044690063 |\n",
      "|    clip_fraction        | 0.0442       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.799       |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 0.000123     |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 2976         |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    value_loss           | 46.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 299          |\n",
      "|    iterations           | 126          |\n",
      "|    time_elapsed         | 13783        |\n",
      "|    total_timesteps      | 4128768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035462878 |\n",
      "|    clip_fraction        | 0.0421       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.803       |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.000122     |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 3000         |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 44.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 300          |\n",
      "|    iterations           | 127          |\n",
      "|    time_elapsed         | 13866        |\n",
      "|    total_timesteps      | 4161536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040230043 |\n",
      "|    clip_fraction        | 0.035        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.797       |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 0.000122     |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 3024         |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    value_loss           | 42           |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4188928, episode_reward=37.41 +/- 15.17\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 37.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4188928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005140893 |\n",
      "|    clip_fraction        | 0.0498      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.785      |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.000121    |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 3048        |\n",
      "|    policy_gradient_loss | -0.00249    |\n",
      "|    value_loss           | 45          |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 300     |\n",
      "|    iterations      | 128     |\n",
      "|    time_elapsed    | 13977   |\n",
      "|    total_timesteps | 4194304 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 300          |\n",
      "|    iterations           | 129          |\n",
      "|    time_elapsed         | 14060        |\n",
      "|    total_timesteps      | 4227072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029386762 |\n",
      "|    clip_fraction        | 0.0449       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.776       |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.00012      |\n",
      "|    loss                 | 22.5         |\n",
      "|    n_updates            | 3072         |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    value_loss           | 45.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 301          |\n",
      "|    iterations           | 130          |\n",
      "|    time_elapsed         | 14143        |\n",
      "|    total_timesteps      | 4259840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033783517 |\n",
      "|    clip_fraction        | 0.0428       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.76        |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.00012      |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 3096         |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    value_loss           | 44.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 301          |\n",
      "|    iterations           | 131          |\n",
      "|    time_elapsed         | 14226        |\n",
      "|    total_timesteps      | 4292608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028323417 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.753       |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.000119     |\n",
      "|    loss                 | 22.3         |\n",
      "|    n_updates            | 3120         |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    value_loss           | 44.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 302          |\n",
      "|    iterations           | 132          |\n",
      "|    time_elapsed         | 14308        |\n",
      "|    total_timesteps      | 4325376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038638022 |\n",
      "|    clip_fraction        | 0.0581       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.76        |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.000118     |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 3144         |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    value_loss           | 43.9         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4348928, episode_reward=35.65 +/- 14.12\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 35.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4348928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003301524 |\n",
      "|    clip_fraction        | 0.0421      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.736      |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.000118    |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 3168        |\n",
      "|    policy_gradient_loss | -0.00244    |\n",
      "|    value_loss           | 43.1        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 302     |\n",
      "|    iterations      | 133     |\n",
      "|    time_elapsed    | 14417   |\n",
      "|    total_timesteps | 4358144 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 14498       |\n",
      "|    total_timesteps      | 4390912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004122222 |\n",
      "|    clip_fraction        | 0.0487      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.71       |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.000117    |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 3192        |\n",
      "|    policy_gradient_loss | -0.00271    |\n",
      "|    value_loss           | 41.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 303          |\n",
      "|    iterations           | 135          |\n",
      "|    time_elapsed         | 14582        |\n",
      "|    total_timesteps      | 4423680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041330573 |\n",
      "|    clip_fraction        | 0.0379       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.735       |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 0.000117     |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 3216         |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    value_loss           | 40.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 303          |\n",
      "|    iterations           | 136          |\n",
      "|    time_elapsed         | 14664        |\n",
      "|    total_timesteps      | 4456448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038620401 |\n",
      "|    clip_fraction        | 0.0338       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.718       |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.000116     |\n",
      "|    loss                 | 21.3         |\n",
      "|    n_updates            | 3240         |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    value_loss           | 42.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 304          |\n",
      "|    iterations           | 137          |\n",
      "|    time_elapsed         | 14746        |\n",
      "|    total_timesteps      | 4489216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030890994 |\n",
      "|    clip_fraction        | 0.0357       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.727       |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.000115     |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 3264         |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    value_loss           | 43.5         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4508928, episode_reward=37.04 +/- 15.31\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 37           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4508928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025581704 |\n",
      "|    clip_fraction        | 0.0412       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.727       |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.000115     |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 3288         |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    value_loss           | 44.2         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 304     |\n",
      "|    iterations      | 138     |\n",
      "|    time_elapsed    | 14856   |\n",
      "|    total_timesteps | 4521984 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 14938       |\n",
      "|    total_timesteps      | 4554752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003778331 |\n",
      "|    clip_fraction        | 0.0554      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.713      |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.000114    |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 3312        |\n",
      "|    policy_gradient_loss | -0.00248    |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 305          |\n",
      "|    iterations           | 140          |\n",
      "|    time_elapsed         | 15020        |\n",
      "|    total_timesteps      | 4587520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036445737 |\n",
      "|    clip_fraction        | 0.0488       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.694       |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.000113     |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 3336         |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    value_loss           | 45.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 15102       |\n",
      "|    total_timesteps      | 4620288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003191778 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.668      |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.000113    |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 3360        |\n",
      "|    policy_gradient_loss | -0.00301    |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 15183       |\n",
      "|    total_timesteps      | 4653056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006606532 |\n",
      "|    clip_fraction        | 0.0445      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.675      |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.000112    |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 3384        |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4668928, episode_reward=37.73 +/- 15.43\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 37.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4668928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004691528 |\n",
      "|    clip_fraction        | 0.0582      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.68       |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.000112    |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 3408        |\n",
      "|    policy_gradient_loss | -0.00158    |\n",
      "|    value_loss           | 44.2        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 306     |\n",
      "|    iterations      | 143     |\n",
      "|    time_elapsed    | 15293   |\n",
      "|    total_timesteps | 4685824 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 15376       |\n",
      "|    total_timesteps      | 4718592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003325982 |\n",
      "|    clip_fraction        | 0.038       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.715      |\n",
      "|    explained_variance   | 0.725       |\n",
      "|    learning_rate        | 0.000111    |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 3432        |\n",
      "|    policy_gradient_loss | -0.00284    |\n",
      "|    value_loss           | 46.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 15458       |\n",
      "|    total_timesteps      | 4751360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004313353 |\n",
      "|    clip_fraction        | 0.0344      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.698      |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.00011     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 3456        |\n",
      "|    policy_gradient_loss | -0.00263    |\n",
      "|    value_loss           | 46.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 15539       |\n",
      "|    total_timesteps      | 4784128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008025935 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.725      |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.00011     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 3480        |\n",
      "|    policy_gradient_loss | -0.0018     |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 15621       |\n",
      "|    total_timesteps      | 4816896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002976512 |\n",
      "|    clip_fraction        | 0.039       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.733      |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.000109    |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 3504        |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    value_loss           | 45.2        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4828928, episode_reward=36.43 +/- 14.41\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 36.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4828928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032956605 |\n",
      "|    clip_fraction        | 0.0446       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.723       |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.000108     |\n",
      "|    loss                 | 23.1         |\n",
      "|    n_updates            | 3528         |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    value_loss           | 42.5         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 308     |\n",
      "|    iterations      | 148     |\n",
      "|    time_elapsed    | 15731   |\n",
      "|    total_timesteps | 4849664 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 308        |\n",
      "|    iterations           | 149        |\n",
      "|    time_elapsed         | 15812      |\n",
      "|    total_timesteps      | 4882432    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00428696 |\n",
      "|    clip_fraction        | 0.0471     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.713     |\n",
      "|    explained_variance   | 0.72       |\n",
      "|    learning_rate        | 0.000108   |\n",
      "|    loss                 | 25.5       |\n",
      "|    n_updates            | 3552       |\n",
      "|    policy_gradient_loss | -0.0026    |\n",
      "|    value_loss           | 47.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 309          |\n",
      "|    iterations           | 150          |\n",
      "|    time_elapsed         | 15896        |\n",
      "|    total_timesteps      | 4915200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037477731 |\n",
      "|    clip_fraction        | 0.0452       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.705       |\n",
      "|    explained_variance   | 0.719        |\n",
      "|    learning_rate        | 0.000107     |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 3576         |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    value_loss           | 45.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 15978       |\n",
      "|    total_timesteps      | 4947968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033635654 |\n",
      "|    clip_fraction        | 0.0739      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.707      |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.000107    |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 3600        |\n",
      "|    policy_gradient_loss | 0.000668    |\n",
      "|    value_loss           | 44.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 310          |\n",
      "|    iterations           | 152          |\n",
      "|    time_elapsed         | 16060        |\n",
      "|    total_timesteps      | 4980736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022776364 |\n",
      "|    clip_fraction        | 0.0369       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.714       |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 0.000106     |\n",
      "|    loss                 | 22.7         |\n",
      "|    n_updates            | 3624         |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    value_loss           | 46.7         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4988928, episode_reward=36.75 +/- 15.11\n",
      "Episode length: 25.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 25         |\n",
      "|    mean_reward          | 36.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4988928    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00335313 |\n",
      "|    clip_fraction        | 0.0379     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.703     |\n",
      "|    explained_variance   | 0.732      |\n",
      "|    learning_rate        | 0.000105   |\n",
      "|    loss                 | 20.6       |\n",
      "|    n_updates            | 3648       |\n",
      "|    policy_gradient_loss | -0.00333   |\n",
      "|    value_loss           | 43.2       |\n",
      "----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 310     |\n",
      "|    iterations      | 153     |\n",
      "|    time_elapsed    | 16172   |\n",
      "|    total_timesteps | 5013504 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 310          |\n",
      "|    iterations           | 154          |\n",
      "|    time_elapsed         | 16253        |\n",
      "|    total_timesteps      | 5046272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030903025 |\n",
      "|    clip_fraction        | 0.028        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.694       |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 0.000105     |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 3672         |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    value_loss           | 46.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 310          |\n",
      "|    iterations           | 155          |\n",
      "|    time_elapsed         | 16336        |\n",
      "|    total_timesteps      | 5079040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024174848 |\n",
      "|    clip_fraction        | 0.0378       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.689       |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.000104     |\n",
      "|    loss                 | 23           |\n",
      "|    n_updates            | 3696         |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    value_loss           | 46.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 311          |\n",
      "|    iterations           | 156          |\n",
      "|    time_elapsed         | 16419        |\n",
      "|    total_timesteps      | 5111808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043709716 |\n",
      "|    clip_fraction        | 0.0668       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.703       |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.000103     |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 3720         |\n",
      "|    policy_gradient_loss | 0.00125      |\n",
      "|    value_loss           | 49.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 157         |\n",
      "|    time_elapsed         | 16501       |\n",
      "|    total_timesteps      | 5144576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005165009 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.709      |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.000103    |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 3744        |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5148928, episode_reward=37.04 +/- 14.45\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 37           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5148928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032168617 |\n",
      "|    clip_fraction        | 0.0416       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.713       |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 0.000102     |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 3768         |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    value_loss           | 46.6         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 311     |\n",
      "|    iterations      | 158     |\n",
      "|    time_elapsed    | 16612   |\n",
      "|    total_timesteps | 5177344 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 312          |\n",
      "|    iterations           | 159          |\n",
      "|    time_elapsed         | 16693        |\n",
      "|    total_timesteps      | 5210112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037540058 |\n",
      "|    clip_fraction        | 0.0386       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.71        |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.000102     |\n",
      "|    loss                 | 22.3         |\n",
      "|    n_updates            | 3792         |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    value_loss           | 43.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 312          |\n",
      "|    iterations           | 160          |\n",
      "|    time_elapsed         | 16775        |\n",
      "|    total_timesteps      | 5242880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034277157 |\n",
      "|    clip_fraction        | 0.0473       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.723       |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.000101     |\n",
      "|    loss                 | 23           |\n",
      "|    n_updates            | 3816         |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    value_loss           | 43.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 312          |\n",
      "|    iterations           | 161          |\n",
      "|    time_elapsed         | 16856        |\n",
      "|    total_timesteps      | 5275648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044402275 |\n",
      "|    clip_fraction        | 0.0368       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.718       |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 3840         |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    value_loss           | 46.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 16938       |\n",
      "|    total_timesteps      | 5308416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004118887 |\n",
      "|    clip_fraction        | 0.0401      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.731      |\n",
      "|    explained_variance   | 0.725       |\n",
      "|    learning_rate        | 9.98e-05    |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 3864        |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    value_loss           | 44.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5308928, episode_reward=36.27 +/- 14.89\n",
      "Episode length: 25.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 25        |\n",
      "|    mean_reward          | 36.3      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 5308928   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0047197 |\n",
      "|    clip_fraction        | 0.0382    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.732    |\n",
      "|    explained_variance   | 0.72      |\n",
      "|    learning_rate        | 9.91e-05  |\n",
      "|    loss                 | 22.8      |\n",
      "|    n_updates            | 3888      |\n",
      "|    policy_gradient_loss | -0.0028   |\n",
      "|    value_loss           | 48.1      |\n",
      "---------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 313     |\n",
      "|    iterations      | 163     |\n",
      "|    time_elapsed    | 17050   |\n",
      "|    total_timesteps | 5341184 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 17133       |\n",
      "|    total_timesteps      | 5373952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003257336 |\n",
      "|    clip_fraction        | 0.035       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.741      |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 9.85e-05    |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 3912        |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    value_loss           | 49.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 314          |\n",
      "|    iterations           | 165          |\n",
      "|    time_elapsed         | 17217        |\n",
      "|    total_timesteps      | 5406720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050790585 |\n",
      "|    clip_fraction        | 0.0408       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.705       |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 9.79e-05     |\n",
      "|    loss                 | 22.3         |\n",
      "|    n_updates            | 3936         |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    value_loss           | 50.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 314          |\n",
      "|    iterations           | 166          |\n",
      "|    time_elapsed         | 17298        |\n",
      "|    total_timesteps      | 5439488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031610918 |\n",
      "|    clip_fraction        | 0.0394       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.727       |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 9.73e-05     |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 3960         |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    value_loss           | 49.5         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5468928, episode_reward=37.37 +/- 14.38\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 37.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5468928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002903631 |\n",
      "|    clip_fraction        | 0.0414      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.733      |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 9.66e-05    |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 3984        |\n",
      "|    policy_gradient_loss | -0.00224    |\n",
      "|    value_loss           | 47.9        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 314     |\n",
      "|    iterations      | 167     |\n",
      "|    time_elapsed    | 17409   |\n",
      "|    total_timesteps | 5472256 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 314          |\n",
      "|    iterations           | 168          |\n",
      "|    time_elapsed         | 17487        |\n",
      "|    total_timesteps      | 5505024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022061695 |\n",
      "|    clip_fraction        | 0.0295       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.727       |\n",
      "|    explained_variance   | 0.705        |\n",
      "|    learning_rate        | 9.6e-05      |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 4008         |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    value_loss           | 49.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 17563       |\n",
      "|    total_timesteps      | 5537792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003171336 |\n",
      "|    clip_fraction        | 0.0377      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.737      |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 9.54e-05    |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 4032        |\n",
      "|    policy_gradient_loss | -0.00228    |\n",
      "|    value_loss           | 50.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 17638       |\n",
      "|    total_timesteps      | 5570560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003359609 |\n",
      "|    clip_fraction        | 0.03        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.752      |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 9.48e-05    |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 4056        |\n",
      "|    policy_gradient_loss | -0.00244    |\n",
      "|    value_loss           | 49.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 316          |\n",
      "|    iterations           | 171          |\n",
      "|    time_elapsed         | 17714        |\n",
      "|    total_timesteps      | 5603328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020992986 |\n",
      "|    clip_fraction        | 0.0338       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.756       |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 9.42e-05     |\n",
      "|    loss                 | 27.6         |\n",
      "|    n_updates            | 4080         |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    value_loss           | 53.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5628928, episode_reward=36.48 +/- 15.16\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 36.5         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5628928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016872529 |\n",
      "|    clip_fraction        | 0.0442       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.74        |\n",
      "|    explained_variance   | 0.715        |\n",
      "|    learning_rate        | 9.35e-05     |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 4104         |\n",
      "|    policy_gradient_loss | -0.000614    |\n",
      "|    value_loss           | 48.8         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 316     |\n",
      "|    iterations      | 172     |\n",
      "|    time_elapsed    | 17818   |\n",
      "|    total_timesteps | 5636096 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 17893       |\n",
      "|    total_timesteps      | 5668864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003168669 |\n",
      "|    clip_fraction        | 0.0441      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.737      |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 9.29e-05    |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 4128        |\n",
      "|    policy_gradient_loss | -0.00204    |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 317          |\n",
      "|    iterations           | 174          |\n",
      "|    time_elapsed         | 17969        |\n",
      "|    total_timesteps      | 5701632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047266395 |\n",
      "|    clip_fraction        | 0.0545       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.738       |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 9.23e-05     |\n",
      "|    loss                 | 23.9         |\n",
      "|    n_updates            | 4152         |\n",
      "|    policy_gradient_loss | -0.00136     |\n",
      "|    value_loss           | 49.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 317          |\n",
      "|    iterations           | 175          |\n",
      "|    time_elapsed         | 18045        |\n",
      "|    total_timesteps      | 5734400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033939406 |\n",
      "|    clip_fraction        | 0.0436       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.723       |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 9.17e-05     |\n",
      "|    loss                 | 25.4         |\n",
      "|    n_updates            | 4176         |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    value_loss           | 48.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 18122       |\n",
      "|    total_timesteps      | 5767168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004976078 |\n",
      "|    clip_fraction        | 0.0387      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.709      |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 9.1e-05     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 4200        |\n",
      "|    policy_gradient_loss | -0.00187    |\n",
      "|    value_loss           | 49.8        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5788928, episode_reward=36.73 +/- 15.32\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 36.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5788928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037487468 |\n",
      "|    clip_fraction        | 0.0382       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.693       |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 9.04e-05     |\n",
      "|    loss                 | 24.2         |\n",
      "|    n_updates            | 4224         |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    value_loss           | 48.8         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 318     |\n",
      "|    iterations      | 177     |\n",
      "|    time_elapsed    | 18225   |\n",
      "|    total_timesteps | 5799936 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 318          |\n",
      "|    iterations           | 178          |\n",
      "|    time_elapsed         | 18300        |\n",
      "|    total_timesteps      | 5832704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030161957 |\n",
      "|    clip_fraction        | 0.0428       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.705       |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 8.98e-05     |\n",
      "|    loss                 | 24.9         |\n",
      "|    n_updates            | 4248         |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    value_loss           | 49.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 179         |\n",
      "|    time_elapsed         | 18376       |\n",
      "|    total_timesteps      | 5865472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004215878 |\n",
      "|    clip_fraction        | 0.0377      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.699      |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 8.92e-05    |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 4272        |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    value_loss           | 49          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 18453       |\n",
      "|    total_timesteps      | 5898240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022153715 |\n",
      "|    clip_fraction        | 0.0297      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.64       |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 8.86e-05    |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 4296        |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    value_loss           | 50.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 320          |\n",
      "|    iterations           | 181          |\n",
      "|    time_elapsed         | 18528        |\n",
      "|    total_timesteps      | 5931008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031274548 |\n",
      "|    clip_fraction        | 0.0269       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.57        |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 8.79e-05     |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 4320         |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    value_loss           | 44.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5948928, episode_reward=37.38 +/- 14.64\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 37.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5948928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023828838 |\n",
      "|    clip_fraction        | 0.0309       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.565       |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 8.73e-05     |\n",
      "|    loss                 | 23.1         |\n",
      "|    n_updates            | 4344         |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 45.6         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 320     |\n",
      "|    iterations      | 182     |\n",
      "|    time_elapsed    | 18632   |\n",
      "|    total_timesteps | 5963776 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 320         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 18706       |\n",
      "|    total_timesteps      | 5996544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007999737 |\n",
      "|    clip_fraction        | 0.0534      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.545      |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 8.67e-05    |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 4368        |\n",
      "|    policy_gradient_loss | -0.000979   |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 321          |\n",
      "|    iterations           | 184          |\n",
      "|    time_elapsed         | 18781        |\n",
      "|    total_timesteps      | 6029312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026035642 |\n",
      "|    clip_fraction        | 0.0338       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 8.61e-05     |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 4392         |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    value_loss           | 41.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 321          |\n",
      "|    iterations           | 185          |\n",
      "|    time_elapsed         | 18858        |\n",
      "|    total_timesteps      | 6062080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025045918 |\n",
      "|    clip_fraction        | 0.05         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.523       |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 8.54e-05     |\n",
      "|    loss                 | 21           |\n",
      "|    n_updates            | 4416         |\n",
      "|    policy_gradient_loss | -0.00076     |\n",
      "|    value_loss           | 45.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 321         |\n",
      "|    iterations           | 186         |\n",
      "|    time_elapsed         | 18934       |\n",
      "|    total_timesteps      | 6094848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002820989 |\n",
      "|    clip_fraction        | 0.0281      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.515      |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 8.48e-05    |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 4440        |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6108928, episode_reward=37.08 +/- 14.61\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 37.1         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6108928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026078545 |\n",
      "|    clip_fraction        | 0.0499       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.749        |\n",
      "|    learning_rate        | 8.42e-05     |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 4464         |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    value_loss           | 40.3         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 321     |\n",
      "|    iterations      | 187     |\n",
      "|    time_elapsed    | 19035   |\n",
      "|    total_timesteps | 6127616 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 19112       |\n",
      "|    total_timesteps      | 6160384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002682434 |\n",
      "|    clip_fraction        | 0.0209      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.515      |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 8.36e-05    |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 4488        |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 322          |\n",
      "|    iterations           | 189          |\n",
      "|    time_elapsed         | 19187        |\n",
      "|    total_timesteps      | 6193152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024202026 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 8.3e-05      |\n",
      "|    loss                 | 19.8         |\n",
      "|    n_updates            | 4512         |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    value_loss           | 41.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 19263       |\n",
      "|    total_timesteps      | 6225920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003624141 |\n",
      "|    clip_fraction        | 0.0346      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.523      |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 8.23e-05    |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 4536        |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 323          |\n",
      "|    iterations           | 191          |\n",
      "|    time_elapsed         | 19338        |\n",
      "|    total_timesteps      | 6258688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027433317 |\n",
      "|    clip_fraction        | 0.0394       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 8.17e-05     |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 4560         |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    value_loss           | 41.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=6268928, episode_reward=36.27 +/- 14.22\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 36.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 6268928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002230943 |\n",
      "|    clip_fraction        | 0.0292      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 8.11e-05    |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 4584        |\n",
      "|    policy_gradient_loss | -0.00264    |\n",
      "|    value_loss           | 41.7        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 323     |\n",
      "|    iterations      | 192     |\n",
      "|    time_elapsed    | 19441   |\n",
      "|    total_timesteps | 6291456 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 324          |\n",
      "|    iterations           | 193          |\n",
      "|    time_elapsed         | 19517        |\n",
      "|    total_timesteps      | 6324224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025501028 |\n",
      "|    clip_fraction        | 0.0299       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 8.05e-05     |\n",
      "|    loss                 | 21.4         |\n",
      "|    n_updates            | 4608         |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    value_loss           | 43.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 324          |\n",
      "|    iterations           | 194          |\n",
      "|    time_elapsed         | 19592        |\n",
      "|    total_timesteps      | 6356992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026628366 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 7.98e-05     |\n",
      "|    loss                 | 21           |\n",
      "|    n_updates            | 4632         |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    value_loss           | 40.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 324         |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 19667       |\n",
      "|    total_timesteps      | 6389760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002167954 |\n",
      "|    clip_fraction        | 0.0343      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.497      |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 7.92e-05    |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 4656        |\n",
      "|    policy_gradient_loss | -0.00253    |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 325          |\n",
      "|    iterations           | 196          |\n",
      "|    time_elapsed         | 19745        |\n",
      "|    total_timesteps      | 6422528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049488703 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 7.86e-05     |\n",
      "|    loss                 | 19.9         |\n",
      "|    n_updates            | 4680         |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    value_loss           | 44           |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6428928, episode_reward=37.27 +/- 15.09\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 37.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6428928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023521422 |\n",
      "|    clip_fraction        | 0.0323       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 7.8e-05      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 4704         |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    value_loss           | 41.8         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 325     |\n",
      "|    iterations      | 197     |\n",
      "|    time_elapsed    | 19846   |\n",
      "|    total_timesteps | 6455296 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 325         |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 19920       |\n",
      "|    total_timesteps      | 6488064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002819863 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.484      |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 7.73e-05    |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 4728        |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    value_loss           | 43.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 326          |\n",
      "|    iterations           | 199          |\n",
      "|    time_elapsed         | 19996        |\n",
      "|    total_timesteps      | 6520832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032977187 |\n",
      "|    clip_fraction        | 0.0349       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 7.67e-05     |\n",
      "|    loss                 | 22.6         |\n",
      "|    n_updates            | 4752         |\n",
      "|    policy_gradient_loss | -0.00241     |\n",
      "|    value_loss           | 44.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 326          |\n",
      "|    iterations           | 200          |\n",
      "|    time_elapsed         | 20074        |\n",
      "|    total_timesteps      | 6553600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019507413 |\n",
      "|    clip_fraction        | 0.0344       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.473       |\n",
      "|    explained_variance   | 0.748        |\n",
      "|    learning_rate        | 7.61e-05     |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 4776         |\n",
      "|    policy_gradient_loss | -0.00141     |\n",
      "|    value_loss           | 41.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 326          |\n",
      "|    iterations           | 201          |\n",
      "|    time_elapsed         | 20150        |\n",
      "|    total_timesteps      | 6586368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024294583 |\n",
      "|    clip_fraction        | 0.0403       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.475       |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 7.55e-05     |\n",
      "|    loss                 | 21           |\n",
      "|    n_updates            | 4800         |\n",
      "|    policy_gradient_loss | -0.00193     |\n",
      "|    value_loss           | 43.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=6588928, episode_reward=38.19 +/- 14.92\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 38.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 6588928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002294829 |\n",
      "|    clip_fraction        | 0.0238      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.485      |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 7.49e-05    |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 4824        |\n",
      "|    policy_gradient_loss | -0.00288    |\n",
      "|    value_loss           | 47          |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 326     |\n",
      "|    iterations      | 202     |\n",
      "|    time_elapsed    | 20253   |\n",
      "|    total_timesteps | 6619136 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 327          |\n",
      "|    iterations           | 203          |\n",
      "|    time_elapsed         | 20330        |\n",
      "|    total_timesteps      | 6651904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043031434 |\n",
      "|    clip_fraction        | 0.0339       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 7.42e-05     |\n",
      "|    loss                 | 21.3         |\n",
      "|    n_updates            | 4848         |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    value_loss           | 44.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 327          |\n",
      "|    iterations           | 204          |\n",
      "|    time_elapsed         | 20405        |\n",
      "|    total_timesteps      | 6684672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029935178 |\n",
      "|    clip_fraction        | 0.029        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.742        |\n",
      "|    learning_rate        | 7.36e-05     |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 4872         |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    value_loss           | 42.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 327          |\n",
      "|    iterations           | 205          |\n",
      "|    time_elapsed         | 20481        |\n",
      "|    total_timesteps      | 6717440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026648524 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.475       |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 7.3e-05      |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 4896         |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    value_loss           | 43.3         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6748928, episode_reward=37.72 +/- 15.27\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 37.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6748928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028122736 |\n",
      "|    clip_fraction        | 0.0296       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.472       |\n",
      "|    explained_variance   | 0.742        |\n",
      "|    learning_rate        | 7.24e-05     |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 4920         |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    value_loss           | 41.7         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 327     |\n",
      "|    iterations      | 206     |\n",
      "|    time_elapsed    | 20584   |\n",
      "|    total_timesteps | 6750208 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 328          |\n",
      "|    iterations           | 207          |\n",
      "|    time_elapsed         | 20658        |\n",
      "|    total_timesteps      | 6782976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022546838 |\n",
      "|    clip_fraction        | 0.028        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 7.17e-05     |\n",
      "|    loss                 | 22.6         |\n",
      "|    n_updates            | 4944         |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    value_loss           | 42.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 328          |\n",
      "|    iterations           | 208          |\n",
      "|    time_elapsed         | 20735        |\n",
      "|    total_timesteps      | 6815744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021535316 |\n",
      "|    clip_fraction        | 0.0286       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 7.11e-05     |\n",
      "|    loss                 | 22.6         |\n",
      "|    n_updates            | 4968         |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    value_loss           | 46.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 328          |\n",
      "|    iterations           | 209          |\n",
      "|    time_elapsed         | 20816        |\n",
      "|    total_timesteps      | 6848512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018051094 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 7.05e-05     |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 4992         |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    value_loss           | 45.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 329          |\n",
      "|    iterations           | 210          |\n",
      "|    time_elapsed         | 20891        |\n",
      "|    total_timesteps      | 6881280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021364535 |\n",
      "|    clip_fraction        | 0.0275       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 6.99e-05     |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 5016         |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    value_loss           | 45.2         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6908928, episode_reward=37.67 +/- 14.70\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 37.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6908928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018933649 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 6.93e-05     |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 5040         |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    value_loss           | 44           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 329     |\n",
      "|    iterations      | 211     |\n",
      "|    time_elapsed    | 20992   |\n",
      "|    total_timesteps | 6914048 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 329          |\n",
      "|    iterations           | 212          |\n",
      "|    time_elapsed         | 21069        |\n",
      "|    total_timesteps      | 6946816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032746783 |\n",
      "|    clip_fraction        | 0.0344       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.484       |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 6.86e-05     |\n",
      "|    loss                 | 20.1         |\n",
      "|    n_updates            | 5064         |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    value_loss           | 42.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 330          |\n",
      "|    iterations           | 213          |\n",
      "|    time_elapsed         | 21145        |\n",
      "|    total_timesteps      | 6979584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021050894 |\n",
      "|    clip_fraction        | 0.0321       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.473       |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 6.8e-05      |\n",
      "|    loss                 | 22.7         |\n",
      "|    n_updates            | 5088         |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    value_loss           | 44.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 330         |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 21220       |\n",
      "|    total_timesteps      | 7012352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002841664 |\n",
      "|    clip_fraction        | 0.0263      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.488      |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 6.74e-05    |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 5112        |\n",
      "|    policy_gradient_loss | -0.00256    |\n",
      "|    value_loss           | 45.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 330         |\n",
      "|    iterations           | 215         |\n",
      "|    time_elapsed         | 21295       |\n",
      "|    total_timesteps      | 7045120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002599669 |\n",
      "|    clip_fraction        | 0.0248      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.477      |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 6.68e-05    |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 5136        |\n",
      "|    policy_gradient_loss | -0.00236    |\n",
      "|    value_loss           | 46          |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=7068928, episode_reward=36.29 +/- 15.26\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 36.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 7068928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004341797 |\n",
      "|    clip_fraction        | 0.0297      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.468      |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 6.61e-05    |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 5160        |\n",
      "|    policy_gradient_loss | -0.00242    |\n",
      "|    value_loss           | 48.1        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 330     |\n",
      "|    iterations      | 216     |\n",
      "|    time_elapsed    | 21398   |\n",
      "|    total_timesteps | 7077888 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 331         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 21474       |\n",
      "|    total_timesteps      | 7110656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007336362 |\n",
      "|    clip_fraction        | 0.0338      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.466      |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 6.55e-05    |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 5184        |\n",
      "|    policy_gradient_loss | -0.00199    |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 331          |\n",
      "|    iterations           | 218          |\n",
      "|    time_elapsed         | 21550        |\n",
      "|    total_timesteps      | 7143424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018940445 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 6.49e-05     |\n",
      "|    loss                 | 20.1         |\n",
      "|    n_updates            | 5208         |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    value_loss           | 42           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 331          |\n",
      "|    iterations           | 219          |\n",
      "|    time_elapsed         | 21626        |\n",
      "|    total_timesteps      | 7176192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023926983 |\n",
      "|    clip_fraction        | 0.0236       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 6.43e-05     |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 5232         |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    value_loss           | 45.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 332          |\n",
      "|    iterations           | 220          |\n",
      "|    time_elapsed         | 21703        |\n",
      "|    total_timesteps      | 7208960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021331692 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.75         |\n",
      "|    learning_rate        | 6.37e-05     |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 5256         |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    value_loss           | 41.1         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7228928, episode_reward=37.23 +/- 14.20\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 37.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7228928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026316436 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 6.3e-05      |\n",
      "|    loss                 | 21           |\n",
      "|    n_updates            | 5280         |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    value_loss           | 42.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 332     |\n",
      "|    iterations      | 221     |\n",
      "|    time_elapsed    | 21806   |\n",
      "|    total_timesteps | 7241728 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 332         |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 21881       |\n",
      "|    total_timesteps      | 7274496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002737285 |\n",
      "|    clip_fraction        | 0.0226      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.461      |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 6.24e-05    |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 5304        |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    value_loss           | 42.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 332          |\n",
      "|    iterations           | 223          |\n",
      "|    time_elapsed         | 21959        |\n",
      "|    total_timesteps      | 7307264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021003475 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 6.18e-05     |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 5328         |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    value_loss           | 45.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 333          |\n",
      "|    iterations           | 224          |\n",
      "|    time_elapsed         | 22037        |\n",
      "|    total_timesteps      | 7340032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019199314 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.464       |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 6.12e-05     |\n",
      "|    loss                 | 19.8         |\n",
      "|    n_updates            | 5352         |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    value_loss           | 41.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 333          |\n",
      "|    iterations           | 225          |\n",
      "|    time_elapsed         | 22112        |\n",
      "|    total_timesteps      | 7372800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019533578 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.47        |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 6.05e-05     |\n",
      "|    loss                 | 20.4         |\n",
      "|    n_updates            | 5376         |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    value_loss           | 41.6         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7388928, episode_reward=37.93 +/- 14.93\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 37.9         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7388928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030147394 |\n",
      "|    clip_fraction        | 0.0282       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.468       |\n",
      "|    explained_variance   | 0.749        |\n",
      "|    learning_rate        | 5.99e-05     |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 5400         |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    value_loss           | 40.6         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 333     |\n",
      "|    iterations      | 226     |\n",
      "|    time_elapsed    | 22216   |\n",
      "|    total_timesteps | 7405568 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 333          |\n",
      "|    iterations           | 227          |\n",
      "|    time_elapsed         | 22292        |\n",
      "|    total_timesteps      | 7438336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035735422 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 5.93e-05     |\n",
      "|    loss                 | 23.5         |\n",
      "|    n_updates            | 5424         |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    value_loss           | 44.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 333          |\n",
      "|    iterations           | 228          |\n",
      "|    time_elapsed         | 22368        |\n",
      "|    total_timesteps      | 7471104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029072338 |\n",
      "|    clip_fraction        | 0.0249       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.449       |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 5.87e-05     |\n",
      "|    loss                 | 19.9         |\n",
      "|    n_updates            | 5448         |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    value_loss           | 43.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 334          |\n",
      "|    iterations           | 229          |\n",
      "|    time_elapsed         | 22445        |\n",
      "|    total_timesteps      | 7503872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042798957 |\n",
      "|    clip_fraction        | 0.0251       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 5.8e-05      |\n",
      "|    loss                 | 19.5         |\n",
      "|    n_updates            | 5472         |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    value_loss           | 41.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 334          |\n",
      "|    iterations           | 230          |\n",
      "|    time_elapsed         | 22521        |\n",
      "|    total_timesteps      | 7536640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022591362 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.468       |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 5.74e-05     |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 5496         |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    value_loss           | 43.3         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7548928, episode_reward=37.47 +/- 15.42\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 37.5        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 7548928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002766246 |\n",
      "|    clip_fraction        | 0.0261      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.473      |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 5.68e-05    |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 5520        |\n",
      "|    policy_gradient_loss | -0.00249    |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 334     |\n",
      "|    iterations      | 231     |\n",
      "|    time_elapsed    | 22623   |\n",
      "|    total_timesteps | 7569408 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 334         |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 22698       |\n",
      "|    total_timesteps      | 7602176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003873638 |\n",
      "|    clip_fraction        | 0.0256      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.475      |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 5.62e-05    |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 5544        |\n",
      "|    policy_gradient_loss | -0.00211    |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 335          |\n",
      "|    iterations           | 233          |\n",
      "|    time_elapsed         | 22773        |\n",
      "|    total_timesteps      | 7634944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016741883 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.479       |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 5.56e-05     |\n",
      "|    loss                 | 23.9         |\n",
      "|    n_updates            | 5568         |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    value_loss           | 44.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 22851       |\n",
      "|    total_timesteps      | 7667712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003447926 |\n",
      "|    clip_fraction        | 0.023       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.477      |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 5.49e-05    |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 5592        |\n",
      "|    policy_gradient_loss | -0.00234    |\n",
      "|    value_loss           | 44.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 335          |\n",
      "|    iterations           | 235          |\n",
      "|    time_elapsed         | 22927        |\n",
      "|    total_timesteps      | 7700480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017778187 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.733        |\n",
      "|    learning_rate        | 5.43e-05     |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 5616         |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    value_loss           | 44.8         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7708928, episode_reward=36.23 +/- 13.79\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 36.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7708928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021273596 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.449       |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 5.37e-05     |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 5640         |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    value_loss           | 44.5         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 335     |\n",
      "|    iterations      | 236     |\n",
      "|    time_elapsed    | 23028   |\n",
      "|    total_timesteps | 7733248 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 336          |\n",
      "|    iterations           | 237          |\n",
      "|    time_elapsed         | 23105        |\n",
      "|    total_timesteps      | 7766016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023097629 |\n",
      "|    clip_fraction        | 0.0252       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.447       |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 5.31e-05     |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 5664         |\n",
      "|    policy_gradient_loss | -0.00207     |\n",
      "|    value_loss           | 47.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 336         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 23181       |\n",
      "|    total_timesteps      | 7798784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002197819 |\n",
      "|    clip_fraction        | 0.0262      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.446      |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 5.24e-05    |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 5688        |\n",
      "|    policy_gradient_loss | -0.00188    |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 336          |\n",
      "|    iterations           | 239          |\n",
      "|    time_elapsed         | 23256        |\n",
      "|    total_timesteps      | 7831552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023689258 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.452       |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 5.18e-05     |\n",
      "|    loss                 | 20.6         |\n",
      "|    n_updates            | 5712         |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    value_loss           | 44.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 337          |\n",
      "|    iterations           | 240          |\n",
      "|    time_elapsed         | 23333        |\n",
      "|    total_timesteps      | 7864320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019771114 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.454       |\n",
      "|    explained_variance   | 0.737        |\n",
      "|    learning_rate        | 5.12e-05     |\n",
      "|    loss                 | 22           |\n",
      "|    n_updates            | 5736         |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    value_loss           | 41.6         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7868928, episode_reward=36.99 +/- 14.42\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 37           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7868928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031747427 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.463       |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 5.06e-05     |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 5760         |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    value_loss           | 40.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 336     |\n",
      "|    iterations      | 241     |\n",
      "|    time_elapsed    | 23436   |\n",
      "|    total_timesteps | 7897088 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 337         |\n",
      "|    iterations           | 242         |\n",
      "|    time_elapsed         | 23509       |\n",
      "|    total_timesteps      | 7929856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001962436 |\n",
      "|    clip_fraction        | 0.035       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.45       |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 5784        |\n",
      "|    policy_gradient_loss | -0.00181    |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 337          |\n",
      "|    iterations           | 243          |\n",
      "|    time_elapsed         | 23584        |\n",
      "|    total_timesteps      | 7962624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019928892 |\n",
      "|    clip_fraction        | 0.0218       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.444       |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 4.93e-05     |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 5808         |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    value_loss           | 43.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 337          |\n",
      "|    iterations           | 244          |\n",
      "|    time_elapsed         | 23660        |\n",
      "|    total_timesteps      | 7995392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023800647 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.443       |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 4.87e-05     |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 5832         |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    value_loss           | 42.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 338          |\n",
      "|    iterations           | 245          |\n",
      "|    time_elapsed         | 23738        |\n",
      "|    total_timesteps      | 8028160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051716696 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.44        |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 4.81e-05     |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 5856         |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    value_loss           | 43           |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8028928, episode_reward=37.34 +/- 14.27\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 37.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 8028928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002269009 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.462      |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 4.75e-05    |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 5880        |\n",
      "|    policy_gradient_loss | -0.0021     |\n",
      "|    value_loss           | 45.3        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 338     |\n",
      "|    iterations      | 246     |\n",
      "|    time_elapsed    | 23840   |\n",
      "|    total_timesteps | 8060928 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 338          |\n",
      "|    iterations           | 247          |\n",
      "|    time_elapsed         | 23915        |\n",
      "|    total_timesteps      | 8093696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022498316 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.441       |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 4.68e-05     |\n",
      "|    loss                 | 22.7         |\n",
      "|    n_updates            | 5904         |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    value_loss           | 43.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 338          |\n",
      "|    iterations           | 248          |\n",
      "|    time_elapsed         | 23992        |\n",
      "|    total_timesteps      | 8126464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017087839 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.462       |\n",
      "|    explained_variance   | 0.729        |\n",
      "|    learning_rate        | 4.62e-05     |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 5928         |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    value_loss           | 45.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 338          |\n",
      "|    iterations           | 249          |\n",
      "|    time_elapsed         | 24069        |\n",
      "|    total_timesteps      | 8159232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020734414 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.463       |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 4.56e-05     |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 5952         |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    value_loss           | 46.3         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8188928, episode_reward=37.46 +/- 14.92\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 37.5         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8188928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016152568 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.467       |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 4.5e-05      |\n",
      "|    loss                 | 21.8         |\n",
      "|    n_updates            | 5976         |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    value_loss           | 43.5         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 338     |\n",
      "|    iterations      | 250     |\n",
      "|    time_elapsed    | 24170   |\n",
      "|    total_timesteps | 8192000 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 339          |\n",
      "|    iterations           | 251          |\n",
      "|    time_elapsed         | 24245        |\n",
      "|    total_timesteps      | 8224768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021476522 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.454       |\n",
      "|    explained_variance   | 0.733        |\n",
      "|    learning_rate        | 4.44e-05     |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 6000         |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    value_loss           | 44.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 339          |\n",
      "|    iterations           | 252          |\n",
      "|    time_elapsed         | 24323        |\n",
      "|    total_timesteps      | 8257536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012968521 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.459       |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 4.37e-05     |\n",
      "|    loss                 | 23.5         |\n",
      "|    n_updates            | 6024         |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    value_loss           | 43.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 339          |\n",
      "|    iterations           | 253          |\n",
      "|    time_elapsed         | 24399        |\n",
      "|    total_timesteps      | 8290304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018415581 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 4.31e-05     |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 6048         |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    value_loss           | 47.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 340          |\n",
      "|    iterations           | 254          |\n",
      "|    time_elapsed         | 24473        |\n",
      "|    total_timesteps      | 8323072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017331201 |\n",
      "|    clip_fraction        | 0.0223       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.445       |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 4.25e-05     |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 6072         |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    value_loss           | 46.4         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8348928, episode_reward=37.32 +/- 15.39\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 37.3         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8348928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020038204 |\n",
      "|    clip_fraction        | 0.0284       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.449       |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 4.19e-05     |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 6096         |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    value_loss           | 45.4         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 340     |\n",
      "|    iterations      | 255     |\n",
      "|    time_elapsed    | 24575   |\n",
      "|    total_timesteps | 8355840 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 340          |\n",
      "|    iterations           | 256          |\n",
      "|    time_elapsed         | 24650        |\n",
      "|    total_timesteps      | 8388608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017268355 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.729        |\n",
      "|    learning_rate        | 4.12e-05     |\n",
      "|    loss                 | 21.8         |\n",
      "|    n_updates            | 6120         |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    value_loss           | 45.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 340          |\n",
      "|    iterations           | 257          |\n",
      "|    time_elapsed         | 24726        |\n",
      "|    total_timesteps      | 8421376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019127274 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.445       |\n",
      "|    explained_variance   | 0.72         |\n",
      "|    learning_rate        | 4.06e-05     |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 6144         |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    value_loss           | 47.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 24804       |\n",
      "|    total_timesteps      | 8454144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001440258 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.443      |\n",
      "|    explained_variance   | 0.721       |\n",
      "|    learning_rate        | 4e-05       |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 6168        |\n",
      "|    policy_gradient_loss | -0.00203    |\n",
      "|    value_loss           | 46.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 341         |\n",
      "|    iterations           | 259         |\n",
      "|    time_elapsed         | 24881       |\n",
      "|    total_timesteps      | 8486912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002083627 |\n",
      "|    clip_fraction        | 0.0157      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.44       |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 3.94e-05    |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 6192        |\n",
      "|    policy_gradient_loss | -0.00224    |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=8508928, episode_reward=36.81 +/- 14.45\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 36.8         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8508928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017705776 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.447       |\n",
      "|    explained_variance   | 0.72         |\n",
      "|    learning_rate        | 3.87e-05     |\n",
      "|    loss                 | 22           |\n",
      "|    n_updates            | 6216         |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    value_loss           | 45.2         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 341     |\n",
      "|    iterations      | 260     |\n",
      "|    time_elapsed    | 24983   |\n",
      "|    total_timesteps | 8519680 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 341          |\n",
      "|    iterations           | 261          |\n",
      "|    time_elapsed         | 25060        |\n",
      "|    total_timesteps      | 8552448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012985964 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 3.81e-05     |\n",
      "|    loss                 | 23.2         |\n",
      "|    n_updates            | 6240         |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    value_loss           | 46.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 341          |\n",
      "|    iterations           | 262          |\n",
      "|    time_elapsed         | 25136        |\n",
      "|    total_timesteps      | 8585216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021241414 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.444       |\n",
      "|    explained_variance   | 0.716        |\n",
      "|    learning_rate        | 3.75e-05     |\n",
      "|    loss                 | 25.3         |\n",
      "|    n_updates            | 6264         |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    value_loss           | 46           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 341          |\n",
      "|    iterations           | 263          |\n",
      "|    time_elapsed         | 25211        |\n",
      "|    total_timesteps      | 8617984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018626517 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.429       |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 3.69e-05     |\n",
      "|    loss                 | 22.7         |\n",
      "|    n_updates            | 6288         |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    value_loss           | 44.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 342          |\n",
      "|    iterations           | 264          |\n",
      "|    time_elapsed         | 25287        |\n",
      "|    total_timesteps      | 8650752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017195083 |\n",
      "|    clip_fraction        | 0.024        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.422       |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 3.63e-05     |\n",
      "|    loss                 | 20.6         |\n",
      "|    n_updates            | 6312         |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    value_loss           | 43.4         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8668928, episode_reward=36.99 +/- 14.86\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 37          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 8668928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001409173 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.422      |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 3.56e-05    |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 6336        |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    value_loss           | 45.3        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 341     |\n",
      "|    iterations      | 265     |\n",
      "|    time_elapsed    | 25390   |\n",
      "|    total_timesteps | 8683520 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 342          |\n",
      "|    iterations           | 266          |\n",
      "|    time_elapsed         | 25464        |\n",
      "|    total_timesteps      | 8716288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017514538 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.424       |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 3.5e-05      |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 6360         |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    value_loss           | 44.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 342          |\n",
      "|    iterations           | 267          |\n",
      "|    time_elapsed         | 25539        |\n",
      "|    total_timesteps      | 8749056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020086442 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.434       |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 3.44e-05     |\n",
      "|    loss                 | 24.7         |\n",
      "|    n_updates            | 6384         |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    value_loss           | 48.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 342          |\n",
      "|    iterations           | 268          |\n",
      "|    time_elapsed         | 25616        |\n",
      "|    total_timesteps      | 8781824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019061486 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.419       |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 3.38e-05     |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 6408         |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    value_loss           | 44.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 343          |\n",
      "|    iterations           | 269          |\n",
      "|    time_elapsed         | 25691        |\n",
      "|    total_timesteps      | 8814592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017833044 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.416       |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 3.31e-05     |\n",
      "|    loss                 | 23.4         |\n",
      "|    n_updates            | 6432         |\n",
      "|    policy_gradient_loss | -0.00161     |\n",
      "|    value_loss           | 47.1         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8828928, episode_reward=37.42 +/- 14.89\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 37.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8828928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014295935 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.418       |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 3.25e-05     |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 6456         |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    value_loss           | 45.3         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 343     |\n",
      "|    iterations      | 270     |\n",
      "|    time_elapsed    | 25791   |\n",
      "|    total_timesteps | 8847360 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 343          |\n",
      "|    iterations           | 271          |\n",
      "|    time_elapsed         | 25867        |\n",
      "|    total_timesteps      | 8880128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016894029 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.404       |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 3.19e-05     |\n",
      "|    loss                 | 24.2         |\n",
      "|    n_updates            | 6480         |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    value_loss           | 45.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 343          |\n",
      "|    iterations           | 272          |\n",
      "|    time_elapsed         | 25942        |\n",
      "|    total_timesteps      | 8912896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012166662 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 3.13e-05     |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 6504         |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    value_loss           | 40.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 343          |\n",
      "|    iterations           | 273          |\n",
      "|    time_elapsed         | 26016        |\n",
      "|    total_timesteps      | 8945664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014791464 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.411       |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 3.07e-05     |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 6528         |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    value_loss           | 41.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 344          |\n",
      "|    iterations           | 274          |\n",
      "|    time_elapsed         | 26091        |\n",
      "|    total_timesteps      | 8978432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016003314 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.404       |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 6552         |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    value_loss           | 45.9         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8988928, episode_reward=36.27 +/- 15.11\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 36.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 8988928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001454093 |\n",
      "|    clip_fraction        | 0.0114      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.406      |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 2.94e-05    |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 6576        |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    value_loss           | 46.4        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 343     |\n",
      "|    iterations      | 275     |\n",
      "|    time_elapsed    | 26196   |\n",
      "|    total_timesteps | 9011200 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 344          |\n",
      "|    iterations           | 276          |\n",
      "|    time_elapsed         | 26272        |\n",
      "|    total_timesteps      | 9043968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015824508 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.415       |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 2.88e-05     |\n",
      "|    loss                 | 22.3         |\n",
      "|    n_updates            | 6600         |\n",
      "|    policy_gradient_loss | -0.00207     |\n",
      "|    value_loss           | 44.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 344         |\n",
      "|    iterations           | 277         |\n",
      "|    time_elapsed         | 26348       |\n",
      "|    total_timesteps      | 9076736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002491369 |\n",
      "|    clip_fraction        | 0.0184      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.404      |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 2.82e-05    |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 6624        |\n",
      "|    policy_gradient_loss | -0.00215    |\n",
      "|    value_loss           | 44.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 344          |\n",
      "|    iterations           | 278          |\n",
      "|    time_elapsed         | 26423        |\n",
      "|    total_timesteps      | 9109504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014531671 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.404       |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 2.75e-05     |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 6648         |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    value_loss           | 47.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 345          |\n",
      "|    iterations           | 279          |\n",
      "|    time_elapsed         | 26498        |\n",
      "|    total_timesteps      | 9142272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016669419 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 2.69e-05     |\n",
      "|    loss                 | 23.2         |\n",
      "|    n_updates            | 6672         |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    value_loss           | 44.2         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9148928, episode_reward=37.46 +/- 14.81\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 37.5         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9148928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014131232 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.397       |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 2.63e-05     |\n",
      "|    loss                 | 21.5         |\n",
      "|    n_updates            | 6696         |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    value_loss           | 41.3         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 344     |\n",
      "|    iterations      | 280     |\n",
      "|    time_elapsed    | 26602   |\n",
      "|    total_timesteps | 9175040 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 345         |\n",
      "|    iterations           | 281         |\n",
      "|    time_elapsed         | 26679       |\n",
      "|    total_timesteps      | 9207808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001536173 |\n",
      "|    clip_fraction        | 0.0159      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.399      |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 2.57e-05    |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 6720        |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 345          |\n",
      "|    iterations           | 282          |\n",
      "|    time_elapsed         | 26757        |\n",
      "|    total_timesteps      | 9240576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016528915 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 2.51e-05     |\n",
      "|    loss                 | 22.5         |\n",
      "|    n_updates            | 6744         |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    value_loss           | 43.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 345          |\n",
      "|    iterations           | 283          |\n",
      "|    time_elapsed         | 26835        |\n",
      "|    total_timesteps      | 9273344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013746569 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.409       |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 2.44e-05     |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 6768         |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    value_loss           | 45.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 345          |\n",
      "|    iterations           | 284          |\n",
      "|    time_elapsed         | 26912        |\n",
      "|    total_timesteps      | 9306112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014311798 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.402       |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 2.38e-05     |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 6792         |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    value_loss           | 42.6         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9308928, episode_reward=36.67 +/- 14.58\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 36.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 9308928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001499211 |\n",
      "|    clip_fraction        | 0.0137      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.398      |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 2.32e-05    |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 6816        |\n",
      "|    policy_gradient_loss | -0.0018     |\n",
      "|    value_loss           | 43.1        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 345     |\n",
      "|    iterations      | 285     |\n",
      "|    time_elapsed    | 27014   |\n",
      "|    total_timesteps | 9338880 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 345          |\n",
      "|    iterations           | 286          |\n",
      "|    time_elapsed         | 27091        |\n",
      "|    total_timesteps      | 9371648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013546911 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.4         |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 2.26e-05     |\n",
      "|    loss                 | 20.4         |\n",
      "|    n_updates            | 6840         |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    value_loss           | 43           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 346          |\n",
      "|    iterations           | 287          |\n",
      "|    time_elapsed         | 27166        |\n",
      "|    total_timesteps      | 9404416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018139854 |\n",
      "|    clip_fraction        | 0.00963      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 2.19e-05     |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 6864         |\n",
      "|    policy_gradient_loss | -0.00163     |\n",
      "|    value_loss           | 46.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 346          |\n",
      "|    iterations           | 288          |\n",
      "|    time_elapsed         | 27243        |\n",
      "|    total_timesteps      | 9437184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022717523 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 2.13e-05     |\n",
      "|    loss                 | 19           |\n",
      "|    n_updates            | 6888         |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    value_loss           | 41.6         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9468928, episode_reward=37.72 +/- 15.41\n",
      "Episode length: 25.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 37.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 9468928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001344553 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.406      |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 2.07e-05    |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 6912        |\n",
      "|    policy_gradient_loss | -0.00165    |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 346     |\n",
      "|    iterations      | 289     |\n",
      "|    time_elapsed    | 27345   |\n",
      "|    total_timesteps | 9469952 |\n",
      "--------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 346           |\n",
      "|    iterations           | 290           |\n",
      "|    time_elapsed         | 27421         |\n",
      "|    total_timesteps      | 9502720       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090469193 |\n",
      "|    clip_fraction        | 0.00844       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.407        |\n",
      "|    explained_variance   | 0.748         |\n",
      "|    learning_rate        | 2.01e-05      |\n",
      "|    loss                 | 21.2          |\n",
      "|    n_updates            | 6936          |\n",
      "|    policy_gradient_loss | -0.00143      |\n",
      "|    value_loss           | 41.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 346          |\n",
      "|    iterations           | 291          |\n",
      "|    time_elapsed         | 27497        |\n",
      "|    total_timesteps      | 9535488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013980867 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.407       |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 1.94e-05     |\n",
      "|    loss                 | 21.5         |\n",
      "|    n_updates            | 6960         |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    value_loss           | 43.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 347          |\n",
      "|    iterations           | 292          |\n",
      "|    time_elapsed         | 27573        |\n",
      "|    total_timesteps      | 9568256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008505134 |\n",
      "|    clip_fraction        | 0.00942      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.4         |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 1.88e-05     |\n",
      "|    loss                 | 21.5         |\n",
      "|    n_updates            | 6984         |\n",
      "|    policy_gradient_loss | -0.00149     |\n",
      "|    value_loss           | 44.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 347          |\n",
      "|    iterations           | 293          |\n",
      "|    time_elapsed         | 27648        |\n",
      "|    total_timesteps      | 9601024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011767827 |\n",
      "|    clip_fraction        | 0.00993      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 1.82e-05     |\n",
      "|    loss                 | 22.3         |\n",
      "|    n_updates            | 7008         |\n",
      "|    policy_gradient_loss | -0.00149     |\n",
      "|    value_loss           | 42.9         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9628928, episode_reward=36.99 +/- 14.87\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 37           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9628928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013698514 |\n",
      "|    clip_fraction        | 0.0086       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.414       |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 1.76e-05     |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 7032         |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    value_loss           | 43.1         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 347     |\n",
      "|    iterations      | 294     |\n",
      "|    time_elapsed    | 27751   |\n",
      "|    total_timesteps | 9633792 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 347          |\n",
      "|    iterations           | 295          |\n",
      "|    time_elapsed         | 27828        |\n",
      "|    total_timesteps      | 9666560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013927673 |\n",
      "|    clip_fraction        | 0.00946      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 1.7e-05      |\n",
      "|    loss                 | 23.5         |\n",
      "|    n_updates            | 7056         |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    value_loss           | 46.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 347          |\n",
      "|    iterations           | 296          |\n",
      "|    time_elapsed         | 27903        |\n",
      "|    total_timesteps      | 9699328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014773996 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.403       |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 1.63e-05     |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 7080         |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    value_loss           | 43.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 347          |\n",
      "|    iterations           | 297          |\n",
      "|    time_elapsed         | 27977        |\n",
      "|    total_timesteps      | 9732096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018521701 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.414       |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 1.57e-05     |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 7104         |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    value_loss           | 44.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 348          |\n",
      "|    iterations           | 298          |\n",
      "|    time_elapsed         | 28054        |\n",
      "|    total_timesteps      | 9764864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012961489 |\n",
      "|    clip_fraction        | 0.00761      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 1.51e-05     |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 7128         |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    value_loss           | 44.7         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9788928, episode_reward=37.07 +/- 15.23\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 37.1         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9788928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016178174 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 1.45e-05     |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 7152         |\n",
      "|    policy_gradient_loss | -0.00163     |\n",
      "|    value_loss           | 40.5         |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 347     |\n",
      "|    iterations      | 299     |\n",
      "|    time_elapsed    | 28156   |\n",
      "|    total_timesteps | 9797632 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 348          |\n",
      "|    iterations           | 300          |\n",
      "|    time_elapsed         | 28230        |\n",
      "|    total_timesteps      | 9830400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010911855 |\n",
      "|    clip_fraction        | 0.00771      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.402       |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 1.38e-05     |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 7176         |\n",
      "|    policy_gradient_loss | -0.00144     |\n",
      "|    value_loss           | 43           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 348          |\n",
      "|    iterations           | 301          |\n",
      "|    time_elapsed         | 28305        |\n",
      "|    total_timesteps      | 9863168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012080474 |\n",
      "|    clip_fraction        | 0.00681      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.411       |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 1.32e-05     |\n",
      "|    loss                 | 22.3         |\n",
      "|    n_updates            | 7200         |\n",
      "|    policy_gradient_loss | -0.00108     |\n",
      "|    value_loss           | 45.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 348          |\n",
      "|    iterations           | 302          |\n",
      "|    time_elapsed         | 28382        |\n",
      "|    total_timesteps      | 9895936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007362795 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 1.26e-05     |\n",
      "|    loss                 | 21.4         |\n",
      "|    n_updates            | 7224         |\n",
      "|    policy_gradient_loss | -0.0013      |\n",
      "|    value_loss           | 42.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 348          |\n",
      "|    iterations           | 303          |\n",
      "|    time_elapsed         | 28458        |\n",
      "|    total_timesteps      | 9928704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013727206 |\n",
      "|    clip_fraction        | 0.00761      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.413       |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 1.2e-05      |\n",
      "|    loss                 | 22           |\n",
      "|    n_updates            | 7248         |\n",
      "|    policy_gradient_loss | -0.00111     |\n",
      "|    value_loss           | 43.3         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9948928, episode_reward=38.21 +/- 15.55\n",
      "Episode length: 25.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25           |\n",
      "|    mean_reward          | 38.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9948928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012569574 |\n",
      "|    clip_fraction        | 0.00688      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.407       |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 1.14e-05     |\n",
      "|    loss                 | 20.4         |\n",
      "|    n_updates            | 7272         |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    value_loss           | 41.4         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 348     |\n",
      "|    iterations      | 304     |\n",
      "|    time_elapsed    | 28559   |\n",
      "|    total_timesteps | 9961472 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 349          |\n",
      "|    iterations           | 305          |\n",
      "|    time_elapsed         | 28636        |\n",
      "|    total_timesteps      | 9994240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010354018 |\n",
      "|    clip_fraction        | 0.00757      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 1.07e-05     |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 7296         |\n",
      "|    policy_gradient_loss | -0.00146     |\n",
      "|    value_loss           | 41.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 349          |\n",
      "|    iterations           | 306          |\n",
      "|    time_elapsed         | 28714        |\n",
      "|    total_timesteps      | 10027008     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012221797 |\n",
      "|    clip_fraction        | 0.00855      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.411       |\n",
      "|    explained_variance   | 0.753        |\n",
      "|    learning_rate        | 1.01e-05     |\n",
      "|    loss                 | 20.1         |\n",
      "|    n_updates            | 7320         |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    value_loss           | 40.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x14f732b8610>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", env, learning_rate = learning_rate, batch_size = 2048, n_epochs = 24, policy_kwargs = policy_kwargs, gamma = 0.99,  verbose=1, tensorboard_log = \"C:/Users/kubaw/Desktop/DELFT/THESIS\\CODE/TEST_MODELS/LOGS/logs\")\n",
    "TIMESTEPS = 10000000\n",
    "model.learn(total_timesteps = TIMESTEPS, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "aa5c9e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r\"C:\\Users\\kubaw\\Desktop\\DELFT\\THESIS\\CODE\\TEST_MODELS\\32_ja_low_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d69968a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Act: [ 7 10] \n",
      " Obs: [0.92634445 0.8925168  0.91141653 0.89069617 0.9930584  0.9240684\n",
      " 0.9932654  0.98363453 0.9877893  0.9850194  0.9924606  0.99464905\n",
      " 0.9421162  0.9174931  0.9921635  0.84989536 0.8701049  0.99775994\n",
      " 0.995036   0.99662364 0.93052363 0.9832196  0.9883196  0.9898605\n",
      " 0.9920565  0.9934534  0.9125185  0.9900119  0.90531087 0.85756266\n",
      " 0.9914007  0.9929415  0.07363535 0.07836134 0.00636957 0.5167822\n",
      " 0.35770845 0.09400264 0.18666667] \n",
      " Balance 402.36250792691953\n",
      "Act: [0 0] \n",
      " Obs: [0.9216845  0.8840601  0.8926022  0.8757936  0.98503816 0.91861403\n",
      " 0.9892795  0.9699225  0.96993166 0.9811535  0.98836875 0.9876858\n",
      " 0.9301391  0.8950002  1.0026964  0.83625853 0.8600339  0.999407\n",
      " 0.9887747  0.9849863  0.91840464 0.9732661  0.9706089  0.98661536\n",
      " 0.9881776  0.9817699  0.9103362  0.9932513  0.885845   0.8431694\n",
      " 0.9860694  0.9883433  0.0620769  0.07151994 0.00636957 0.4730827\n",
      " 0.0559319  0.11265902 0.41066667] \n",
      " Balance 1751.8465235468889\n",
      "Act: [2 0] \n",
      " Obs: [0.91732854 0.87105995 0.8837616  0.996556   0.97623295 0.90846306\n",
      " 0.98205453 0.97038686 0.9634919  0.9841472  0.9825875  0.97881097\n",
      " 0.9203006  0.8779489  1.0083187  0.99904734 0.85078377 0.9921377\n",
      " 0.97966737 0.97505677 0.9039465  0.9640271  0.9554604  0.98039865\n",
      " 0.9732334  0.97702986 0.90239763 0.9853617  0.8712409  0.8368972\n",
      " 0.97737384 0.98533916 0.0837642  0.05021925 0.00636957 0.43788582\n",
      " 0.09555791 0.14588256 0.07733333] \n",
      " Balance 1026.7664663824153\n",
      "Act: [0 0] \n",
      " Obs: [0.90921396 0.8635565  0.8779455  0.99476653 0.9652628  0.89516217\n",
      " 0.9625444  0.9591787  0.95564234 0.9757006  0.9661266  0.96788764\n",
      " 0.9096643  0.8639704  0.9944501  0.9942096  0.8431051  0.987668\n",
      " 0.9729183  0.97142106 0.8924202  0.94694287 0.9481133  0.97873986\n",
      " 0.9645263  0.9539246  0.88951457 0.9786732  0.8640629  0.82871175\n",
      " 0.9652167  0.9763491  0.05373904 0.05201529 0.00643761 0.43818468\n",
      " 0.05819155 0.17089693 0.99333334] \n",
      " Balance 917.1958493792749\n",
      "Act: [1 0] \n",
      " Obs: [0.9079249  0.9922904  0.87355524 0.98955303 0.9447068  0.8890344\n",
      " 0.9595701  0.9521016  0.95354885 0.967458   0.95574945 0.9555883\n",
      " 0.90823615 0.8553958  0.9914282  0.9806761  0.84050965 0.987538\n",
      " 0.9574606  0.96323556 0.8745708  0.9454576  0.9357446  0.9742938\n",
      " 0.9605035  0.9579599  0.87301826 0.973355   0.8494021  0.820946\n",
      " 0.9436108  0.9758564  0.06154051 0.02554587 0.00643761 0.3999234\n",
      " 0.07985997 0.06247457 0.7173333 ] \n",
      " Balance 321.5564005092833\n",
      "Act: [1 0] \n",
      " Obs: [0.8982102  0.97459155 0.8617922  0.9756674  0.9401771  0.8862802\n",
      " 0.94150263 0.94054437 0.9477044  0.9568849  0.9474291  0.95480025\n",
      " 0.90510416 0.980997   0.9828936  0.97277886 0.837535   0.97845304\n",
      " 0.94731754 0.         0.86745155 0.93218774 0.9321205  0.9842458\n",
      " 0.9553314  0.9572816  0.86501694 0.9611167  0.83432883 0.80662555\n",
      " 0.93829453 0.9704372  0.07425638 0.02266277 0.00644046 0.40531918\n",
      " 0.08117204 0.03187914 0.5133333 ] \n",
      " Balance 806.9525278996375\n",
      "Act: [0 0] \n",
      " Obs: [0.8896913  0.9635358  0.8539048  0.97095335 0.93703717 0.8822965\n",
      " 0.9369067  0.92845786 0.9314955  0.9485772  0.93831944 0.9450158\n",
      " 0.9007594  0.967543   0.9737195  0.9689509  0.82697827 0.97751147\n",
      " 0.9420092  0.         0.86205024 0.9383099  0.92146075 0.9784078\n",
      " 0.94914407 0.95065415 0.8670265  0.94881904 0.8272053  0.7962157\n",
      " 0.92653924 0.9645548  0.07855926 0.02397599 0.00675054 0.37904334\n",
      " 0.05982355 0.04408333 0.34      ] \n",
      " Balance 1202.1596414376645\n",
      "Act: [0 0] \n",
      " Obs: [0.8826506  0.95414966 0.8427618  0.9693517  0.9313805  0.8708633\n",
      " 0.9324764  0.9240331  0.9165828  0.93909675 0.92590845 0.92849857\n",
      " 0.894331   0.9529599  0.9615926  0.95643467 0.8200494  0.9598814\n",
      " 0.93597794 0.         0.86059237 0.92123836 0.91779584 0.9766737\n",
      " 0.9357416  0.94591    0.86606014 0.94538856 0.81093794 0.79100436\n",
      " 0.91956747 0.9605269  0.08992148 0.0274437  0.00675368 0.38868576\n",
      " 0.06102002 0.02412914 0.91466665] \n",
      " Balance 1119.3244580153498\n",
      "Act: [1 3] \n",
      " Obs: [0.8607763  0.9529639  0.9828714  0.9539526  0.9314424  0.86688685\n",
      " 0.92806953 0.9178313  0.90438175 0.93729955 0.91086596 0.9187102\n",
      " 0.8875316  0.9405889  0.9565886  0.94761026 0.8068869  0.9510486\n",
      " 0.91958606 0.9897243  0.8568963  0.91971046 0.9098687  0.9810294\n",
      " 0.92534006 0.9481522  0.8544739  0.93869716 0.9928019  0.9872921\n",
      " 0.9080138  0.95776176 0.09429036 0.02877706 0.00675368 0.34801593\n",
      " 0.16817929 0.05059821 0.08666667] \n",
      " Balance 437.3985776033919\n",
      "Act: [0 0] \n",
      " Obs: [0.8647877  0.95470995 0.96705043 0.9497634  0.91723275 0.85484296\n",
      " 0.9131092  0.9043991  0.90030986 0.92624336 0.8989949  0.92205024\n",
      " 0.88351953 0.9291438  0.94278944 0.937858   0.7995061  0.94205123\n",
      " 0.90555334 0.98625654 0.8516378  0.9059464  0.         0.9669505\n",
      " 0.92623615 0.935638   0.84511524 0.9407475  0.9827653  0.96469295\n",
      " 0.9035876  0.9584485  0.0749796  0.02288349 0.0071092  0.39867508\n",
      " 0.06553314 0.07168568 0.89066666] \n",
      " Balance 1276.129980045431\n",
      "Act: [1 0] \n",
      " Obs: [0.8527542  0.9492651  0.9575982  0.94154483 0.91025347 0.9882228\n",
      " 0.90115047 0.89843684 0.8929809  0.9237925  0.8923246  0.9133277\n",
      " 0.86837107 0.92532164 0.         0.9235238  0.80084246 0.94425726\n",
      " 0.8956802  0.9877663  0.8439939  0.8936245  0.         0.95240575\n",
      " 0.9149463  0.9260246  0.83519286 0.93030494 0.9695937  0.9552573\n",
      " 0.8964637  0.9515217  0.08888309 0.02712678 0.00711716 0.36497706\n",
      " 0.08713633 0.06380851 0.90133333] \n",
      " Balance 600.5718531609864\n",
      "Act: [1 0] \n",
      " Obs: [0.8342855  0.9376655  0.9518052  0.9357359  0.9011219  0.9834483\n",
      " 0.8837543  0.89689904 0.89164704 0.9187014  0.88955265 0.8899515\n",
      " 0.8619515  0.91866827 0.99169564 0.9131132  0.8010146  0.93547344\n",
      " 0.8849956  0.97471774 0.84266025 0.8826258  0.         0.9492265\n",
      " 0.9057449  0.91987693 0.8388893  0.92642057 0.96855253 0.9387739\n",
      " 0.88637894 0.9463675  0.11827676 0.03609762 0.00881142 0.37556902\n",
      " 0.10873435 0.03949037 0.588     ] \n",
      " Balance 576.0421086074639\n",
      "Act: [2 0] \n",
      " Obs: [0.99017644 0.92265016 0.94914395 0.9238233  0.8959327  0.9780311\n",
      " 0.87669134 0.89119333 0.8861914  0.91356623 0.87961316 0.8797423\n",
      " 0.99963516 0.9009141  0.9918664  0.9063842  0.78981686 0.923449\n",
      " 0.8890324  0.9663553  0.83950454 0.8801849  0.         0.9348582\n",
      " 0.89436406 0.91407865 0.825685   0.9091246  0.9614253  0.9276847\n",
      " 0.88205975 0.929826   0.1457283  0.04447573 0.00907213 0.36910382\n",
      " 0.1180663  0.06374205 0.22133334] \n",
      " Balance 988.8385797196729\n",
      "Act: [0 0] \n",
      " Obs: [0.9877475  0.9096046  0.9461408  0.91973394 0.8827414  0.9759366\n",
      " 0.8721637  0.89087147 0.8761358  0.9022574  0.8706814  0.87439907\n",
      " 0.989098   0.89104843 0.9849269  0.894494   0.7871913  0.9122865\n",
      " 0.8770375  0.9569384  0.8213213  0.8747295  0.         0.93059576\n",
      " 0.8852974  0.90350646 0.8166166  0.9060155  0.9594733  0.9180165\n",
      " 0.8677572  0.9238332  0.1696267  0.05176943 0.00907213 0.3245261\n",
      " 0.06871846 0.0422077  0.8106667 ] \n",
      " Balance 1545.3249640766523\n",
      "Act: [1 0] \n",
      " Obs: [0.98398626 0.90060073 0.9359264  0.91360265 0.8765653  0.9642459\n",
      " 0.8611096  0.87933415 0.8625142  0.8976416  0.9851298  0.87166494\n",
      " 0.9828342  0.88129497 0.9751422  0.9004315  0.7751022  0.9074016\n",
      " 0.87024    0.9443841  0.8135348  0.8744656  0.         0.921623\n",
      " 0.8768629  0.90055746 0.81118566 0.8929022  0.9546501  0.9117759\n",
      " 0.8543122  0.9222717  0.17962603 0.05482119 0.00907302 0.29712018\n",
      " 0.09361288 0.05310803 0.012     ] \n",
      " Balance 1700.903385014983\n",
      "Act: [0 0] \n",
      " Obs: [0.96532166 0.8916726  0.9296869  0.91504663 0.8715854  0.96031815\n",
      " 0.8462264  0.8757606  0.8644068  0.8941181  0.97906125 0.8540668\n",
      " 0.977603   0.8762462  0.9763855  0.9018084  0.76920986 0.89481926\n",
      " 0.8592687  0.92683995 0.806655   0.867027   0.         0.90007526\n",
      " 0.87002426 0.88932174 0.8027602  0.88608277 0.94663763 0.8984445\n",
      " 0.84536976 0.92040503 0.1624571  0.04958129 0.00907421 0.2832732\n",
      " 0.07149468 0.04742225 0.20533334] \n",
      " Balance 1908.2112324778925\n",
      "Act: [0 0] \n",
      " Obs: [0.9644007  0.8859083  0.9188653  0.90705645 0.8584323  0.95411044\n",
      " 0.8343601  0.8636427  0.8579667  0.89417887 0.9635928  0.83861375\n",
      " 0.9803914  0.86698586 0.96517617 0.88734895 0.76258564 0.8894749\n",
      " 0.8593814  0.92322445 0.7915928  0.8539581  0.         0.88133824\n",
      " 0.8589719  0.8789214  0.79673827 0.8766506  0.9370642  0.8859098\n",
      " 0.8217803  0.9193822  0.1921142  0.05863253 0.02475015 0.29263774\n",
      " 0.07292458 0.05704786 0.88266665] \n",
      " Balance 1737.8665848571738\n",
      "Act: [1 0] \n",
      " Obs: [0.95291156 0.87753344 0.90468943 0.88902754 0.8471541  0.94867605\n",
      " 0.9990039  0.86089516 0.8355596  0.8863205  0.9547555  0.8364322\n",
      " 0.97408956 0.8574328  0.9675404  0.87681705 0.74960005 0.8776437\n",
      " 0.84698546 0.92073315 0.7732753  0.8471053  0.         0.87620723\n",
      " 0.8422967  0.8670517  0.77943116 0.87025994 0.91814274 0.8659014\n",
      " 0.8233554  0.8983021  0.2342296  0.07148599 0.07892025 0.2928863\n",
      " 0.09897459 0.04575573 0.488     ] \n",
      " Balance 1683.8119999551081\n",
      "Act: [0 0] \n",
      " Obs: [0.9420808  0.8666977  0.89308804 0.8809364  0.84487414 0.9513588\n",
      " 1.0002328  0.86377025 0.8216616  0.8720867  0.94949406 0.8348897\n",
      " 0.9679102  0.86387104 0.968687   0.866137   0.739698   0.8670019\n",
      " 0.84271073 0.9171921  0.776465   0.83450466 0.         0.87460023\n",
      " 0.84464294 0.86686563 0.7695512  0.86345166 0.90856415 0.8497513\n",
      " 0.82111377 0.88847405 0.27814868 0.08488993 0.13621907 0.27032584\n",
      " 0.07587072 0.06324914 0.32133332] \n",
      " Balance 2379.7353593480902\n",
      "Act: [0 0] \n",
      " Obs: [0.9353639  0.85298836 0.8728103  0.8786233  0.837528   0.\n",
      " 1.0053803  0.86443627 0.813213   0.8691791  0.9435994  0.83272356\n",
      " 0.96132714 0.8531262  0.9628005  0.86194205 0.7321226  0.8703378\n",
      " 0.83323723 0.9081182  0.77599216 0.82153356 0.         0.86824566\n",
      " 0.8366211  0.8650449  0.7628044  0.8598395  0.9068362  0.8469018\n",
      " 0.8188334  0.87820554 0.34405014 0.10500281 0.13621907 0.27278674\n",
      " 0.07738814 0.0525227  0.316     ] \n",
      " Balance 2629.8709658424737\n",
      "Act: [0 0] \n",
      " Obs: [0.9254775  0.84642756 0.86273366 0.8682088  0.827367   0.\n",
      " 0.9885822  0.85242885 0.80498767 0.8659248  0.9383723  0.8306861\n",
      " 0.95417005 0.84714687 0.9528076  0.         0.72167516 0.8583283\n",
      " 0.8246143  0.90028745 0.76745075 0.8161333  0.         0.86031497\n",
      " 0.8232516  0.8685226  0.7512667  0.8614013  0.8944215  0.8533982\n",
      " 0.8146963  0.87636787 0.37610084 0.11478456 0.13632831 0.26566046\n",
      " 0.07638958 0.03582848 0.24      ] \n",
      " Balance 3161.145260255875\n",
      "Act: [0 0] \n",
      " Obs: [0.9205131  0.83971214 0.8484524  0.86192054 0.81831115 0.\n",
      " 0.9762044  0.84517    0.80808336 0.8555971  0.9208449  0.81646127\n",
      " 0.94367975 0.8383751  0.95156604 0.         0.71251166 0.85499144\n",
      " 0.81626296 0.90032405 0.7558954  0.8092417  0.         0.8579578\n",
      " 0.81341016 0.86429447 0.741997   0.8588612  0.8919862  0.85635644\n",
      " 0.8028417  0.8656672  0.3462821  0.10568398 0.13632831 0.2687021\n",
      " 0.07532013 0.05799408 0.508     ] \n",
      " Balance 3399.1853536084336\n",
      "Act: [1 0] \n",
      " Obs: [0.9100503  0.83304733 0.         0.8555967  0.80640465 1.0158396\n",
      " 0.9787128  0.8329605  0.8014628  0.84617126 0.9103635  0.8002301\n",
      " 0.943532   0.83114976 0.9487413  0.         0.70835125 0.834553\n",
      " 0.80166125 0.88138175 0.7433257  0.8021581  0.         0.86028486\n",
      " 0.80978453 0.         0.7299414  0.84805113 0.881479   0.8465935\n",
      " 0.7963909  0.855483   0.38777503 0.11834747 0.1698353  0.2580491\n",
      " 0.12373921 0.06750807 0.88266665] \n",
      " Balance 2617.827734619351\n",
      "Act: [0 0] \n",
      " Obs: [0.898927   0.81842464 0.         0.8470754  0.8036463  1.0035576\n",
      " 0.9717627  0.81946    0.         0.83588886 0.90648633 0.7934992\n",
      " 0.94142133 0.82460976 0.94542074 0.         0.7076288  0.8198155\n",
      " 0.         0.8659926  0.7317296  0.7929214  0.         0.8514436\n",
      " 0.78874844 0.         0.7249495  0.8419527  0.8720598  0.82372296\n",
      " 0.7923114  0.8462291  0.38397357 0.11718728 0.16983531 0.26236904\n",
      " 0.07566089 0.05112636 0.9866667 ] \n",
      " Balance 3033.0198671496973\n",
      "Act: [ 1 12] \n",
      " Obs: [0.89008594 0.80632406 1.0189269  0.         0.7989105  0.995614\n",
      " 0.95923114 0.80959165 0.         0.82927924 0.9031812  0.7875959\n",
      " 0.         0.8220291  0.9400351  0.         1.0217916  1.0110942\n",
      " 1.0201715  0.8656986  1.0148646  1.026457   1.0163331  0.\n",
      " 1.0114475  1.016803   1.0134933  1.0238882  0.8593306  1.0139184\n",
      " 1.0077027  0.8377844  0.38397357 0.11718728 0.16983531 0.26236904\n",
      " 0.38707298 0.11411989 0.41066667] \n",
      " Balance 884.3489815780149\n",
      "total financial balance: (eur) 38108.397163018126 internal rate of return nan \n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate1(1, env_test, model)\n",
    "\n",
    "# model 3 - max rew = 37.30\n",
    "# model 4 - 38.21\n",
    "# model 5 - 38.39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "84b1e177",
   "metadata": {
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate2(episodes, environment, model):\n",
    "    \n",
    "    mean_irr = 0\n",
    "    mean_fin_balance = 0\n",
    "    irr = 0\n",
    "    fin_balance = 0\n",
    "    count = 0\n",
    "    npv = 0\n",
    "    list_npv = []\n",
    "    env_balance = 0\n",
    "    mean_env_balance = 0\n",
    "\n",
    "    for ep in range(episodes):\n",
    "\n",
    "        obs, _ = environment.reset()  # Unpack the tuple and ignore the info part\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs)  # Now obs is just the observation array\n",
    "            obs, reward, done, truncated, info = environment.step(action)\n",
    "            # Extracting the 2nd and 3rd key-value pairs\n",
    "            keys = list(info.keys())\n",
    "            values = list(info.values())\n",
    "\n",
    "            # Getting the 2nd key-value pair\n",
    "            second_value = values[1]\n",
    "\n",
    "            # Getting the 3rd key-value pair\n",
    "            fourth_value = values[4]\n",
    "            \n",
    "            fith_value = values[5]\n",
    "        \n",
    "        fin_balance += second_value\n",
    "        npv += fourth_value\n",
    "        count += 1\n",
    "        \n",
    "        env_balance += fith_value\n",
    "        \n",
    "        list_npv.append(fourth_value)\n",
    "            \n",
    "    mean_fin_balance = fin_balance/count\n",
    "    mean_npv = npv/count\n",
    "    mean_env_balance = env_balance / count\n",
    "\n",
    "    #print(mean_npv)\n",
    "\n",
    "    environment.close()\n",
    "    \n",
    "    return(mean_npv, mean_env_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9ac8ec3b",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kubaw\\AppData\\Local\\Temp\\ipykernel_4840\\3085370352.py:225: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  value = annual_expense / self.current_budget_constraint\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22241.29117767018, 61643.237394789)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate2(3000, env_test, model)\n",
    "\n",
    "# 29126.347277021632\n",
    "# 29241.136351006262\n",
    "# 36152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e0af1d69",
   "metadata": {
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def basepolicy1(episodes, environment):\n",
    "    \n",
    "    mean_irr = 0\n",
    "    mean_fin_balance = 0\n",
    "    irr = 0\n",
    "    fin_balance = 0\n",
    "    count = 0\n",
    "    irr_count = 0\n",
    "    npv = 0\n",
    "    list_npv = []\n",
    "    env_balance = 0\n",
    "    mean_env_balance = 0\n",
    "\n",
    "    for ep in range(episodes):\n",
    "\n",
    "        obs, _ = environment.reset()  # Unpack the tuple and ignore the info part\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            \n",
    "            action = np.array([0, 0])\n",
    "            for i, n in enumerate(obs):\n",
    "                if i < 32:\n",
    "                    if i < 16:\n",
    "                        if n < 0.80:\n",
    "                            action[0] += 1\n",
    "                    if i >= 16:\n",
    "                        if n < 0.80:\n",
    "                            action[1] += 1\n",
    "                    \n",
    "\n",
    "            obs, reward, done, truncated, info = environment.step(action)\n",
    "\n",
    "            # Extracting the 2nd and 3rd key-value pairs\n",
    "            keys = list(info.keys())\n",
    "            values = list(info.values())\n",
    "\n",
    "            # Getting the 2nd key-value pair\n",
    "            second_value = values[1]\n",
    "\n",
    "            # Getting the 3rd key-value pair\n",
    "    \n",
    "            third_value = values[2]\n",
    "            fourth_value = values[4]\n",
    "            fith_value = values[5]\n",
    "            \n",
    "        \n",
    "        fin_balance += second_value\n",
    "        npv += fourth_value\n",
    "        count += 1\n",
    "        \n",
    "        env_balance += fith_value\n",
    "        \n",
    "        list_npv.append(fourth_value)\n",
    "            \n",
    "    mean_fin_balance = fin_balance/count\n",
    "    mean_env_balance = env_balance/count\n",
    "    mean_npv = npv/count\n",
    "\n",
    "    #print(mean_npv, \"\\n\", mean_irr, \"\\n\" )\n",
    "\n",
    "    environment.close()\n",
    "    \n",
    "    return(mean_npv, mean_env_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "52278c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kubaw\\AppData\\Local\\Temp\\ipykernel_4840\\3085370352.py:225: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  value = annual_expense / self.current_budget_constraint\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22103.15529939608, 62351.283144360495)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basepolicy1(5000, env_test)\n",
    "\n",
    "#34811"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
